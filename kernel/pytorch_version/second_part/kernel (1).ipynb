{
  "cells": [
    {
      "metadata": {
        "_uuid": "54643e32b4132d15df20d55f2b9ee09efc2c51a8"
      },
      "cell_type": "markdown",
      "source": "# Libraries"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b15761a022f76bb50db1bb55c21b59a3f1c88261"
      },
      "cell_type": "code",
      "source": "import os\nimport sys\nimport random\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-white')\nimport seaborn as sns\nsns.set_style(\"white\")\n\nimport shutil\n\n%matplotlib inline\n\n# import cv2\nfrom sklearn.model_selection import train_test_split\n\nfrom scipy import ndimage\n\nfrom tqdm import tqdm_notebook #, tnrange\n#from itertools import chain\nfrom skimage.io import imread, imshow #, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\nfrom skimage import filters\n\nfrom imgaug import augmenters as iaa\n\nfrom tqdm import tqdm\nfrom pathlib import Path\n\nimport cv2\nfrom sklearn.model_selection import StratifiedKFold\nimport torch\nfrom torch import nn\nfrom torch import Tensor\nfrom torch.optim import Adam, SGD\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.backends.cudnn as cudnn\nimport torch.backends.cudnn\nfrom torch.autograd import Variable\nfrom torch.nn import functional as F\nfrom torchvision.transforms import ToTensor, ToPILImage, Normalize, Compose\n\nimport PIL\n\nfrom datetime import datetime\nimport json\nimport gc\n\nimport time\nt_start = time.time()",
      "execution_count": 41,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "99e7207d6aec7d921e4b8ad4f30d310d2346216a"
      },
      "cell_type": "markdown",
      "source": "# Global variable"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "73cc76d8506e96b912600406fa5ceeb47083978a"
      },
      "cell_type": "code",
      "source": "TRAIN_IMG_PATH = \"../input/tgs-salt-identification-challenge/train/images/\"\nTEST_IMG_PATH = \"../input/tgs-salt-identification-challenge/test/images/\"\nDEPTH_PATH = \"../input/tgs-salt-identification-challenge/depths.csv\"\nTRAIN_MASK_PATH = \"../input/tgs-salt-identification-challenge/train/masks/\"\nTRAIN_INFO_PATH = \"../input/tgs-salt-identification-challenge/train.csv\"\nFILENAME = \"checkpoint.pth.tar\"\nBEST_FILENAME = \"model_best.pth.tar\"\n\n# basic parameters\nIMG_ORI_SIZE = 101\nIMG_TAR_SIZE = 101\n\n# Keras Model parameters\nSTART_NEURONS = 16\nDROPOUT_RATIO = 0.5\n\nMODEL1_ADAM_LR = 0.01\nMODEL1_EPOCHS = 100\nMODEL1_BATCH_SIZE = 64\nMODEL1_STEPS_PER_EPOCH_TRAIN = 200\nMODEL1_LOSS = 'binary_crossentropy'\n\nMODEL2_ADAM_LR = 0.01\nMODEL2_EPOCHS = 100\nMODEL2_BATCH_SIZE = 64\nMODEL2_STEPS_PER_EPOCH_TRAIN = 200\nMODEL2_LOSS = 'lovasz_loss'\n\n# ReduceLROnPlateau parameters\nMODEL1_REDUCE_FACTOR = 0.5\nMODEL1_REDUCE_PATIENT = 5\n\nMODEL2_REDUCE_FACTOR = 0.5\nMODEL2_REDUCE_PATIENT = 5\n\nversion = 1\n\n# Name\nBASIC_NAME = f'Unet_resnet_v{version}'\nSAVE_MODEL_NAME = BASIC_NAME + '.model'\nSUBMISSION_NAME = BASIC_NAME + '.csv'",
      "execution_count": 42,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "aa113e7f4cabb11b9a14afc2151e96ff664ef7ed"
      },
      "cell_type": "code",
      "source": "# encoding=utf8\nimport cv2\nimport numpy as np\nfrom torch import nn\nfrom functools import reduce\n\n################################################################################\n# related functions & loss functions\n################################################################################\n\n\ndef upsample(img):\n    if IMG_ORI_SIZE == IMG_TAR_SIZE:\n        return img\n    return cv2.resize(img, (IMG_TAR_SIZE, IMG_TAR_SIZE))\n\n\ndef downsample(img):\n    if IMG_ORI_SIZE == IMG_TAR_SIZE:\n        return img\n    return cv2.resize(img, (IMG_ORI_SIZE, IMG_ORI_SIZE))\n\nclass MyEncoder(json.JSONEncoder):\n    def default(self, obj):\n        if isinstance(obj, np.integer):\n            return int(obj)\n        elif isinstance(obj, np.floating):\n            return float(obj)\n        elif isinstance(obj, np.ndarray):\n            return obj.tolist()\n        else:\n            return super(MyEncoder, self).default(obj)\n\ndef write_event(log, step: int, **data):\n    data['step'] = step\n    data['dt'] = datetime.now().isoformat()\n    log.write(json.dumps(data, sort_keys=True, cls=MyEncoder))\n    log.write('\\n')\n    log.flush()\n\ndef get_variable(x):\n    \"\"\" Converts tensors to cuda, if available. \"\"\"\n    if torch.cuda.is_available():\n        return x.cuda()\n    return x\n\ndef get_numpy(x):\n    \"\"\" Get numpy array for both cuda and not. \"\"\"\n    if torch.cuda.is_available():\n        return x.cpu().data.numpy()\n    return x.data.numpy()\n    \ndef iou_numpy(outputs, labels):\n    SMOOTH = 1e-6\n    labels = labels.squeeze(1)\n    outputs = outputs.squeeze(1)\n    \n    intersection = (outputs & labels).sum((1, 2))\n    union = (outputs | labels).sum((1, 2))\n    \n    iou = (intersection + SMOOTH) / (union + SMOOTH)\n    \n    thresholded = np.ceil(np.clip(20 * (iou - 0.5), 0, 10)) / 10\n    \n    return thresholded.mean()\n\n\ndef my_iou_metric(label, pred):\n    return iou_numpy(pred > 0.5, label>0.5)\n\n\ndef my_iou_metric_2(label, pred):\n    return iou_numpy(pred > 0, label>0.5)\n\n\ndef my_iou_metric_thre(label, pred, thre):\n    return iou_numpy(pred > thre, label>0.5) \n\n\nclass DICELoss(nn.Module):\n\n    def __init__(self):\n        super(DICELoss, self).__init__()\n\n    def forward(self, output, mask):\n\n        probs = torch.squeeze(output, 1)\n        mask = torch.squeeze(mask, 1)\n\n        intersection = probs * mask\n        intersection = torch.sum(intersection, 2)\n        intersection = torch.sum(intersection, 1)\n\n        den1 = probs\n        # print(den1.size())\n        den1 = torch.sum(den1, 2)\n        den1 = torch.sum(den1, 1)\n\n        den2 = mask\n        # print(den2.size())\n        den2 = torch.sum(den2, 2)\n        den2 = torch.sum(den2, 1)\n\n        eps = 0.0000001\n        dice = 2 * ((intersection + eps) / (den1 + den2 + eps))\n        # dice_eso = dice[:, 1:]\n        dice_eso = dice\n\n        loss = 1 - torch.sum(dice_eso) / dice_eso.size(0)\n        return loss   \n\nclass BCE_DICE_Loss(nn.Module):\n\n    def __init__(self):\n        super(BCE_DICE_Loss, self).__init__()\n\n    def forward(self, output, mask):\n        criterion_1 = nn.BCELoss()\n        criterion_2 = DICELoss()\n        loss = criterion_1(output, mask) + criterion_2(output, mask)\n        return loss   \n    \ndef save_checkpoint(state, is_best, filename=FILENAME):\n    torch.save(state, filename)\n    if is_best:\n        shutil.copyfile(filename, BEST_FILENAME)\n        \n\n\"\"\"\nLovasz-Softmax and Jaccard hinge loss in PyTorch\nMaxim Berman 2018 ESAT-PSI KU Leuven (MIT License)\n\"\"\"\n\nfrom __future__ import print_function, division\n\nimport torch\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nimport numpy as np\ntry:\n    from itertools import  ifilterfalse\nexcept ImportError: # py3k\n    from itertools import  filterfalse\n\n\ndef lovasz_grad(gt_sorted):\n    \"\"\"\n    Computes gradient of the Lovasz extension w.r.t sorted errors\n    See Alg. 1 in paper\n    \"\"\"\n    p = len(gt_sorted)\n    gts = torch.sum(gt_sorted)\n    intersection = gts - torch.cumsum(gt_sorted,0)\n    union = gts + torch.cumsum(1 - gt_sorted, 0)\n    jaccard = 1. - intersection / union\n    if p > 1: # cover 1-pixel case\n        jaccard[1:p] = jaccard[1:p] - jaccard[0:-1]\n    return jaccard\n\n\n# --------------------------- BINARY LOSSES ---------------------------\n\n\ndef lovasz_hinge(logits, labels, per_image=True, ignore=None):\n    \"\"\"\n    Binary Lovasz hinge loss\n      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n      per_image: compute the loss per image instead of per batch\n      ignore: void class id\n    \"\"\"\n    if per_image:\n        losses = 0\n        loss = mean(lovasz_hinge_flat(*flatten_binary_scores(log.unsqueeze(0), lab.unsqueeze(0), ignore))\n                          for log, lab in zip(logits, labels))\n    else:\n        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n    return loss\n\n\ndef lovasz_hinge_flat(logits, labels):\n    \"\"\"D\n    Binary Lovasz hinge loss\n      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n      labels: [P] Tensor, binary ground truth labels (0 or 1)\n      ignore: label to ignore\n    \"\"\"\n    if len(labels) == 0:\n        # only void pixels, the gradients should be 0\n        return logits.sum() * 0.\n    signs = 2 * labels - 1.\n    errors = (1 - logits * signs)\n    errors_sorted, perm = torch.sort(errors, dim=0, descending=True)\n    perm = perm.data\n    gt_sorted = labels[perm]\n    grad = lovasz_grad(gt_sorted)\n    loss = torch.dot(F.relu(errors_sorted), grad)\n    return loss\n\n\ndef flatten_binary_scores(scores, labels, ignore=None):\n    \"\"\"\n    Flattens predictions in the batch (binary case)\n    Remove labels equal to 'ignore'\n    \"\"\"\n    scores = scores.view(-1)\n    labels = labels.view(-1)\n    if ignore is None:\n        return scores, labels\n    valid = (labels != ignore)\n    vscores = scores[valid]\n    vlabels = labels[valid]\n    return vscores, vlabels\n\ndef mean(l, ignore_nan=False, empty=0):\n    \"\"\"\n    nanmean compatible with generators.\n    \"\"\"\n    l = iter(l)\n    if ignore_nan:\n        l = ifilterfalse(np.isnan, l)\n    try:\n        n = 1\n        acc = next(l)\n    except StopIteration:\n        if empty == 'raise':\n            raise ValueError('Empty mean')\n        return empty\n    for n, v in enumerate(l, 2):\n        acc += v\n    if n == 1:\n        return acc\n    return acc / n\n\n\nclass Lovasz_Loss(nn.Module):\n\n    def __init__(self):\n        super(Lovasz_Loss, self).__init__()\n\n    def forward(self, output, mask, per_image=True, ignore=None):\n        \n        return lovasz_hinge(output, mask, per_image, ignore)",
      "execution_count": 58,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ef0e5853d0c2cc72dbf8a9fe90720a610a8dcccd"
      },
      "cell_type": "code",
      "source": "import imgaug as ia\nfrom imgaug import augmenters as iaa\nimport numpy as np\n\nia.seed(2018)\n\n\ndef _standardize(img):\n    return (img - img.map(np.mean)) / img.map(np.std)\n\n\nst = lambda aug: iaa.Sometimes(0.5, aug)\naffine_seq = iaa.Sequential([\n    # General\n    st(iaa.Affine(\n            scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)}, # scale images to 80-120% of their size, individually per axis\n            translate_percent={\"x\": (-0.15, 0.15), \"y\": (-0.15, 0.15)} # translate by -16 to +16 pixels (per axis)\n        )),\n    # Deformations\n    iaa.Sometimes(0.3, iaa.PiecewiseAffine(scale=(0.04, 0.08))),\n    iaa.Sometimes(0.3, iaa.PerspectiveTransform(scale=(0.05, 0.1))),\n], random_order=True)\n\nintensity_seq = iaa.Sequential([\n    iaa.Invert(0.3),\n    iaa.Sometimes(0.3, iaa.ContrastNormalization((0.5, 1.5))),\n    iaa.OneOf([\n        iaa.Noop(),\n        iaa.Sequential([\n            iaa.OneOf([\n                iaa.Add((-10, 10)),\n                iaa.AddElementwise((-10, 10)),\n                iaa.Multiply((0.95, 1.05)),\n                iaa.MultiplyElementwise((0.95, 1.05)),\n            ]),\n        ]),\n        iaa.OneOf([\n            iaa.GaussianBlur(sigma=(0.0, 1.0)),\n            iaa.AverageBlur(k=(2, 5)),\n            #iaa.MedianBlur(k=(3, 5))\n        ])\n    ])\n], random_order=False)",
      "execution_count": 44,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1de194accd07b923821cc2f665f35d4502420869"
      },
      "cell_type": "code",
      "source": "# encoding=utf8\nimport numpy as np\nimport pandas as pd\nimport cv2\nfrom tqdm import tqdm_notebook\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nimport torch\nfrom torch import nn\nfrom torch.optim import Adam\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.backends.cudnn as cudnn\nimport torch.backends.cudnn\nfrom torch.autograd import Variable\nfrom torch.nn import functional as F\nfrom torchvision.transforms import ToTensor, Normalize, Compose\n\n## convert salt coverage to class\ndef _cov_to_class(mask):\n    border = 10\n    outer = np.zeros((101-2*border, 101-2*border), np.float32)\n    outer = cv2.copyMakeBorder(outer, border, border, border, border, borderType = cv2.BORDER_CONSTANT, value = 1)\n\n    cover = (mask>0.5).sum()\n    if cover < 8:\n        return 0 # empty\n    if cover == ((mask*outer) > 0.5).sum():\n        return 1 #border\n    if np.all(mask==mask[0]):\n        return 2 #vertical\n\n    percentage = cover/(101*101)\n    if percentage < 0.15:\n        return 3\n    elif percentage < 0.25:\n        return 4\n    elif percentage < 0.50:\n        return 5\n    elif percentage < 0.75:\n        return 6\n    else:\n        return 7\n\n## used to load data from data files\nclass my_DataLoader:\n\n    def __init__(self, train=True, test=True, Kflod=False, test_size=0.2, num_flod=5):\n        self.test = test\n        self.train = train\n        self.Kflod = Kflod\n        self.test_size = test_size\n        \n        if self.Kflod:\n            self.num_flod = num_flod\n        else:\n            self.num_flod = 0\n        \n        if self.train:\n            train_df, self.test_df = self._load_depth()\n            self._load_image_mask(train_df, self.test_df)\n            train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(IMG_ORI_SIZE, 2)\n            train_df[\"coverage_class\"] = train_df.masks.map(_cov_to_class)\n            self.x_train, self.x_valid, self.y_train, self.y_valid = self._get_train_test_split(train_df)\n            train_df = None\n            \n        if self.test:\n            self.x_test = np.array(self.test_df.images.tolist()).reshape(-1, IMG_TAR_SIZE, IMG_TAR_SIZE, 1)\n\n    @staticmethod\n    def _load_image_mask(train_df, test_df):\n        # load image data & mask data\n        train_df['images'] = [np.array(cv2.imread(TRAIN_IMG_PATH + \"{}.png\".format(idx), 0)) for idx in tqdm_notebook(train_df.index)]\n        train_df['masks'] = [np.array(cv2.imread(TRAIN_MASK_PATH + \"{}.png\".format(idx), 0)) for idx in tqdm_notebook(train_df.index)]\n        test_df['images'] = [np.array(cv2.imread(TEST_IMG_PATH + \"{}.png\".format(idx), 0)) for idx in tqdm_notebook(test_df.index)]\n        # Normalize image vectors\n        train_df['images'] /= 255\n        test_df['images'] /= 255\n        train_df['masks'] /= 255\n\n    @staticmethod\n    def _load_depth():\n        train_df = pd.read_csv(TRAIN_INFO_PATH, index_col=\"id\", usecols=[0])\n        depths_df = pd.read_csv(DEPTH_PATH, index_col=\"id\")\n        depths_df['z'] = depths_df['z'].astype('float')\n        train_df = train_df.join(depths_df)\n        test_df = depths_df[~depths_df.index.isin(train_df.index)]\n        return train_df, test_df\n\n    ## get train & validation split stratified by salt coverage\n    @staticmethod\n    def _get_train_test_split(train_df):\n        x_train, x_valid, y_train, y_valid = train_test_split(\n            np.array(train_df.images.map(upsample).tolist()).reshape(-1, IMG_TAR_SIZE, IMG_TAR_SIZE, 1),\n            np.array(train_df.masks.map(upsample).tolist()).reshape(-1, IMG_TAR_SIZE, IMG_TAR_SIZE, 1),\n            test_size=0.2, stratify=train_df.coverage_class, random_state=1234)\n        return x_train, x_valid, y_train, y_valid\n\n    def get_train(self):\n        return self.x_train, self.y_train\n    \n    def get_valid(self):\n        return self.x_valid, self.y_valid\n\n    def get_test_x(self):\n        return self.x_test\n\n    def get_test_df(self):\n        return self.test_df\n    \nclass ShipDataset(Dataset):\n    def __init__(self, data, transform=None, mode='train'):\n        if mode == 'train' or mode == 'valid':\n            self.x = np.transpose(data[0], (0,3,1,2))\n            self.y = np.transpose(data[1], (0,3,1,2))\n        elif mode == 'test':\n            self.data = np.transpose(data, (0,3,1,2))\n        else:\n            raise RuntimeError('MODE_ERROR')\n        self.transform = transform\n        self.mode = mode\n\n    def __len__(self):\n        if self.mode == 'train' or self.mode == 'valid':\n            return len(self.x)\n        elif self.mode == 'test':\n            return len(self.data)\n        else:\n            raise RuntimeError('MODE_ERROR')\n               \n    def __getitem__(self, idx):\n        if self.mode == 'train':\n            affine_seq_det = affine_seq.to_deterministic()\n            new_x_batch = affine_seq_det.augment_images(self.x[idx]*255)\n            new_x_batch = intensity_seq.augment_images(new_x_batch)/255\n            new_y_batch = affine_seq_det.augment_images(self.y[idx]*255)/255\n            return torch.from_numpy(new_x_batch).float(), torch.from_numpy(new_y_batch).float()\n        elif self.mode == 'valid':\n            return torch.from_numpy(self.x[idx]).float(), torch.from_numpy(self.y[idx]).float()\n        elif self.mode == 'test':\n            return torch.from_numpy(self.data[idx]).float()\n        else:\n            raise RuntimeError('MODE_ERROR')\n            \ndef make_loader(data, batch_size, num_workers=4, shuffle=False, transform=None, mode='train'):\n        return DataLoader(\n            dataset=ShipDataset(data, transform=transform, mode=mode),\n            shuffle=shuffle,\n            num_workers = num_workers,\n            batch_size = batch_size,\n            pin_memory=torch.cuda.is_available()\n        )",
      "execution_count": 45,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "47a024a662f85e6cbe936b1bce96d1c471533ddc"
      },
      "cell_type": "code",
      "source": "dl = my_DataLoader()\nx_train, y_train = dl.get_train()\nx_valid, y_valid = dl.get_valid()\n\n#Data augmentation\nx_train = np.append(x_train, [np.fliplr(x) for x in x_train], axis=0)\ny_train = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90fe1f1f430d483d851dc2dd2ceae9e2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": "\n",
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ecfc4876c7f4b11b94d3203e35e9b34"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": "\n",
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(IntProgress(value=0, max=18000), HTML(value='')))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dae1951a65774a98bffd68409b8fceac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": "\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bbc578c9bfb6b93b501b74b721a456c0a60ef0f0"
      },
      "cell_type": "code",
      "source": "train_loader = make_loader((x_train, y_train), batch_size=32, shuffle=True)\nvalid_loader = make_loader((x_valid, y_valid), num_workers=0, batch_size=64, mode='valid')",
      "execution_count": 59,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "438c676e325d9eea868ee669225fe6bae0eeb769"
      },
      "cell_type": "code",
      "source": "# encoding=utf8\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n################################################################################\n# train u-net & resnet model with Pytorch\n################################################################################\nclass BatchActivate(nn.Module):\n    def __init__(self, out_ch):\n        super(BatchActivate, self).__init__()\n        self.BA = nn.Sequential(\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True)\n        )\n        \n    def forward(self, x):\n        x = self.BA(x)\n        return x\n\nclass convolution_block(nn.Module):\n    def __init__(self, in_ch, out_ch, size, strides=(1,1), padding=(1,1), activation=True):\n        super(convolution_block, self).__init__()\n        \n        if activation == True:\n            self.CB = nn.Sequential(\n                nn.Conv2d(in_ch, out_ch, size, stride=strides, padding=(1, 1)),\n                BatchActivate(out_ch)\n            )\n        else:\n            self.CB = nn.Conv2d(in_ch, out_ch, size, stride=strides, padding=(1, 1))\n            \n    def forward(self, x):\n        x = self.CB(x)\n        return x\n    \nclass residual_block(nn.Module):\n    def __init__(self, out_ch, batch_activation=False):\n        super(residual_block, self).__init__()\n        self.BAC = nn.Sequential(\n            BatchActivate(out_ch),\n            convolution_block(out_ch, out_ch, (3,3)),\n            convolution_block(out_ch, out_ch, (3,3), activation=False)\n        )\n        self.BA = BatchActivate(out_ch)\n        self.batch_activation = batch_activation\n        \n    def forward(self, blockinput):\n        x = self.BAC(blockinput)\n        x = torch.add(blockinput, 1, x)\n        \n        if self.batch_activation:\n            return self.BA(x)\n        else:\n            return x\n        \nclass up_block(nn.Module):\n    def __init__(self, in_ch, out_ch, DropoutRatio=0.5, padding=0, output_padding=0):\n        super(up_block, self).__init__()\n        self.UP = nn.ConvTranspose2d(in_ch, out_ch, (3,3), (2,2), padding, output_padding)\n        self.DP = nn.Dropout(DropoutRatio)\n            \n        self.CR = nn.Sequential(\n            nn.Conv2d(out_ch*2, out_ch, (3,3), padding=(1, 1)),\n            residual_block(out_ch),\n            residual_block(out_ch, True)\n        )\n        \n    def forward(self, xb, xa):\n        xa = self.UP(xa)\n        x = torch.cat([xa, xb], dim=1)\n        x = self.DP(x)\n        x = self.CR(x)\n        return x\n        \nclass Res_UNet(nn.Module):\n    def __init__(self, start_neurons):\n        super(Res_UNet, self).__init__()\n             \n        self.d1 = nn.Sequential(\n            nn.Conv2d(1, start_neurons * 1, (3,3), padding=(1, 1)),\n            residual_block(start_neurons * 1),\n            residual_block(start_neurons * 1, True),\n        )\n        \n        self.d2 = nn.Sequential(\n            nn.Conv2d(start_neurons * 1, start_neurons * 2, (3,3), padding=(1, 1)),\n            residual_block(start_neurons * 2),\n            residual_block(start_neurons * 2, True),\n        )\n        \n        self.d3 = nn.Sequential(\n            nn.Conv2d(start_neurons * 2, start_neurons * 4, (3,3), padding=(1, 1)),\n            residual_block(start_neurons * 4),\n            residual_block(start_neurons * 4, True),\n        )\n        \n        self.d4 = nn.Sequential(\n            nn.Conv2d(start_neurons * 4, start_neurons * 8, (3,3), padding=(1, 1)),\n            residual_block(start_neurons * 8),\n            residual_block(start_neurons * 8, True),\n        )\n        \n        self.m = nn.Sequential(\n            nn.Conv2d(start_neurons * 8, start_neurons * 16, (3,3), padding=(1, 1)),\n            residual_block(start_neurons * 16),\n            residual_block(start_neurons * 16, True)\n        )\n        \n        self.up4 = up_block(start_neurons * 16, start_neurons * 8, padding=1, output_padding=1)\n        \n        self.up5 = up_block(start_neurons * 8, start_neurons * 4)\n        \n        self.up6 = up_block(start_neurons * 4, start_neurons * 2, padding=1, output_padding=1)\n        \n        self.up7 = up_block(start_neurons * 2, start_neurons * 1)\n        \n        self.conv2d_noactiv = nn.Conv2d(start_neurons * 1, 1, (1,1))\n        \n        #self.activ = nn.Softmax()\n        \n    def forward(self, x, DropOutRatio=0.5):\n        x1 = self.d1(x)\n        x1d = F.dropout(F.max_pool2d(x1, 2), DropOutRatio/2)\n        x2 = self.d2(x1d)\n        x2d = F.dropout(F.max_pool2d(x2, 2), DropOutRatio)\n        x3 = self.d3(x2d)\n        x3d = F.dropout(F.max_pool2d(x3, 2), DropOutRatio)\n        x4 = self.d4(x3d)\n        x4d = F.dropout(F.max_pool2d(x4, 2), DropOutRatio)\n        x5 = self.m(x4d)\n        x6 = self.up4(x4, x5)\n        x7 = self.up5(x3, x6)\n        x8 = self.up6(x2, x7)\n        x9 = self.up7(x1, x8)\n        x_noactiv = self.conv2d_noactiv(x9)\n        return x_noactiv",
      "execution_count": 48,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d1e5972b534849e0cec3405de9ba678904411afe"
      },
      "cell_type": "code",
      "source": "import torch.optim as optim\nfrom torch.autograd import Variable\n\nres_unet_noactiv = Res_UNet(16)\ncriterion = Lovasz_Loss()\n\nif torch.cuda.is_available():\n    res_unet_noactiv = res_unet_noactiv.cuda()\n    criterion = criterion.cuda()\n\n#optimizer= Adam(res_unet.parameters(), lr=0.01)\n\nresume_path = '../input/shanlins-s-pretrained-res-unet-v2/model_best.pth.tar'\nif os.path.isfile(resume_path):\n    checkpoint = torch.load(resume_path)\n    #start_epoch = checkpoint['epoch']\n    best_iou = checkpoint['best_iou']\n    res_unet_noactiv.load_state_dict(checkpoint['state_dict'])\n    #optimizer.load_state_dict(checkpoint['optimizer'])\n\noptimizer= Adam(res_unet_noactiv.parameters(), lr=0.0005)",
      "execution_count": 49,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "66be681ece2c0b85c8c0db265979c57cd7097569"
      },
      "cell_type": "code",
      "source": "def validation(model: nn.Module, criterion, valid_loader):\n    model.eval()\n    losses = []\n    iou = []\n    with torch.no_grad():\n        for inputs, targets in valid_loader:\n            inputs = torch.FloatTensor(inputs).cuda()\n            targets = torch.FloatTensor(targets).cuda()\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n            losses += [loss.item()]\n            iou += [my_iou_metric_2(get_numpy(targets), get_numpy(outputs))]\n\n        valid_loss = np.mean(losses)  # type: float\n\n        valid_iou = np.mean(iou)\n\n        metrics = {'val_loss': valid_loss, 'val_iou': valid_iou}\n    return metrics\n\ndef train(model, criterion, train_loader, optimizer, epoch, \n          report_each=10, valid_iou=0, fold=None):\n        model.train()\n        random.seed()\n        #scheduler.step(valid_iou)\n        losses = []\n        ious = []\n        tl = train_loader\n        \n        try:\n            mean_loss = 0\n            mean_iou = 0\n            for i, (inputs, targets) in enumerate(tl):\n                inputs = torch.FloatTensor(inputs).cuda()\n                targets = torch.FloatTensor(targets).cuda()\n                outputs = model(inputs)\n                loss = criterion(outputs, targets)\n                optimizer.zero_grad()\n                batch_size = inputs.size(0)\n                loss.backward()\n                optimizer.step()\n                losses += [loss.item()]\n                ious += [my_iou_metric_2(get_numpy(targets), get_numpy(outputs))]\n                mean_loss = np.mean(losses[-report_each:])\n                mean_iou = np.mean(ious[-report_each:])\n\n                if i % report_each == 0:\n                    print('Epoch: [{0}][{1}/{2}]\\t'\n                          'Loss {loss:.4f} ({loss_avg:.4f})\\t'\n                          'IOU {iou:.3f} ({iou_avg:.3f})'.format(\n                           epoch, i, len(tl), loss=losses[-1], loss_avg=mean_loss, iou=ious[-1], iou_avg=mean_iou))\n\n            metrics = {'train_loss': mean_loss, 'train_iou': mean_iou}\n            return metrics\n        \n        except KeyboardInterrupt:\n            print('Ctrl+C, saving snapshot')\n            print('done.')\n            return",
      "execution_count": 50,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5ea6b2cc9a581db9b2d156bf5671ac58a9e4a0e8",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "#scheduler = ReduceLROnPlateau(optimizer, mode='max', verbose=True, patience=5, factor=0.8, min_lr=0.0001)\n#model = nn.DataParallel(model, device_ids=None)\n\nn_epochs = 25\nstart_epoch = 0\nreport_each = 10\nvalid_losses = []\nvalid_ious = []\ntrain_losses = []\ntrain_ious = []\nvalid_iou = 0\nvalid_loss = 0\nfor epoch in range(start_epoch, n_epochs + 1):\n    \n    train_metrics = train(res_unet_noactiv, criterion, train_loader, optimizer, \n                          epoch, report_each, valid_iou)\n    valid_metrics = validation(res_unet_noactiv, criterion, valid_loader)\n\n    train_loss = train_metrics['train_loss']\n    train_iou = train_metrics['train_iou']\n    train_losses += [train_loss]\n    train_ious += [train_iou]\n    valid_loss = valid_metrics['val_loss']\n    valid_iou = valid_metrics['val_iou']\n    valid_losses += [valid_loss]\n    valid_ious += [valid_iou]\n    print('Epoch: [{0}][Validation]\\t' \n          'Val_Loss: {val_loss:.5f}\\t' \n          'Val_IOU: {val_iou:.5f}'.format(epoch, val_loss=valid_loss, val_iou=valid_iou))\n    is_best = best_iou < valid_iou\n    best_iou = max(valid_iou, best_iou)\n    save_checkpoint({\n        'epoch': epoch + 1,\n        'state_dict': res_unet_noactiv.state_dict(),\n        'best_iou': best_iou,\n        'optimizer': optimizer.state_dict(),\n    }, is_best)",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Epoch: [0][0/200]\tLoss 0.7282 (0.7282)\tIOU 0.719 (0.719)\nEpoch: [0][10/200]\tLoss 0.6239 (0.6685)\tIOU 0.750 (0.731)\nEpoch: [0][20/200]\tLoss 0.7955 (0.5555)\tIOU 0.703 (0.769)\nEpoch: [0][30/200]\tLoss 0.5425 (0.5459)\tIOU 0.706 (0.737)\nEpoch: [0][40/200]\tLoss 0.5809 (0.6313)\tIOU 0.722 (0.722)\nEpoch: [0][50/200]\tLoss 0.2796 (0.5048)\tIOU 0.859 (0.764)\nEpoch: [0][60/200]\tLoss 0.9835 (0.6006)\tIOU 0.634 (0.725)\nEpoch: [0][70/200]\tLoss 0.5315 (0.5168)\tIOU 0.731 (0.762)\nEpoch: [0][80/200]\tLoss 0.1858 (0.4296)\tIOU 0.891 (0.789)\nEpoch: [0][90/200]\tLoss 0.5137 (0.5270)\tIOU 0.722 (0.736)\nEpoch: [0][100/200]\tLoss 0.4844 (0.4317)\tIOU 0.734 (0.786)\nEpoch: [0][110/200]\tLoss 0.6982 (0.4849)\tIOU 0.653 (0.747)\nEpoch: [0][120/200]\tLoss 0.3991 (0.4585)\tIOU 0.759 (0.747)\nEpoch: [0][130/200]\tLoss 0.4573 (0.4998)\tIOU 0.781 (0.741)\nEpoch: [0][140/200]\tLoss 0.4962 (0.3822)\tIOU 0.788 (0.802)\nEpoch: [0][150/200]\tLoss 0.3142 (0.4108)\tIOU 0.812 (0.772)\nEpoch: [0][160/200]\tLoss 0.1937 (0.3870)\tIOU 0.922 (0.813)\nEpoch: [0][170/200]\tLoss 0.2597 (0.4350)\tIOU 0.831 (0.791)\nEpoch: [0][180/200]\tLoss 0.3772 (0.3973)\tIOU 0.787 (0.784)\nEpoch: [0][190/200]\tLoss 0.3465 (0.4871)\tIOU 0.781 (0.732)\nEpoch: [0][Validation]\tVal_Loss: 0.37608\tVal_IOU: 0.80433\nEpoch: [1][0/200]\tLoss 0.4322 (0.4322)\tIOU 0.756 (0.756)\nEpoch: [1][10/200]\tLoss 0.2829 (0.3894)\tIOU 0.859 (0.804)\nEpoch: [1][20/200]\tLoss 0.7227 (0.3798)\tIOU 0.694 (0.801)\nEpoch: [1][30/200]\tLoss 0.4094 (0.3863)\tIOU 0.809 (0.810)\nEpoch: [1][40/200]\tLoss 0.3681 (0.4142)\tIOU 0.831 (0.766)\nEpoch: [1][50/200]\tLoss 0.4601 (0.4558)\tIOU 0.753 (0.748)\nEpoch: [1][60/200]\tLoss 0.2750 (0.3992)\tIOU 0.841 (0.785)\nEpoch: [1][70/200]\tLoss 0.3170 (0.4392)\tIOU 0.809 (0.769)\nEpoch: [1][80/200]\tLoss 0.4366 (0.3929)\tIOU 0.741 (0.783)\nEpoch: [1][90/200]\tLoss 0.2719 (0.3157)\tIOU 0.841 (0.823)\nEpoch: [1][100/200]\tLoss 0.5448 (0.4125)\tIOU 0.669 (0.770)\nEpoch: [1][110/200]\tLoss 0.4154 (0.4401)\tIOU 0.734 (0.752)\nEpoch: [1][120/200]\tLoss 0.4743 (0.4173)\tIOU 0.763 (0.778)\nEpoch: [1][130/200]\tLoss 0.3263 (0.4327)\tIOU 0.800 (0.752)\nEpoch: [1][140/200]\tLoss 0.3414 (0.3634)\tIOU 0.816 (0.788)\nEpoch: [1][150/200]\tLoss 0.5107 (0.4039)\tIOU 0.747 (0.775)\nEpoch: [1][160/200]\tLoss 0.2299 (0.3763)\tIOU 0.853 (0.793)\nEpoch: [1][170/200]\tLoss 0.2984 (0.3739)\tIOU 0.781 (0.792)\nEpoch: [1][180/200]\tLoss 0.3295 (0.3832)\tIOU 0.838 (0.776)\nEpoch: [1][190/200]\tLoss 0.2279 (0.3509)\tIOU 0.844 (0.802)\nEpoch: [1][Validation]\tVal_Loss: 0.35681\tVal_IOU: 0.80433\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cd27e39a1ad7f38b811f4a6427fdad1d5401c7ad"
      },
      "cell_type": "code",
      "source": "resume_path = BEST_FILENAME\nif os.path.isfile(resume_path):\n    checkpoint = torch.load(resume_path)\n    start_epoch = checkpoint['epoch']\n    best_iou = checkpoint['best_iou']\n    res_unet_noactiv.load_state_dict(checkpoint['state_dict'])\n    #optimizer.load_state_dict(checkpoint['optimizer'])",
      "execution_count": 52,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "225d0c2b80e5219c2c8e48d59d782ae58f872bfb"
      },
      "cell_type": "code",
      "source": "optimizer= Adam(res_unet_noactiv.parameters(), lr=0.0001)\n#scheduler = ReduceLROnPlateau(optimizer, mode='max', verbose=True, patience=5, factor=0.8, min_lr=0.0001)\n#model = nn.DataParallel(model, device_ids=None)\n\nn_epochs = 40\nreport_each = 10\nvalid_losses = []\nvalid_ious = []\ntrain_losses = []\ntrain_ious = []\nvalid_iou = 0\nvalid_loss = 0\nfor epoch in range(start_epoch, n_epochs + 1):\n    \n        train_metrics = train(res_unet_noactiv, criterion, train_loader, optimizer, \n                              epoch, report_each, valid_iou)\n        valid_metrics = validation(res_unet_noactiv, criterion, valid_loader)\n        \n        train_loss = train_metrics['train_loss']\n        train_iou = train_metrics['train_iou']\n        train_losses += [train_loss]\n        train_ious += [train_iou]\n        valid_loss = valid_metrics['val_loss']\n        valid_iou = valid_metrics['val_iou']\n        valid_losses += [valid_loss]\n        valid_ious += [valid_iou]\n        print('Epoch: [{0}][Validation]\\t' \n              'Val_Loss: {val_loss:.5f}\\t' \n              'Val_IOU: {val_iou:.5f}'.format(epoch, val_loss=valid_loss, val_iou=valid_iou))\n        is_best = best_iou < valid_iou\n        best_iou = max(valid_iou, best_iou)\n        save_checkpoint({\n            'epoch': epoch + 1,\n            'state_dict': res_unet_noactiv.state_dict(),\n            'best_iou': best_iou,\n            'optimizer': optimizer.state_dict(),\n        }, is_best)",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Epoch: [2][0/200]\tLoss 0.3929 (0.3929)\tIOU 0.759 (0.759)\nEpoch: [2][10/200]\tLoss 0.3904 (0.3436)\tIOU 0.762 (0.806)\nEpoch: [2][20/200]\tLoss 0.4000 (0.3918)\tIOU 0.734 (0.785)\nEpoch: [2][30/200]\tLoss 0.3724 (0.3598)\tIOU 0.781 (0.805)\nEpoch: [2][40/200]\tLoss 0.2038 (0.4154)\tIOU 0.872 (0.773)\nEpoch: [2][50/200]\tLoss 0.2269 (0.3766)\tIOU 0.856 (0.794)\nEpoch: [2][60/200]\tLoss 0.3115 (0.3731)\tIOU 0.803 (0.777)\nEpoch: [2][70/200]\tLoss 0.3182 (0.4246)\tIOU 0.791 (0.760)\nEpoch: [2][80/200]\tLoss 0.3359 (0.2968)\tIOU 0.794 (0.834)\nEpoch: [2][90/200]\tLoss 0.5327 (0.3669)\tIOU 0.716 (0.789)\nEpoch: [2][100/200]\tLoss 0.2617 (0.3846)\tIOU 0.837 (0.778)\nEpoch: [2][110/200]\tLoss 0.3426 (0.3282)\tIOU 0.809 (0.823)\nEpoch: [2][120/200]\tLoss 0.2519 (0.4148)\tIOU 0.850 (0.764)\nEpoch: [2][130/200]\tLoss 0.6080 (0.3924)\tIOU 0.634 (0.761)\nEpoch: [2][140/200]\tLoss 0.4080 (0.3632)\tIOU 0.747 (0.790)\nEpoch: [2][150/200]\tLoss 0.4484 (0.4289)\tIOU 0.753 (0.766)\nEpoch: [2][160/200]\tLoss 0.3821 (0.4690)\tIOU 0.775 (0.736)\nEpoch: [2][170/200]\tLoss 0.4798 (0.4105)\tIOU 0.706 (0.756)\nEpoch: [2][180/200]\tLoss 0.3111 (0.3350)\tIOU 0.831 (0.797)\nEpoch: [2][190/200]\tLoss 0.2585 (0.3711)\tIOU 0.866 (0.780)\nEpoch: [2][Validation]\tVal_Loss: 0.35220\tVal_IOU: 0.80120\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cc45d408a40354ab6609f7c41675eaaac979ac44"
      },
      "cell_type": "code",
      "source": "x_test = dl.get_test_x()\ntest_loader = make_loader(x_test, batch_size=64, mode='test')",
      "execution_count": 54,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "08a07a21cbdaa905f726c1a3f09510d967f7e59e"
      },
      "cell_type": "code",
      "source": "resume_path = BEST_FILENAME\nif os.path.isfile(resume_path):\n    checkpoint = torch.load(resume_path)\n    res_unet_noactiv.load_state_dict(checkpoint['state_dict'])\n    #optimizer.load_state_dict(checkpoint['optimizer'])",
      "execution_count": 55,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "91f0108ca5e7b6f88b4f54d5a82bec6740a685d4"
      },
      "cell_type": "code",
      "source": "res_unet_noactiv.eval()\noutput_list = []\nwith torch.no_grad():\n    for i, (inputs, targets) in enumerate(valid_loader):\n        inputs = torch.FloatTensor(inputs).cuda()\n        outputs = res_unet_noactiv(inputs)\n        output_list += [get_numpy(outputs)]\n        if i % report_each == 0:\n            print('iteration: [{0}/{1}]'.format(i, len(valid_loader)))\noutput_valid = np.concatenate(output_list, 0)",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": "iteration: [0/16]\niteration: [10/16]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0f3a7494b35bba062ab316e827771c0fdb29b53c"
      },
      "cell_type": "code",
      "source": "label = y_valid.swapaxes(2,3).swapaxes(1,2)",
      "execution_count": 68,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c6b9ba9e9fa80fcc3ab842ba17bf93a33ea7003b"
      },
      "cell_type": "code",
      "source": "## Scoring for last model, choose threshold by validation data \nthresholds_ori = np.linspace(0.3, 0.7, 31)\n# Reverse sigmoid function: Use code below because the  sigmoid activation was removed\nthresholds = np.log(thresholds_ori/(1-thresholds_ori)) \nious = np.array([my_iou_metric_thre(label, output_valid, threshold) for threshold in tqdm_notebook(thresholds)])",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(IntProgress(value=0, max=31), HTML(value='')))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a53894dbe3124595b0c497b498d97818"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": "\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c377da1769325a926afca009f87685a865f8dcbc"
      },
      "cell_type": "code",
      "source": "threshold_best_index = np.argmax(ious) \niou_best = ious[threshold_best_index]\nthreshold_best = thresholds[threshold_best_index]\n\nplt.plot(thresholds, ious)\nplt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"IoU\")\nplt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\nplt.legend()",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 72,
          "data": {
            "text/plain": "<matplotlib.legend.Legend at 0x7fddc5db8a58>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "23286e49e518a5f4f4f921a52e0fb727229a3d64"
      },
      "cell_type": "code",
      "source": "res_unet_noactiv.eval()\noutput_list = []\nwith torch.no_grad():\n    for i, inputs in enumerate(test_loader):\n        inputs_1 = torch.FloatTensor(inputs)\n        inputs_2 = torch.flip(inputs_1, [3])\n        inputs_1, inputs_2 = inputs_1.cuda(), inputs_2.cuda()\n        outputs_1 = res_unet_noactiv(inputs_1)\n        outputs_2 = res_unet_noactiv(inputs_2)\n        outputs_2 = torch.flip(outputs_2, [3])\n        outputs = 0.5 * (outputs_1 + outputs_2)\n        output_list += [get_numpy(outputs)]\n        if i % report_each == 0:\n            print('iteration: [{0}/{1}]'.format(i, len(test_loader)))\noutput_test = np.concatenate(output_list, 0)",
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": "iteration: [0/282]\niteration: [10/282]\niteration: [20/282]\niteration: [30/282]\niteration: [40/282]\niteration: [50/282]\niteration: [60/282]\niteration: [70/282]\niteration: [80/282]\niteration: [90/282]\niteration: [100/282]\niteration: [110/282]\niteration: [120/282]\niteration: [130/282]\niteration: [140/282]\niteration: [150/282]\niteration: [160/282]\niteration: [170/282]\niteration: [180/282]\niteration: [190/282]\niteration: [200/282]\niteration: [210/282]\niteration: [220/282]\niteration: [230/282]\niteration: [240/282]\niteration: [250/282]\niteration: [260/282]\niteration: [270/282]\niteration: [280/282]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0593fbd2dbd25dab97df4998eb0550bbb89372a3"
      },
      "cell_type": "code",
      "source": "\"\"\"\nused for converting the decoded image to rle mask\nFast compared to previous one\n\"\"\"\ndef rle_encode(im):\n    '''\n    im: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = im.flatten(order = 'F')\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)",
      "execution_count": 77,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6751d1f5d2910b0d0397e8e551834b16c0d1e580"
      },
      "cell_type": "code",
      "source": "test_df = dl.get_test_df()",
      "execution_count": 74,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "68041a48e44bfc5cd13403ce7ef6caa09e94634d"
      },
      "cell_type": "code",
      "source": "pred_dict = {idx: rle_encode(output_test[i] > threshold_best) for i, idx in enumerate(tqdm_notebook(test_df.index.values))}",
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(IntProgress(value=0, max=18000), HTML(value='')))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4583920e93694ca48e8b437dc6531ef3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d508d564403cd37916cdc85908653f276cf5813e"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}