{
  "cells": [
    {
      "metadata": {
        "_uuid": "54643e32b4132d15df20d55f2b9ee09efc2c51a8"
      },
      "cell_type": "markdown",
      "source": "# Libraries"
    },
    {
      "metadata": {
        "_uuid": "b15761a022f76bb50db1bb55c21b59a3f1c88261",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\nimport sys\nimport random\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-white')\nimport seaborn as sns\nsns.set_style(\"white\")\n\nimport shutil\n\n%matplotlib inline\n\n# import cv2\nfrom sklearn.model_selection import train_test_split\n\nfrom scipy import ndimage\n\nfrom tqdm import tqdm_notebook #, tnrange\n#from itertools import chain\nfrom skimage.io import imread, imshow #, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\nfrom skimage import filters\n\nfrom imgaug import augmenters as iaa\n\nfrom tqdm import tqdm\nfrom pathlib import Path\n\nimport cv2\nfrom sklearn.model_selection import StratifiedKFold\nimport torch\nfrom torch import nn\nfrom torch import Tensor\nfrom torch.optim import Adam, SGD\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.backends.cudnn as cudnn\nimport torch.backends.cudnn\nfrom torch.autograd import Variable\nfrom torch.nn import functional as F\nfrom torchvision.transforms import ToTensor, ToPILImage, Normalize, Compose\n\nimport PIL\n\nfrom datetime import datetime\nimport json\nimport gc\n\nimport time\n#t_start = time.time()",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "99e7207d6aec7d921e4b8ad4f30d310d2346216a"
      },
      "cell_type": "markdown",
      "source": "# Global variable"
    },
    {
      "metadata": {
        "_uuid": "73cc76d8506e96b912600406fa5ceeb47083978a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "TRAIN_IMG_PATH = \"../input/tgs-salt-identification-challenge/train/images/\"\nTEST_IMG_PATH = \"../input/tgs-salt-identification-challenge/test/images/\"\nDEPTH_PATH = \"../input/tgs-salt-identification-challenge/depths.csv\"\nTRAIN_MASK_PATH = \"../input/tgs-salt-identification-challenge/train/masks/\"\nTRAIN_INFO_PATH = \"../input/tgs-salt-identification-challenge/train.csv\"\nFILENAME = \"checkpoint.pth.tar\"\nBEST_FILENAME = \"model_best.pth.tar\"\n\n# basic parameters\nIMG_ORI_SIZE = 101\nIMG_TAR_SIZE = 128\nSCALE = 1\n\n# Model parameters\nSTART_NEURONS = 16\nDROPOUT_RATIO = 0.5\n\nLOAD_CHECKPONT = False\n\nINPUT_CHANNEL = 1\n\nMODEL1_ADAM_LR = 0.01\nMODEL1_EPOCHS = 100\nMODEL1_BATCH_SIZE = 64\nMODEL1_STEPS_PER_EPOCH_TRAIN = 200\nMODEL1_LOSS = 'binary_crossentropy'\n\nMODEL2_ADAM_LR = 0.01\nMODEL2_EPOCHS = 100\nMODEL2_BATCH_SIZE = 64\nMODEL2_STEPS_PER_EPOCH_TRAIN = 200\nMODEL2_LOSS = 'lovasz_loss'\n\n# ReduceLROnPlateau parameters\nMODEL1_REDUCE_FACTOR = 0.5\nMODEL1_REDUCE_PATIENT = 5\n\nMODEL2_REDUCE_FACTOR = 0.5\nMODEL2_REDUCE_PATIENT = 5\n\n# DICE_BCE_LOSS Parameters\nBCE_WEIGHT = 1\nDICE_WEIGHT = 0\n\n# Augmentation Parmeters\nAUG = True\nFIT_METHOD = 'resize'\nPAD_METHOD = 'edge'\nKFOLD = False\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "aa113e7f4cabb11b9a14afc2151e96ff664ef7ed",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# encoding=utf8\nimport cv2\nimport numpy as np\nfrom torch import nn\nfrom functools import reduce\n\n################################################################################\n# related functions & loss functions\n################################################################################\n\n\ndef upsample(img):\n    if IMG_ORI_SIZE == IMG_TAR_SIZE:\n        return img\n    return cv2.resize(img, (IMG_TAR_SIZE, IMG_TAR_SIZE))\n\n\ndef downsample(img):\n    if IMG_ORI_SIZE == IMG_TAR_SIZE:\n        return img\n    return cv2.resize(img, (IMG_ORI_SIZE, IMG_ORI_SIZE))\n\n\ndef add_depth_channels(image_array, depth):\n    image_array[:,:,1] = depth\n    image_array[:,:,2] = image_array[:,:,0] * image_array[:,:,1]\n    return image_array\n\n\nclass MyEncoder(json.JSONEncoder):\n    def default(self, obj):\n        if isinstance(obj, np.integer):\n            return int(obj)\n        elif isinstance(obj, np.floating):\n            return float(obj)\n        elif isinstance(obj, np.ndarray):\n            return obj.tolist()\n        else:\n            return super(MyEncoder, self).default(obj)\n\n        \ndef write_event(log, step: int, **data):\n    data['step'] = step\n    data['dt'] = datetime.now().isoformat()\n    log.write(json.dumps(data, sort_keys=True, cls=MyEncoder))\n    log.write('\\n')\n    log.flush()\n\n    \ndef get_variable(x):\n    \"\"\" Converts tensors to cuda, if available. \"\"\"\n    if torch.cuda.is_available():\n        return x.cuda()\n    return x\n\n\ndef get_numpy(x):\n    \"\"\" Get numpy array for both cuda and not. \"\"\"\n    if torch.cuda.is_available():\n        return x.cpu().data.numpy()\n    return x.data.numpy()\n\n\ndef get_true_target(targets):\n    truth_image = targets.squeeze(3).sum(2).sum(1) > 0\n    return truth_image\n  \n\ndef get_logits_outputs(outputs_image, outputs_pixel):\n    batch_size, C, H, W = outputs_pixel.shape\n    zero_mask = torch.zeros([batch_size, C, H, W], dtype=torch.float).to(device)\n    empty_label = outputs_image<0\n    outputs_pixel[empty_label] = zero_mask[empty_label]\n    return outputs_pixel\n\n\ndef iou_numpy(outputs, labels):\n    SMOOTH = 1e-6\n    labels = labels.squeeze(1)\n    outputs = outputs.squeeze(1)\n    \n    intersection = (outputs & labels).sum((1, 2))\n    union = (outputs | labels).sum((1, 2))\n    \n    iou = (intersection + SMOOTH) / (union + SMOOTH)\n    \n    thresholded = np.ceil(np.clip(20 * (iou - 0.5), 0, 10)) / 10\n    \n    return thresholded.mean()\n\n\ndef my_iou_metric(label, pred):\n    return iou_numpy(pred > 0.5, label>0.5)\n\n\ndef my_iou_metric_2(label, pred):\n    return iou_numpy(pred > 0, label>0.5)\n\n\ndef my_iou_metric_pad(label, pred):\n    pad_size = (IMG_TAR_SIZE-SCALE*IMG_ORI_SIZE)//2\n    return iou_numpy(pred[:,:,pad_size:-pad_size-1,pad_size+1:-pad_size]>0,label[:,:,pad_size:-pad_size-1,pad_size+1:-pad_size]>0.5)\n\n    \ndef save_checkpoint(state, is_best, filename):\n    check_filename = 'checkpoint_{}_resize.pth.tar'.format(filename)\n    torch.save(state, check_filename)\n    if is_best:\n        shutil.copyfile(check_filename, 'model_best_{}_resize.pth.tar'.format(filename))\n        \n\nclass EarlyStopping(object):\n    def __init__(self, mode='min', min_delta=0, patience=10):\n        self.mode = mode\n        self.min_delta = min_delta\n        self.patience = patience\n        self.best = None\n        self.num_bad_epochs = 0\n        self.is_better = None\n        self._init_is_better(mode, min_delta)\n\n        if patience == 0:\n            self.is_better = lambda a, b: True\n\n    def step(self, metrics):\n        if self.best is None:\n            self.best = metrics\n            return False\n\n        if np.isnan(metrics):\n            return True\n\n        if self.is_better(metrics, self.best):\n            self.num_bad_epochs = 0\n            self.best = metrics\n        else:\n            self.num_bad_epochs += 1\n\n        if self.num_bad_epochs >= self.patience:\n            return True\n\n        return False\n\n    def _init_is_better(self, mode, min_delta):\n        if mode not in {'min', 'max'}:\n            raise ValueError('mode ' + mode + ' is unknown!')\n        if mode == 'min':\n            self.is_better = lambda a, best: a < best - min_delta\n        if mode == 'max':\n            self.is_better = lambda a, best: a > best + min_delta\n",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "951cbf65518e980d4d9cc3595458a9b366374f58",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from __future__ import print_function, division\n\nimport torch\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nimport numpy as np\ntry:\n    from itertools import  ifilterfalse\nexcept ImportError: # py3k\n    from itertools import  filterfalse\n    \n\nclass DiceLoss(nn.Module):\n    def __init__(self, smooth=0, eps=1e-7):\n        super(DiceLoss, self).__init__()\n        self.smooth = smooth\n        self.eps = eps\n\n    def forward(self, output, target):\n        output = torch.sigmoid(output)\n        return 1 - (2 * torch.sum(output * target) + self.smooth) / (torch.sum(output) + torch.sum(target) + self.smooth + self.eps)\n\n\nclass Dice_Bce_Loss(nn.Module):\n    def __init__(self, smooth=0, eps=1e-7, dice_weight=0.5, \n                 dice_loss=None, bce_weight=0.9, bce_loss=None):\n        super(Dice_Bce_Loss, self).__init__()\n        self.smooth = smooth\n        self.eps = eps\n        self.dice_weight = dice_weight\n        self.bce_weight = bce_weight\n        self.bce_loss = bce_loss\n        self.dice_loss = dice_loss\n        \n        if self.bce_loss is None:\n            self.bce_loss = F.binary_cross_entropy_with_logits\n        if self.dice_loss is None:\n            self.dice_loss = DiceLoss(smooth, eps)\n            \n        self.activation = torch.sigmoid\n            \n    def forward(self, output, target):\n        output = self.activation(output)\n        return self.dice_weight * self.dice_loss(output, target) + self.bce_weight * self.bce_loss(output, target)\n\n\nclass FocalLoss(nn.Module):\n    def __init__(self, alpha=0.5, gamma=2, logits=True, reduce=True):\n        super(FocalLoss, self).__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.logits = logits\n        self.reduce = reduce\n\n    def forward(self, inputs, targets):\n        if self.logits:\n            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n        else:\n            BCE_loss = F.binary_cross_entropy(inputs, targets, reduction='none')\n        pt = torch.exp(-BCE_loss)\n        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n\n        if self.reduce:\n            return torch.mean(F_loss)\n        else:\n            return F_loss\n        \n\n\"\"\"\nLovasz-Softmax and Jaccard hinge loss in PyTorch\nMaxim Berman 2018 ESAT-PSI KU Leuven (MIT License)\n\"\"\"\ndef lovasz_grad(gt_sorted):\n    \"\"\"\n    Computes gradient of the Lovasz extension w.r.t sorted errors\n    See Alg. 1 in paper\n    \"\"\"\n    p = len(gt_sorted)\n    gts = gt_sorted.sum()\n    intersection = gts - gt_sorted.cumsum(0)\n    union = gts + (1 - gt_sorted).cumsum(0)\n    jaccard = 1. - intersection / union\n    if p > 1: # cover 1-pixel case\n        jaccard[1:p] = jaccard[1:p] - jaccard[0:-1]\n    return jaccard\n\n\n# --------------------------- BINARY LOSSES ---------------------------\n\n\ndef lovasz_hinge(logits, labels, per_image=True, ignore=None):\n    \"\"\"\n    Binary Lovasz hinge loss\n      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n      per_image: compute the loss per image instead of per batch\n      ignore: void class id\n    \"\"\"\n    if per_image:\n        loss = mean(lovasz_hinge_flat(*flatten_binary_scores(log.unsqueeze(0), lab.unsqueeze(0), ignore))\n                          for log, lab in zip(logits, labels))\n    else:\n        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n    return loss\n\n\ndef lovasz_hinge_flat(logits, labels):\n    \"\"\"\n    Binary Lovasz hinge loss\n      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n      labels: [P] Tensor, binary ground truth labels (0 or 1)\n      ignore: label to ignore\n    \"\"\"\n    if len(labels) == 0:\n        # only void pixels, the gradients should be 0\n        return logits.sum() * 0.\n    signs = 2. * labels.float() - 1.\n    errors = (1. - logits * signs)\n    errors_sorted, perm = torch.sort(errors, dim=0, descending=True)\n    perm = perm.data\n    gt_sorted = labels[perm]\n    grad = lovasz_grad(gt_sorted)\n    loss = torch.dot(F.elu(errors_sorted)+1, grad)\n    return loss\n\n\ndef flatten_binary_scores(scores, labels, ignore=None):\n    \"\"\"\n    Flattens predictions in the batch (binary case)\n    Remove labels equal to 'ignore'\n    \"\"\"\n    scores = scores.view(-1)\n    labels = labels.view(-1)\n    if ignore is None:\n        return scores, labels\n    valid = (labels != ignore)\n    vscores = scores[valid]\n    vlabels = labels[valid]\n    return vscores, vlabels\n\n# --------------------------- HELPER FUNCTIONS ---------------------------\n\ndef mean(l, ignore_nan=False, empty=0):\n    \"\"\"\n    nanmean compatible with generators.\n    \"\"\"\n    l = iter(l)\n    if ignore_nan:\n        l = ifilterfalse(np.isnan, l)\n    try:\n        n = 1\n        acc = next(l)\n    except StopIteration:\n        if empty == 'raise':\n            raise ValueError('Empty mean')\n        return empty\n    for n, v in enumerate(l, 2):\n        acc += v\n    if n == 1:\n        return acc\n    return acc / n\n\n\nclass BCE_Lovaz_Loss(nn.Module):\n    def __init__(self, per_image=True, ignore=None):\n        super(BCE_Lovaz_Loss, self).__init__()\n        self.per_image = per_image\n        self.ignore = ignore\n        \n    def forward(self, logits, targets):\n        loss_1 = lovasz_hinge(logits.squeeze(1), targets.squeeze(1), self.per_image, self.ignore)\n        loss_2 = nn.BCEWithLogitsLoss()(logits, targets)\n        loss = loss_1 + loss_2\n        return loss\n    \nclass Lovaz_Loss(nn.Module):\n    def __init__(self, per_image=True, ignore=None):\n        super(Lovaz_Loss, self).__init__()\n        self.per_image = per_image\n        self.ignore = ignore\n        \n    def forward(self, logits, targets):\n        loss = lovasz_hinge(logits.squeeze(1), targets.squeeze(1), self.per_image, self.ignore)\n        return loss\n\nclass Fuse_Loss(nn.Module):\n    def __init__(self, pixel_loss_func=Lovaz_Loss(), weight_image=0.05, weight_pixel=0.5, weight=1):\n        super(Fuse_Loss, self).__init__()\n        self.image_loss_func = F.cross_entropy\n        self.pixel_loss_func = pixel_loss_func\n        self.activation = torch.sigmoid\n        self.weight_image = weight_image\n        self.weight_pixel = weight_pixel\n        self.weight = weight\n        \n    def forward(self, logits, logit_pixel, logit_image, truth_pixel, truth_image):\n        pixel_non_empty = logit_pixel[truth_image,:,:,:]\n        mask_non_empty = truth_pixel[truth_image,:,:,:]\n        loss_pixel = self.pixel_loss_func(pixel_non_empty, mask_non_empty)\n        truth_image = truth_image.type(torch.LongTensor).to(device)\n        loss_image = self.image_loss_func(logit_image, truth_image, reduction='elementwise_mean')\n        loss = self.pixel_loss_func(logits, truth_pixel)\n        return self.weight_pixel*loss_pixel + self.weight_image*loss_image + self.weight*loss",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "528f191a441809dd782a3dbf9d425284b9dba18a"
      },
      "cell_type": "code",
      "source": "import torch\nimport math\nfrom torch.optim.lr_scheduler import _LRScheduler\n\nclass CosineAnnealingLR_with_Restart(_LRScheduler):\n    \"\"\"Set the learning rate of each parameter group using a cosine annealing\n    schedule, where :math:`\\eta_{max}` is set to the initial lr and\n    :math:`T_{cur}` is the number of epochs since the last restart in SGDR:\n    .. math::\n        \\eta_t = \\eta_{min} + \\frac{1}{2}(\\eta_{max} - \\eta_{min})(1 +\n        \\cos(\\frac{T_{cur}}{T_{max}}\\pi))\n    When last_epoch=-1, sets initial lr as lr.\n    It has been proposed in\n    `SGDR: Stochastic Gradient Descent with Warm Restarts`_. The original pytorch\n    implementation only implements the cosine annealing part of SGDR,\n    I added my own implementation of the restarts part.\n    Args:\n        optimizer (Optimizer): Wrapped optimizer.\n        T_max (int): Maximum number of iterations.\n        T_mult (float): Increase T_max by a factor of T_mult\n        eta_min (float): Minimum learning rate. Default: 0.\n        last_epoch (int): The index of last epoch. Default: -1.\n        model (pytorch model): The model to save.\n        out_dir (str): Directory to save snapshots\n        take_snapshot (bool): Whether to save snapshots at every restart\n    .. _SGDR\\: Stochastic Gradient Descent with Warm Restarts:\n        https://arxiv.org/abs/1608.03983\n    \"\"\"\n\n    def __init__(self, optimizer, T_max, T_mult, model, out_dir, take_snapshot, eta_min=0, last_epoch=-1):\n        self.T_max = T_max\n        self.T_mult = T_mult\n        self.Te = self.T_max\n        self.eta_min = eta_min\n        self.current_epoch = last_epoch\n\n        self.model = model\n        self.out_dir = out_dir\n        self.take_snapshot = take_snapshot\n\n        self.lr_history = []\n\n        super(CosineAnnealingLR_with_Restart, self).__init__(optimizer, last_epoch)\n\n    def get_lr(self):\n        new_lrs = [self.eta_min + (base_lr - self.eta_min) *\n                   (1 + math.cos(math.pi * self.current_epoch / self.Te)) / 2\n                   for base_lr in self.base_lrs]\n\n        self.lr_history.append(new_lrs)\n        return new_lrs\n\n    def step(self, epoch=None):\n        if epoch is None:\n            epoch = self.last_epoch + 1\n        self.last_epoch = epoch\n        self.current_epoch += 1\n\n        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n            param_group['lr'] = lr\n\n        ## restart\n        if self.current_epoch == self.Te:\n            print(\"restart at epoch {:03d}\".format(self.last_epoch + 1))\n\n            if self.take_snapshot:\n                torch.save({\n                    'epoch': self.T_max,\n                    'state_dict': self.model.state_dict()\n                }, self.out_dir + \"Weight/\" + 'snapshot_e_{:03d}.pth.tar'.format(self.T_max))\n\n            ## reset epochs since the last reset\n            self.current_epoch = 0\n\n            ## reset the next goal\n            self.Te = int(self.Te * self.T_mult)\n            self.T_max = self.T_max + self.Te",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f6879d5d3bbb6c70fd2c25908083b690e59c13a8",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import imgaug as ia\nfrom imgaug import augmenters as iaa\nimport numpy as np\n\nia.seed(2018)\n\ndef _standardize(img):\n    return (img - img.map(np.mean)) / img.map(np.std)\n\naffine_seq = iaa.Sequential([\n    # General\n    iaa.SomeOf((1, 2),\n               [iaa.Fliplr(0.5),\n                iaa.Noop(),\n                ]),\n    iaa.Affine(rotate=(-5, 5), mode='reflect'),\n    iaa.Crop(px=(0, 10)),\n], random_order=True)\n\nintensity_seq = iaa.Sequential([\n    #iaa.Invert(0.3),\n    iaa.Sometimes(0.3, iaa.ContrastNormalization((0.5, 1.5))),\n    iaa.OneOf([\n        iaa.Noop(),\n        iaa.Sequential([\n            iaa.OneOf([\n                iaa.Add((-10, 10)),\n                iaa.AddElementwise((-10, 10)),\n                iaa.Multiply((0.95, 1.05)),\n                iaa.MultiplyElementwise((0.95, 1.05)),\n            ]),\n        ]),\n        iaa.OneOf([\n            iaa.GaussianBlur(sigma=(0.0, 1.0)),\n            iaa.AverageBlur(k=(2, 5)),\n            #iaa.MedianBlur(k=(3, 5))\n        ])\n    ])\n], random_order=False)\n\ntta_intensity_seq = iaa.Sequential([\n    iaa.Noop()\n], random_order=False)\n\ndef resize_pad_seq(pad_size):\n    seq = iaa.Sequential([\n        affine_seq,\n        iaa.Scale({'height': IMG_ORI_SIZE*SCALE, 'width': IMG_ORI_SIZE*SCALE}),\n        iaa.Pad(px=(pad_size, 0, pad_size+1, 0), pad_mode='edge', keep_size=False),\n        iaa.Pad(px=(0, pad_size, 0, pad_size+1), pad_mode='edge', keep_size=False)\n    ], random_order=False)\n    return seq\n\ndef resize_pad_seq_eval(pad_size):\n    seq = iaa.Sequential([\n        iaa.Scale({'height': IMG_ORI_SIZE*SCALE, 'width': IMG_ORI_SIZE*SCALE}),\n        iaa.Pad(px=(pad_size, 0, pad_size+1, 0), pad_mode='edge', keep_size=False),\n        iaa.Pad(px=(0, pad_size, 0, pad_size+1), pad_mode='edge', keep_size=False)\n    ], random_order=False)\n    return seq\n\ndef resize_seq():\n    seq = iaa.Sequential([\n        affine_seq,\n        iaa.Scale({'height': IMG_TAR_SIZE, 'width': IMG_TAR_SIZE})\n    ], random_order=False)\n    return seq\n\ndef resize_seq_eval():\n    seq = iaa.Sequential([\n        iaa.Scale({'height': IMG_TAR_SIZE, 'width': IMG_TAR_SIZE})\n    ], random_order=False)\n    return seq",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8cbfed0014f8791e5d308d3cb6107c45866bef6b",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# encoding=utf8\nimport numpy as np\nimport pandas as pd\nfrom functools import partial\nimport cv2\nfrom tqdm import tqdm_notebook\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nimport torch\nfrom torch import nn\nfrom torch.optim import Adam\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.backends.cudnn as cudnn\nimport torch.backends.cudnn\nfrom torch.autograd import Variable\nfrom torch.nn import functional as F\nfrom torchvision.transforms import ToTensor, Normalize, Compose\n\n## convert salt coverage to class\ndef cov_to_class_1(mask):\n    border = 10\n    outer = np.zeros((101-2*border, 101-2*border), np.float32)\n    outer = cv2.copyMakeBorder(outer, border, border, border, border, borderType = cv2.BORDER_CONSTANT, value = 1)\n\n    cover = (mask>0.5).sum()\n    if cover < 8:\n        return 0 # empty\n    if cover == ((mask*outer) > 0.5).sum():\n        return 1 #border\n    if np.all(mask==mask[0]):\n        return 2 #vertical\n\n    percentage = cover/(101*101)\n    if percentage < 0.15:\n        return 3\n    elif percentage < 0.25:\n        return 4\n    elif percentage < 0.50:\n        return 5\n    elif percentage < 0.75:\n        return 6\n    else:\n        return 7\n    \ndef cov_to_class_2(val):    \n    for i in range(0, 11):\n        if val * 10 <= i :\n            return i\n\n## used to load data from data files\nclass my_DataLoader:\n    def __init__(self, train=False, test=False, Kfold=False, test_size=0.2):\n        self.test = test\n        self.train = train\n        self.Kfold = Kfold\n        self.test_size = test_size\n        self.num_fold = int(1/test_size)\n            \n        train_df, self.test_df = self._load_depth()\n        \n        if self.train:\n            self._load_image_mask(train_df)\n            train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(IMG_ORI_SIZE, 2)\n            train_df[\"coverage_class\"] = train_df.masks.map(cov_to_class_1)\n            self.x_train, self.x_valid, self.y_train, self.y_valid = self._get_train_test_split(train_df, self.Kfold, self.num_fold)\n            \n        if self.test:\n            test_df['images'] = self._load_image_test(self.test_df)\n            self.x_test = np.array(self.test_df.images.tolist()).reshape(-1, IMG_ORI_SIZE, IMG_ORI_SIZE, 1)\n\n    @staticmethod\n    def _load_image_mask(train_df):\n        # load image data & mask data\n        train_df['images'] = [np.array(cv2.imread(TRAIN_IMG_PATH + \"{}.png\".format(idx), 0)) for idx in tqdm_notebook(train_df.index)]\n        train_df['masks'] = [np.array(cv2.imread(TRAIN_MASK_PATH + \"{}.png\".format(idx), 0)) for idx in tqdm_notebook(train_df.index)]\n        # Normalize image vectors\n        #train_df['images'] /= 255\n        #train_df['masks'] /= 255\n        \n    @staticmethod\n    def _load_image_test(test_df):\n        return [np.array(cv2.imread(TEST_IMG_PATH + \"{}.png\".format(idx), 0)) for idx in tqdm_notebook(test_df.index)]\n\n    @staticmethod\n    def _load_depth():\n        train_df = pd.read_csv(TRAIN_INFO_PATH, index_col=\"id\", usecols=[0])\n        depths_df = pd.read_csv(DEPTH_PATH, index_col=\"id\")\n        depths_df['z'] = depths_df['z'].astype('float')\n        train_df = train_df.join(depths_df)\n        test_df = depths_df[~depths_df.index.isin(train_df.index)]\n        return train_df, test_df\n\n    ## get train & validation split stratified by salt coverage\n    @staticmethod\n    def _get_train_test_split(train_df, Kfold, num_fold):\n        x_train, x_valid, y_train, y_valid = [], [], [], []\n        skf = StratifiedKFold(n_splits=num_fold, random_state=1234, shuffle=True)\n        for train_index, valid_index in skf.split(train_df.index.values, train_df.coverage_class):\n            x_tr = np.array(train_df.images[train_index].tolist()).reshape(-1, IMG_ORI_SIZE, IMG_ORI_SIZE, 1)\n            x_tr = np.append(x_tr, [np.fliplr(x) for x in x_tr], axis=0)\n            x_train.append(x_tr)\n            x_valid.append(np.array(train_df.images[valid_index].tolist()).reshape(-1, IMG_ORI_SIZE, IMG_ORI_SIZE, 1))\n            y_tr = np.array(train_df.masks[train_index].tolist()).reshape(-1, IMG_ORI_SIZE, IMG_ORI_SIZE, 1)\n            y_tr = np.append(y_tr, [np.fliplr(y) for y in y_tr], axis=0)\n            y_train.append(y_tr)\n            y_valid.append(np.array(train_df.masks[valid_index].tolist()).reshape(-1, IMG_ORI_SIZE, IMG_ORI_SIZE, 1))\n            if not Kfold:\n                break\n        return x_train, x_valid, y_train, y_valid\n\n    def get_train(self):\n        return self.x_train, self.y_train\n    \n    def get_valid(self):\n        return self.x_valid, self.y_valid\n\n    def get_test_x(self):\n        return self.x_test\n\n    def get_test_df(self):\n        return self.test_df\n    \nclass ShipDataset(Dataset):\n    def __init__(self, data, transform=None, mode='train'):\n        if mode == 'train' or mode == 'valid':\n            self.x = data[0]\n            self.y = data[1]\n        elif mode == 'test':\n            self.data = data\n        else:\n            raise RuntimeError('MODE_ERROR')\n        self.transform = transform\n        self.mode = mode\n        self.pad_method = PAD_METHOD\n        self.pad_size = (IMG_TAR_SIZE-IMG_ORI_SIZE)//2\n        \n        if FIT_METHOD == 'resize_pad':\n            self.aug_func_eval = partial(resize_pad_seq_eval, self.pad_size)\n        elif FIT_METHOD == 'resize':\n            self.aug_func_eval = resize_seq_eval\n            \n        if AUG:\n            if FIT_METHOD == 'resize_pad':\n                self.aug_func = partial(resize_pad_seq, self.pad_size)\n            elif FIT_METHOD == 'resize':\n                self.aug_func = resize_seq\n        \n        if INPUT_CHANNEL == 3:\n            self.depth = np.tile(np.linspace(0,1,IMG_TAR_SIZE),[IMG_TAR_SIZE,1]).T\n\n    def __len__(self):\n        if self.mode == 'train' or self.mode == 'valid':\n            return len(self.x)\n        elif self.mode == 'test':\n            return len(self.data)\n        else:\n            raise RuntimeError('MODE_ERROR')\n               \n    def __getitem__(self, idx):\n        if self.mode == 'train':\n            if AUG:\n                resize_seq_det = self.aug_func().to_deterministic()\n                new_x_batch = resize_seq_det.augment_image(self.x[idx])\n                new_x_batch = intensity_seq.augment_image(new_x_batch)/255\n                new_y_batch = resize_seq_det.augment_image(self.y[idx])/255\n            else:\n                resize_seq_det = self.aug_func_eval().to_deterministic()\n                new_x_batch = resize_seq_det.augment_image(self.x[idx])/255\n                new_y_batch = resize_seq_det.augment_image(self.y[idx])/255\n            if INPUT_CHANNEL == 3:\n                new_x_batch = np.tile(new_x_batch,(1,1,3))\n                new_x_batch = add_depth_channels(new_x_batch, self.depth)\n            return new_x_batch, new_y_batch\n        elif self.mode == 'valid':\n            resize_seq_det = self.aug_func_eval().to_deterministic()\n            new_x_batch = resize_seq_det.augment_image(self.x[idx])/255\n            new_y_batch = resize_seq_det.augment_image(self.y[idx])/255\n            if INPUT_CHANNEL == 3:\n                new_x_batch = np.tile(new_x_batch,(1,1,3))\n                new_x_batch = add_depth_channels(new_x_batch, self.depth)\n            return new_x_batch, new_y_batch\n        elif self.mode == 'test':\n            resize_seq_det = self.aug_func_eval()\n            test_data = resize_seq_det.augment_image(self.data[idx])/255\n            if INPUT_CHANNEL == 3:\n                test_data = np.tile(test_data,(1,1,3))\n                new_x_batch = add_depth_channels(test_data, self.depth)\n            return test_data\n        else:\n            raise RuntimeError('MODE_ERROR')\n            \ndef make_loader(data, batch_size, num_workers=4, shuffle=False, transform=None, mode='train'):\n        return DataLoader(\n            dataset=ShipDataset(data, transform=transform, mode=mode),\n            shuffle=shuffle,\n            num_workers = num_workers,\n            batch_size = batch_size,\n            pin_memory=torch.cuda.is_available()\n        )",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "47a024a662f85e6cbe936b1bce96d1c471533ddc",
        "trusted": true
      },
      "cell_type": "code",
      "source": "dl = my_DataLoader(train=True, Kfold=KFOLD)\nx_train, y_train = dl.get_train()\nx_valid, y_valid = dl.get_valid()\n\n#Data augmentation\n#x_train = np.append(x_train, [np.fliplr(x) for x in x_train], axis=0)\n#y_train = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d6f19bccfc3d436d8ccd6b65fe1c194c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": "\n",
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0098ef6ed5d483c94eb175c13a355a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": "\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "dc7cb553fc8640deee4f67f53d19128da1e5737b",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from torch import nn\nfrom torch.nn import functional as F\nimport torch\nfrom torchvision import models\nimport torchvision.models.resnet\nfrom torchvision.models.resnet import BasicBlock, Bottleneck\nimport torch.utils.model_zoo as model_zoo\n\n\"\"\"\nThis script has been taken (and modified) from :\nhttps://github.com/ternaus/TernausNet\n@ARTICLE{arXiv:1801.05746,\n         author = {V. Iglovikov and A. Shvets},\n          title = {TernausNet: U-Net with VGG11 Encoder Pre-Trained on ImageNet for Image Segmentation},\n        journal = {ArXiv e-prints},\n         eprint = {1801.05746}, \n           year = 2018\n        }\n\"\"\"\n\nclass ConvBn2d(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, padding):\n        super().__init__()\n        self.conv = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding),\n                                  nn.BatchNorm2d(out_channels),\n                                  )\n\n    def forward(self, x):\n        return self.conv(x)\n\n\nclass NoOperation(nn.Module):\n    def forward(self, x):\n        return x\n\n    \nclass CSE(nn.Module):\n    def __init__(self, in_ch, r=2):\n        super(CSE, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.linear_1 = nn.Linear(in_ch, in_ch//r)\n        self.linear_2 = nn.Linear(in_ch//r, in_ch)\n\n        \n    def forward(self, x):\n        batch_size, channel_num, _, _ = x.size()\n        input_x = x\n\n        x = self.avg_pool(x).view(batch_size, channel_num)\n        x = F.relu(self.linear_1(x), inplace=True)\n        x = self.linear_2(x)\n        x = x.unsqueeze(-1).unsqueeze(-1)\n        x = torch.sigmoid(x)\n\n        x = torch.mul(x, input_x)\n\n        return x\n\n\nclass SSE(nn.Module):\n    def __init__(self, in_ch):\n        super(SSE, self).__init__()\n        self.conv = nn.Conv2d(in_ch, 1, kernel_size=1, stride=1, padding=0, bias=False)\n\n    def forward(self, x):\n        input_x = x\n\n        x = self.conv(x)\n        x = torch.sigmoid(x)\n\n        x = torch.mul(x, input_x)\n\n        return x\n\n\nclass SCSE(nn.Module):\n    def __init__(self, in_ch, r=2):\n        super(SCSE, self).__init__()\n\n        self.cSE = CSE(in_ch, r)\n        self.sSE = SSE(in_ch)\n\n    def forward(self, x):\n        cSE = self.cSE(x)\n        sSE = self.sSE(x)\n\n        x = torch.add(cSE,sSE)\n\n        return x\n    \n    \nclass Decoder(nn.Module):\n    def __init__(self, in_channels, middle_channels, out_channels):\n        super(Decoder, self).__init__()\n        self.conv1 = ConvBn2d(in_channels, middle_channels, kernel_size=3, padding=1)\n        self.conv2 = ConvBn2d(middle_channels, out_channels, kernel_size=3, padding=1)\n        self.SCSE = SCSE(out_channels)\n        \n    def forward(self, x, e=None):\n        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)\n        \n        if e is not None:\n            x = torch.cat([x,e], 1)\n            x = F.dropout2d(x, p = 0.50)\n            \n        x = F.relu(self.conv1(x), inplace=True)\n        x = F.relu(self.conv2(x), inplace=True)\n        x = self.SCSE(x)\n\n        return x\n\n\nclass UNetResNet34_DS(nn.Module):\n\n    def __init__(self, dropout_2d=0.2, pretrained=True):\n        super().__init__()\n        self.dropout_2d = dropout_2d\n\n        self.resnet = torchvision.models.resnet34(pretrained=pretrained)\n\n        self.encoder1 = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=7, stride=1, padding=3, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n        )\n        self.encoder2 = nn.Sequential(\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            self.resnet.layer1,\n        )\n        self.encoder3 = self.resnet.layer2\n        self.encoder4 = self.resnet.layer3\n        self.encoder5 = self.resnet.layer4\n        \n        self.center = nn.Sequential(\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            )\n\n        self.decoder5 = Decoder(256+512, 512, 64)\n        self.decoder4 = Decoder( 64+256, 256, 64)\n        self.decoder3 = Decoder( 64+128, 128, 64)\n        self.decoder2 = Decoder( 64+ 64,  64, 64)\n        self.decoder1 = Decoder( 64+ 64,  32, 64)\n        \n        self.fuse_pixel = nn.Sequential(\n            nn.Conv2d(320, 64, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        )\n        \n        self.logit_pixel  = nn.Sequential(\n            nn.Conv2d( 64, 1, kernel_size=1, padding=0),\n        )\n        \n        self.fuse_image = nn.Sequential(\n            nn.Conv2d(512, 64, kernel_size=1),\n            nn.ReLU(inplace=True),\n        )\n\n        self.logit_image = nn.Sequential(\n            nn.Linear(64, 2),\n        )\n        \n        self.logit = nn.Sequential(\n            nn.Conv2d(64+64, 64, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d( 64,  1, kernel_size=1, padding=0),\n        )\n\n    def forward(self, x):\n        batch_size, C, H, W = x.shape\n        mean= [0.485, 0.456, 0.406]\n        std = [0.229, 0.224, 0.225]\n        x = torch.cat([\n            (x-mean[2])/std[2],\n            (x-mean[1])/std[1],\n            (x-mean[0])/std[0],\n        ],1)\n        \"\"\"\n        if INPUT_CHANNEL == 1:\n            x = torch.cat([x,x,x],1)\n        \"\"\"\n        \n        e1 = self.encoder1(x) #;print('e1', e1.size())\n        e2 = self.encoder2(e1)#;print('e2', e2.size())\n        e3 = self.encoder3(e2)#;print('e3', e3.size())\n        e4 = self.encoder4(e3)#;print('e4', e4.size())\n        e5 = self.encoder5(e4)#;print('e5', e5.size())\n        \n        f = self.center(e5)        #;print('f', f.size())\n        \n        d5 = self.decoder5(f,e5)   #;print('d5', d5.size())\n        d4 = self.decoder4(d5,e4)  #;print('d4', d4.size())\n        d3 = self.decoder3(d4,e3)  #;print('d3', d3.size())\n        d2 = self.decoder2(d3,e2)  #;print('d2', d2.size())\n        d1 = self.decoder1(d2,e1)  #;print('d1', d1.size())\n        \n        #hyper column\n        d = torch.cat((\n            d1,\n            F.interpolate(d2, scale_factor= 2, mode='bilinear', align_corners=False),\n            F.interpolate(d3, scale_factor= 4, mode='bilinear', align_corners=False),\n            F.interpolate(d4, scale_factor= 8, mode='bilinear', align_corners=False),\n            F.interpolate(d5, scale_factor=16, mode='bilinear', align_corners=False),\n        ), 1)\n        d = F.dropout2d(d, p=self.dropout_2d)\n        fuse_pixel = self.fuse_pixel(d)\n        logit_pixel = self.logit_pixel(fuse_pixel)\n        \n        e = F.adaptive_avg_pool2d(e5, output_size=[1,1])\n        e = F.dropout(e, p=self.dropout_2d)\n        fuse_image = self.fuse_image(e)\n        fuse_image_flatten = fuse_image.view(fuse_image.size(0), -1)\n        logit_image = self.logit_image(fuse_image_flatten)\n        \n        logit = self.logit(torch.cat([\n            fuse_pixel, \n            F.interpolate(fuse_image.view(batch_size,-1,1,1,),scale_factor=128, mode='nearest')],1))\n\n        return logit, logit_pixel, logit_image",
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2dcfe44283aa19b30ca4c79883149441d50471db",
        "trusted": true
      },
      "cell_type": "code",
      "source": "def validation(model, criterion, valid_loader):\n    model.eval()\n    losses = []\n    iou = []\n    with torch.no_grad():\n        for inputs, targets in valid_loader:\n            inputs = inputs.permute(0,3,1,2).type(torch.FloatTensor).to(device)\n            truth_image = get_true_target(targets)\n            targets = targets.permute(0,3,1,2).type(torch.FloatTensor).to(device)\n            outputs, outputs_pixel, outputs_image = model(inputs)\n            loss = criterion(outputs, outputs_pixel, outputs_image, targets, truth_image)\n            losses += [loss.item()]\n            iou += [my_iou_metric_2(get_numpy(targets), get_numpy(outputs))]\n\n        valid_loss = np.mean(losses)  # type: float\n\n        valid_iou = np.mean(iou)\n\n        metrics = {'val_loss': valid_loss, 'val_iou': valid_iou}\n    return metrics\n\ndef train(model, criterion, train_loader, optimizer, epoch, \n          scheduler, report_each=10, valid_iou=0):\n        model.train()\n        random.seed()\n        scheduler.step()\n        lr = self.optimizer.param_groups[0]['lr']\n        print('change learning rate into: {:.4f}'.format(lr))\n        losses = []\n        ious = []\n        tl = train_loader\n        \n        try:\n            mean_loss = 0\n            mean_iou = 0\n            for i, (inputs, targets) in enumerate(tl):\n                inputs = inputs.permute(0,3,1,2).type(torch.FloatTensor).to(device)\n                truth_image = get_true_target(targets)\n                targets = targets.permute(0,3,1,2).type(torch.FloatTensor).to(device)\n                outputs, outputs_pixel, outputs_image = model(inputs)\n                loss = criterion(outputs, outputs_pixel, outputs_image, targets, truth_image)\n                optimizer.zero_grad()\n                batch_size = inputs.size(0)\n                loss.backward()\n                optimizer.step()\n                losses += [loss.item()]\n                ious += [my_iou_metric_2(get_numpy(targets), get_numpy(outputs))]\n                mean_loss = np.mean(losses[-report_each:])\n                mean_iou = np.mean(ious[-report_each:])\n                \n                for param_group in optimizer.param_groups:\n                    lr = param_group['lr']\n\n                if i % report_each == 0:\n                    print('Epoch: [{0}][{1}/{2}]\\t'\n                          'Loss {loss:.4f} ({loss_avg:.4f})\\t'\n                          'IOU {iou:.3f} ({iou_avg:.3f})'.format(\n                           epoch, i, len(tl), loss=losses[-1], loss_avg=mean_loss, iou=ious[-1], iou_avg=mean_iou))\n\n            metrics = {'train_loss': mean_loss, 'train_iou': mean_iou}\n            return metrics\n        \n        except KeyboardInterrupt:\n            print('Ctrl+C, saving snapshot')\n            print('done.')\n            return",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c4583b6471c8dd706f573c121a12ae447cd01f6c"
      },
      "cell_type": "code",
      "source": "criterion = Fuse_Loss(pixel_loss_func=Lovaz_Loss())\ncriterion = criterion.to(device)\n#early_stop = EarlyStopping(mode='max', min_delta=0, patience=10)",
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "83b13bf870a9ae1557884f62cc299b9c2dc3f312"
      },
      "cell_type": "code",
      "source": "fold = 0\nfor x_train_f, y_train_f, x_valid_f, y_valid_f in zip(x_train, y_train, x_valid, y_valid):\n    train_loader = make_loader((x_train_f, y_train_f), num_workers=0, batch_size=32, shuffle=True)\n    valid_loader = make_loader((x_valid_f, y_valid_f), num_workers=0, batch_size=64, mode='valid')\n\n    res_unet = UNetResNet34_DS(dropout_2d=0.5, pretrained=True)\n    res_unet = res_unet.to(device)\n\n    #early_stop = EarlyStopping(mode='max', min_delta=0, patience=10)\n    #model = nn.DataParallel(model, device_ids=None)\n\n    n_epochs = 10\n    n_cycle = 5\n    start_epoch = 0\n    report_each = 20\n    valid_losses = []\n    valid_ious = []\n    train_losses = []\n    train_ious = []\n    valid_iou = 0\n    valid_loss = 0\n    \n    if LOAD_CHECKPONT:\n        resume_path = f'../input/shanlins-s-pretrained-res-unet-v2/model_best_resnet34_bce_dice_0_0_iou_resize.pth.tar'\n        if os.path.isfile(resume_path):\n            print(\"=> loading checkpoint '{}'\".format(resume_path))\n            checkpoint = torch.load(resume_path)\n            #start_epoch = checkpoint['epoch']\n            #best_iou = checkpoint['best_iou']\n            res_unet.load_state_dict(checkpoint['state_dict'])\n            #optimizer.load_state_dict(checkpoint['optimizer'])\n            \n    optimizer= SGD(filter(lambda p: p.requires_grad, res_unet.parameters()),\n                   0.01, weight_decay=0.0002, momentum=0.9)\n    scheduler = CosineAnnealingLR_with_Restart(optimizer,\n                                              T_max=n_epochs,\n                                              T_mult=1,\n                                              model=res_unet,\n                                              out_dir='',\n                                              take_snapshot=False,\n                                              eta_min=1e-3)\n        \n    print('Fold: [{0}]\\t'.format(fold+1))\n    for cycle in range(n_cycle):\n        print('Cycle: [{0}]\\t'.format(cycle + 1))\n        best_iou = 0\n        \n        for epoch in range(start_epoch, start_epoch + n_epochs):\n            time0 = time.time()\n            train_metrics = train(res_unet, criterion, train_loader, optimizer, \n                                  epoch, scheduler, report_each, valid_iou)\n            valid_metrics = validation(res_unet, criterion, valid_loader)\n\n            train_loss = train_metrics['train_loss']\n            train_iou = train_metrics['train_iou']\n            train_losses += [train_loss]\n            train_ious += [train_iou]\n            valid_loss = valid_metrics['val_loss']\n            valid_iou = valid_metrics['val_iou']\n            valid_losses += [valid_loss]\n            valid_ious += [valid_iou]\n            is_best = best_iou < valid_iou\n            best_iou = max(valid_iou, best_iou)\n            print('Epoch: [{0}][Validation]\\t' \n                  'Val_Loss: {val_loss:.5f}\\t' \n                  'Val_IOU: {val_iou:.5f}\\t'\n                  'Best Val_IOU: {best_iou:.5f}'.format(epoch, \n                                                        val_loss=valid_loss, \n                                                        val_iou=valid_iou, \n                                                        best_iou=best_iou))\n            filename = '{name}_{loss}_{phrase}_{fold}_{cycle}_{mode}'.format(name='resnet34',\n                                                                     loss='bce_dice',\n                                                                     phrase='0',\n                                                                     fold=fold,\n                                                                     cycle=cycle,\n                                                                     mode='iou',)\n            save_checkpoint({\n                'epoch': epoch + 1,\n                'state_dict': res_unet.state_dict(),\n                'best_iou': best_iou,\n                'optimizer': optimizer.state_dict(),\n            }, is_best, filename)\n            time1 = time.time()\n            print('epoch time: ', time1-time0)\n    fold += 1\n    \"\"\"\n    if early_stop.step(valid_iou):\n        break\n    \"\"\"",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /tmp/.torch/models/resnet34-333f7ec4.pth\n",
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ConnectionError",
          "evalue": "HTTPSConnectionPool(host='download.pytorch.org', port=443): Max retries exceeded with url: /models/resnet34-333f7ec4.pth (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f56e7f20ef0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution',))",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 141\u001b[0;31m                 (self.host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mgaierror\u001b[0m: [Errno -3] Temporary failure in name resolution",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    600\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sock'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;31m# Add certificate verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m             raise NewConnectionError(\n\u001b[0;32m--> 150\u001b[0;31m                 self, \"Failed to establish a new connection: %s\" % e)\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.VerifiedHTTPSConnection object at 0x7f56e7f20ef0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m                 )\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    638\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[0;32m--> 639\u001b[0;31m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[1;32m    640\u001b[0m             \u001b[0mretries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='download.pytorch.org', port=443): Max retries exceeded with url: /models/resnet34-333f7ec4.pth (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f56e7f20ef0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution',))",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-b6171f856e4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalid_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mres_unet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUNetResNet34_DS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropout_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mres_unet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres_unet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-4c67c1a1d4ad>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dropout_2d, pretrained)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdropout_2d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet34\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         self.encoder1 = nn.Sequential(\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mresnet34\u001b[0;34m(pretrained, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBasicBlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_zoo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_urls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'resnet34'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/model_zoo.py\u001b[0m in \u001b[0;36mload_url\u001b[0;34m(url, model_dir, map_location, progress)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Downloading: \"{}\" to {}\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mhash_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHASH_REGEX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0m_download_url_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhash_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcached_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/model_zoo.py\u001b[0m in \u001b[0;36m_download_url_to_file\u001b[0;34m(url, dst, hash_prefix, progress)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_download_url_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhash_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrequests_available\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0mfile_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Content-Length\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    506\u001b[0m         }\n\u001b[1;32m    507\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='download.pytorch.org', port=443): Max retries exceeded with url: /models/resnet34-333f7ec4.pth (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f56e7f20ef0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution',))"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7e5a810db663502a8f3c0c0d8f1d92762a4adc05"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}