{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "54643e32b4132d15df20d55f2b9ee09efc2c51a8"
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "b15761a022f76bb50db1bb55c21b59a3f1c88261"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "import shutil\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "from tqdm import tqdm_notebook #, tnrange\n",
    "#from itertools import chain\n",
    "from skimage.io import imread, imshow #, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from skimage import filters\n",
    "\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.backends.cudnn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchvision.transforms import ToTensor, ToPILImage, Normalize, Compose\n",
    "\n",
    "import PIL\n",
    "\n",
    "from datetime import datetime\n",
    "import json\n",
    "import gc\n",
    "\n",
    "import time\n",
    "#t_start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "99e7207d6aec7d921e4b8ad4f30d310d2346216a"
   },
   "source": [
    "# Global variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "73cc76d8506e96b912600406fa5ceeb47083978a"
   },
   "outputs": [],
   "source": [
    "TRAIN_IMG_PATH = \"train/images/\"\n",
    "TEST_IMG_PATH = \"test/images/\"\n",
    "DEPTH_PATH = \"depths.csv\"\n",
    "TRAIN_MASK_PATH = \"train/masks/\"\n",
    "TRAIN_INFO_PATH = \"train.csv\"\n",
    "\n",
    "# basic parameters\n",
    "IMG_ORI_SIZE = 101\n",
    "IMG_TAR_SIZE = 128\n",
    "SCALE = 1\n",
    "\n",
    "# Model parameters\n",
    "START_NEURONS = 16\n",
    "DROPOUT_RATIO = 0.5\n",
    "\n",
    "LOAD_CHECKPONT = True\n",
    "\n",
    "INPUT_CHANNEL = 1\n",
    "\n",
    "MODEL1_ADAM_LR = 0.01\n",
    "MODEL1_EPOCHS = 100\n",
    "MODEL1_BATCH_SIZE = 64\n",
    "MODEL1_STEPS_PER_EPOCH_TRAIN = 200\n",
    "MODEL1_LOSS = 'binary_crossentropy'\n",
    "\n",
    "MODEL2_ADAM_LR = 0.01\n",
    "MODEL2_EPOCHS = 100\n",
    "MODEL2_BATCH_SIZE = 64\n",
    "MODEL2_STEPS_PER_EPOCH_TRAIN = 200\n",
    "MODEL2_LOSS = 'lovasz_loss'\n",
    "\n",
    "# ReduceLROnPlateau parameters\n",
    "MODEL1_REDUCE_FACTOR = 0.5\n",
    "MODEL1_REDUCE_PATIENT = 5\n",
    "\n",
    "MODEL2_REDUCE_FACTOR = 0.5\n",
    "MODEL2_REDUCE_PATIENT = 5\n",
    "\n",
    "# DICE_BCE_LOSS Parameters\n",
    "BCE_WEIGHT = 1\n",
    "DICE_WEIGHT = 0\n",
    "\n",
    "# Augmentation Parmeters\n",
    "AUG = True\n",
    "FIT_METHOD = 'resize_pad'\n",
    "PAD_METHOD = 'edge'\n",
    "KFOLD = True\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "aa113e7f4cabb11b9a14afc2151e96ff664ef7ed"
   },
   "outputs": [],
   "source": [
    "# encoding=utf8\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from functools import reduce\n",
    "\n",
    "################################################################################\n",
    "# related functions & loss functions\n",
    "################################################################################\n",
    "\n",
    "\n",
    "def upsample(img):\n",
    "    if IMG_ORI_SIZE == IMG_TAR_SIZE:\n",
    "        return img\n",
    "    return cv2.resize(img, (IMG_TAR_SIZE, IMG_TAR_SIZE))\n",
    "\n",
    "\n",
    "def downsample(img):\n",
    "    if IMG_ORI_SIZE == IMG_TAR_SIZE:\n",
    "        return img\n",
    "    return cv2.resize(img, (IMG_ORI_SIZE, IMG_ORI_SIZE))\n",
    "\n",
    "\n",
    "def add_depth_channels(image_array, depth):\n",
    "    image_array[:,:,1] = depth\n",
    "    image_array[:,:,2] = image_array[:,:,0] * image_array[:,:,1]\n",
    "    return image_array\n",
    "\n",
    "\n",
    "class MyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return super(MyEncoder, self).default(obj)\n",
    "\n",
    "        \n",
    "def write_event(log, step: int, **data):\n",
    "    data['step'] = step\n",
    "    data['dt'] = datetime.now().isoformat()\n",
    "    log.write(json.dumps(data, sort_keys=True, cls=MyEncoder))\n",
    "    log.write('\\n')\n",
    "    log.flush()\n",
    "\n",
    "    \n",
    "def get_variable(x):\n",
    "    \"\"\" Converts tensors to cuda, if available. \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return x.cuda()\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_numpy(x):\n",
    "    \"\"\" Get numpy array for both cuda and not. \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return x.cpu().data.numpy()\n",
    "    return x.data.numpy()\n",
    "\n",
    "\n",
    "def get_true_target(targets):\n",
    "    truth_image = targets.squeeze(3).sum(2).sum(1) > 0\n",
    "    return truth_image\n",
    "  \n",
    "\n",
    "def get_logits_outputs(outputs_image, outputs_pixel):\n",
    "    batch_size, C, H, W = outputs_pixel.shape\n",
    "    zero_mask = torch.zeros([batch_size, C, H, W], dtype=torch.float).to(device)\n",
    "    empty_label = outputs_image<0\n",
    "    outputs_pixel[empty_label] = zero_mask[empty_label]\n",
    "    return outputs_pixel\n",
    "\n",
    "\n",
    "def iou_numpy(outputs, labels):\n",
    "    SMOOTH = 1e-6\n",
    "    labels = labels.squeeze(1)\n",
    "    outputs = outputs.squeeze(1)\n",
    "    \n",
    "    intersection = (outputs & labels).sum((1, 2))\n",
    "    union = (outputs | labels).sum((1, 2))\n",
    "    \n",
    "    iou = (intersection + SMOOTH) / (union + SMOOTH)\n",
    "    \n",
    "    thresholded = np.ceil(np.clip(20 * (iou - 0.5), 0, 10)) / 10\n",
    "    \n",
    "    return thresholded.mean()\n",
    "\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    return iou_numpy(pred > 0.5, label>0.5)\n",
    "\n",
    "\n",
    "def my_iou_metric_2(label, pred):\n",
    "    return iou_numpy(pred > 0, label>0.5)\n",
    "\n",
    "\n",
    "def my_iou_metric_pad(label, pred):\n",
    "    pad_size = (IMG_TAR_SIZE-SCALE*IMG_ORI_SIZE)//2\n",
    "    return iou_numpy(pred[:,:,pad_size:-pad_size-1,pad_size+1:-pad_size]>0,label[:,:,pad_size:-pad_size-1,pad_size+1:-pad_size]>0.5)\n",
    "\n",
    "    \n",
    "def save_checkpoint(state, is_best, filename):\n",
    "    check_filename = 'checkpoint_{}.pth.tar'.format(filename)\n",
    "    torch.save(state, check_filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(check_filename, 'model_best_{}.pth.tar'.format(filename))\n",
    "        \n",
    "\n",
    "class EarlyStopping(object):\n",
    "    def __init__(self, mode='min', min_delta=0, patience=10):\n",
    "        self.mode = mode\n",
    "        self.min_delta = min_delta\n",
    "        self.patience = patience\n",
    "        self.best = None\n",
    "        self.num_bad_epochs = 0\n",
    "        self.is_better = None\n",
    "        self._init_is_better(mode, min_delta)\n",
    "\n",
    "        if patience == 0:\n",
    "            self.is_better = lambda a, b: True\n",
    "\n",
    "    def step(self, metrics):\n",
    "        if self.best is None:\n",
    "            self.best = metrics\n",
    "            return False\n",
    "\n",
    "        if np.isnan(metrics):\n",
    "            return True\n",
    "\n",
    "        if self.is_better(metrics, self.best):\n",
    "            self.num_bad_epochs = 0\n",
    "            self.best = metrics\n",
    "        else:\n",
    "            self.num_bad_epochs += 1\n",
    "\n",
    "        if self.num_bad_epochs >= self.patience:\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def _init_is_better(self, mode, min_delta):\n",
    "        if mode not in {'min', 'max'}:\n",
    "            raise ValueError('mode ' + mode + ' is unknown!')\n",
    "        if mode == 'min':\n",
    "            self.is_better = lambda a, best: a < best - min_delta\n",
    "        if mode == 'max':\n",
    "            self.is_better = lambda a, best: a > best + min_delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "951cbf65518e980d4d9cc3595458a9b366374f58"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "try:\n",
    "    from itertools import  ifilterfalse\n",
    "except ImportError: # py3k\n",
    "    from itertools import  filterfalse\n",
    "    \n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=0, eps=1e-7):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        output = torch.sigmoid(output)\n",
    "        return 1 - (2 * torch.sum(output * target) + self.smooth) / (torch.sum(output) + torch.sum(target) + self.smooth + self.eps)\n",
    "\n",
    "\n",
    "class Dice_Bce_Loss(nn.Module):\n",
    "    def __init__(self, smooth=0, eps=1e-7, dice_weight=0.5, \n",
    "                 dice_loss=None, bce_weight=0.9, bce_loss=None):\n",
    "        super(Dice_Bce_Loss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "        self.eps = eps\n",
    "        self.dice_weight = dice_weight\n",
    "        self.bce_weight = bce_weight\n",
    "        self.bce_loss = bce_loss\n",
    "        self.dice_loss = dice_loss\n",
    "        \n",
    "        if self.bce_loss is None:\n",
    "            self.bce_loss = F.binary_cross_entropy_with_logits\n",
    "        if self.dice_loss is None:\n",
    "            self.dice_loss = DiceLoss(smooth, eps)\n",
    "            \n",
    "        self.activation = torch.sigmoid\n",
    "            \n",
    "    def forward(self, output, target):\n",
    "        output = self.activation(output)\n",
    "        return self.dice_weight * self.dice_loss(output, target) + self.bce_weight * self.bce_loss(output, target)\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5, gamma=2, logits=True, reduce=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.logits = logits\n",
    "        self.reduce = reduce\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        if self.logits:\n",
    "            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        else:\n",
    "            BCE_loss = F.binary_cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)\n",
    "        else:\n",
    "            return F_loss\n",
    "        \n",
    "\n",
    "\"\"\"\n",
    "Lovasz-Softmax and Jaccard hinge loss in PyTorch\n",
    "Maxim Berman 2018 ESAT-PSI KU Leuven (MIT License)\n",
    "\"\"\"\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    p = len(gt_sorted)\n",
    "    gts = gt_sorted.sum()\n",
    "    intersection = gts - gt_sorted.cumsum(0)\n",
    "    union = gts + (1 - gt_sorted).cumsum(0)\n",
    "    jaccard = 1. - intersection / union\n",
    "    if p > 1: # cover 1-pixel case\n",
    "        jaccard[1:p] = jaccard[1:p] - jaccard[0:-1]\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        loss = mean(lovasz_hinge_flat(*flatten_binary_scores(log.unsqueeze(0), lab.unsqueeze(0), ignore))\n",
    "                          for log, lab in zip(logits, labels))\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "    if len(labels) == 0:\n",
    "        # only void pixels, the gradients should be 0\n",
    "        return logits.sum() * 0.\n",
    "    signs = 2. * labels.float() - 1.\n",
    "    errors = (1. - logits * signs)\n",
    "    errors_sorted, perm = torch.sort(errors, dim=0, descending=True)\n",
    "    perm = perm.data\n",
    "    gt_sorted = labels[perm]\n",
    "    grad = lovasz_grad(gt_sorted)\n",
    "    loss = torch.dot(F.elu(errors_sorted)+1, grad)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = scores.view(-1)\n",
    "    labels = labels.view(-1)\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = (labels != ignore)\n",
    "    vscores = scores[valid]\n",
    "    vlabels = labels[valid]\n",
    "    return vscores, vlabels\n",
    "\n",
    "# --------------------------- HELPER FUNCTIONS ---------------------------\n",
    "\n",
    "def mean(l, ignore_nan=False, empty=0):\n",
    "    \"\"\"\n",
    "    nanmean compatible with generators.\n",
    "    \"\"\"\n",
    "    l = iter(l)\n",
    "    if ignore_nan:\n",
    "        l = ifilterfalse(np.isnan, l)\n",
    "    try:\n",
    "        n = 1\n",
    "        acc = next(l)\n",
    "    except StopIteration:\n",
    "        if empty == 'raise':\n",
    "            raise ValueError('Empty mean')\n",
    "        return empty\n",
    "    for n, v in enumerate(l, 2):\n",
    "        acc += v\n",
    "    if n == 1:\n",
    "        return acc\n",
    "    return acc / n\n",
    "\n",
    "\n",
    "class BCE_Lovaz_Loss(nn.Module):\n",
    "    def __init__(self, per_image=True, ignore=None):\n",
    "        super(BCE_Lovaz_Loss, self).__init__()\n",
    "        self.per_image = per_image\n",
    "        self.ignore = ignore\n",
    "        \n",
    "    def forward(self, logits, targets):\n",
    "        loss_1 = lovasz_hinge(logits.squeeze(1), targets.squeeze(1), self.per_image, self.ignore)\n",
    "        loss_2 = nn.BCEWithLogitsLoss()(logits, targets)\n",
    "        loss = loss_1 + loss_2\n",
    "        return loss\n",
    "    \n",
    "class Lovaz_Loss(nn.Module):\n",
    "    def __init__(self, per_image=True, ignore=None):\n",
    "        super(Lovaz_Loss, self).__init__()\n",
    "        self.per_image = per_image\n",
    "        self.ignore = ignore\n",
    "        \n",
    "    def forward(self, logits, targets):\n",
    "        loss = lovasz_hinge(logits.squeeze(1), targets.squeeze(1), self.per_image, self.ignore)\n",
    "        return loss\n",
    "\n",
    "class Fuse_Loss(nn.Module):\n",
    "    def __init__(self, pixel_loss_func=Lovaz_Loss(), weight_image=0.05, weight_pixel=0.5, weight=1):\n",
    "        super(Fuse_Loss, self).__init__()\n",
    "        self.image_loss_func = F.cross_entropy\n",
    "        self.pixel_loss_func = pixel_loss_func\n",
    "        self.activation = torch.sigmoid\n",
    "        self.weight_image = weight_image\n",
    "        self.weight_pixel = weight_pixel\n",
    "        self.weight = weight\n",
    "        \n",
    "    def forward(self, logits, logit_pixel, logit_image, truth_pixel, truth_image):\n",
    "        pixel_non_empty = logit_pixel[truth_image,:,:,:]\n",
    "        mask_non_empty = truth_pixel[truth_image,:,:,:]\n",
    "        loss_pixel = self.pixel_loss_func(pixel_non_empty, mask_non_empty)\n",
    "        truth_image = truth_image.type(torch.LongTensor).to(device)\n",
    "        loss_image = self.image_loss_func(logit_image, truth_image, reduction='elementwise_mean')\n",
    "        loss = self.pixel_loss_func(logits, truth_pixel)\n",
    "        return self.weight_pixel*loss_pixel + self.weight_image*loss_image + self.weight*loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "528f191a441809dd782a3dbf9d425284b9dba18a"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "class CosineAnnealingLR_with_Restart(_LRScheduler):\n",
    "    \"\"\"Set the learning rate of each parameter group using a cosine annealing\n",
    "    schedule, where :math:`\\eta_{max}` is set to the initial lr and\n",
    "    :math:`T_{cur}` is the number of epochs since the last restart in SGDR:\n",
    "    .. math::\n",
    "        \\eta_t = \\eta_{min} + \\frac{1}{2}(\\eta_{max} - \\eta_{min})(1 +\n",
    "        \\cos(\\frac{T_{cur}}{T_{max}}\\pi))\n",
    "    When last_epoch=-1, sets initial lr as lr.\n",
    "    It has been proposed in\n",
    "    `SGDR: Stochastic Gradient Descent with Warm Restarts`_. The original pytorch\n",
    "    implementation only implements the cosine annealing part of SGDR,\n",
    "    I added my own implementation of the restarts part.\n",
    "    Args:\n",
    "        optimizer (Optimizer): Wrapped optimizer.\n",
    "        T_max (int): Maximum number of iterations.\n",
    "        T_mult (float): Increase T_max by a factor of T_mult\n",
    "        eta_min (float): Minimum learning rate. Default: 0.\n",
    "        last_epoch (int): The index of last epoch. Default: -1.\n",
    "        model (pytorch model): The model to save.\n",
    "        out_dir (str): Directory to save snapshots\n",
    "        take_snapshot (bool): Whether to save snapshots at every restart\n",
    "    .. _SGDR\\: Stochastic Gradient Descent with Warm Restarts:\n",
    "        https://arxiv.org/abs/1608.03983\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer, T_max, T_mult, model, out_dir, take_snapshot, eta_min=0, last_epoch=-1):\n",
    "        self.T_max = T_max\n",
    "        self.T_mult = T_mult\n",
    "        self.Te = self.T_max\n",
    "        self.eta_min = eta_min\n",
    "        self.current_epoch = last_epoch\n",
    "\n",
    "        self.model = model\n",
    "        self.out_dir = out_dir\n",
    "        self.take_snapshot = take_snapshot\n",
    "\n",
    "        self.lr_history = []\n",
    "\n",
    "        super(CosineAnnealingLR_with_Restart, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        new_lrs = [self.eta_min + (base_lr - self.eta_min) *\n",
    "                   (1 + math.cos(math.pi * self.current_epoch / self.Te)) / 2\n",
    "                   for base_lr in self.base_lrs]\n",
    "\n",
    "        self.lr_history.append(new_lrs)\n",
    "        return new_lrs\n",
    "\n",
    "    def step(self, epoch=None):\n",
    "        if epoch is None:\n",
    "            epoch = self.last_epoch + 1\n",
    "        self.last_epoch = epoch\n",
    "        self.current_epoch += 1\n",
    "\n",
    "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "        ## restart\n",
    "        if self.current_epoch == self.Te:\n",
    "            print(\"restart at epoch {:03d}\".format(self.last_epoch + 1))\n",
    "\n",
    "            if self.take_snapshot:\n",
    "                torch.save({\n",
    "                    'epoch': self.T_max,\n",
    "                    'state_dict': self.model.state_dict()\n",
    "                }, self.out_dir + \"Weight/\" + 'snapshot_e_{:03d}.pth.tar'.format(self.T_max))\n",
    "\n",
    "            ## reset epochs since the last reset\n",
    "            self.current_epoch = 0\n",
    "\n",
    "            ## reset the next goal\n",
    "            self.Te = int(self.Te * self.T_mult)\n",
    "            self.T_max = self.T_max + self.Te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "f6879d5d3bbb6c70fd2c25908083b690e59c13a8"
   },
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import numpy as np\n",
    "\n",
    "ia.seed(2018)\n",
    "\n",
    "def _standardize(img):\n",
    "    return (img - img.map(np.mean)) / img.map(np.std)\n",
    "\n",
    "affine_seq = iaa.Sequential([\n",
    "    # General\n",
    "    iaa.SomeOf((1, 2),\n",
    "               [iaa.Fliplr(0.5),\n",
    "                iaa.Noop(),\n",
    "                ]),\n",
    "    iaa.Affine(rotate=(-5, 5), mode='reflect'),\n",
    "    iaa.Crop(px=(0, 10)),\n",
    "], random_order=True)\n",
    "\n",
    "intensity_seq = iaa.Sequential([\n",
    "    #iaa.Invert(0.3),\n",
    "    iaa.Sometimes(0.3, iaa.ContrastNormalization((0.5, 1.5))),\n",
    "    iaa.OneOf([\n",
    "        iaa.Noop(),\n",
    "        iaa.Sequential([\n",
    "            iaa.OneOf([\n",
    "                iaa.Add((-10, 10)),\n",
    "                iaa.AddElementwise((-10, 10)),\n",
    "                iaa.Multiply((0.95, 1.05)),\n",
    "                iaa.MultiplyElementwise((0.95, 1.05)),\n",
    "            ]),\n",
    "        ]),\n",
    "        iaa.OneOf([\n",
    "            iaa.GaussianBlur(sigma=(0.0, 1.0)),\n",
    "            iaa.AverageBlur(k=(2, 5)),\n",
    "            #iaa.MedianBlur(k=(3, 5))\n",
    "        ])\n",
    "    ])\n",
    "], random_order=False)\n",
    "\n",
    "tta_intensity_seq = iaa.Sequential([\n",
    "    iaa.Noop()\n",
    "], random_order=False)\n",
    "\n",
    "def compute_random_pad(limit=(-4,4)):\n",
    "    dy  = IMG_TAR_SIZE - IMG_ORI_SIZE*SCALE\n",
    "    dy0 = dy//2 + np.random.randint(limit[0],limit[1]) # np.random.choice(dy)\n",
    "    dy1 = dy - dy0\n",
    "    dx0 = dy//2 + np.random.randint(limit[0],limit[1]) # np.random.choice(dy)\n",
    "    dx1 = dy - dx0\n",
    "    return dy0, dx0, dy1, dx1\n",
    "\n",
    "def resize_pad_seq(pad_size):\n",
    "    dy0, dx0, dy1, dx1 = compute_random_pad()\n",
    "    seq = iaa.Sequential([\n",
    "        affine_seq,\n",
    "        iaa.Scale({'height': IMG_ORI_SIZE*SCALE, 'width': IMG_ORI_SIZE*SCALE}),\n",
    "        iaa.Pad(px=(dy0, dx0, dy1, dx1), pad_mode='edge', keep_size=False),\n",
    "    ], random_order=False)\n",
    "    return seq\n",
    "\n",
    "def resize_pad_seq_eval(pad_size):\n",
    "    seq = iaa.Sequential([\n",
    "        iaa.Scale({'height': IMG_ORI_SIZE*SCALE, 'width': IMG_ORI_SIZE*SCALE}),\n",
    "        iaa.Pad(px=(pad_size, pad_size, pad_size+1, pad_size+1), pad_mode='edge', keep_size=False),\n",
    "    ], random_order=False)\n",
    "    return seq\n",
    "\n",
    "def resize_seq():\n",
    "    seq = iaa.Sequential([\n",
    "        affine_seq,\n",
    "        iaa.Scale({'height': IMG_TAR_SIZE, 'width': IMG_TAR_SIZE})\n",
    "    ], random_order=False)\n",
    "    return seq\n",
    "\n",
    "def resize_seq_eval():\n",
    "    seq = iaa.Sequential([\n",
    "        iaa.Scale({'height': IMG_TAR_SIZE, 'width': IMG_TAR_SIZE})\n",
    "    ], random_order=False)\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "8cbfed0014f8791e5d308d3cb6107c45866bef6b"
   },
   "outputs": [],
   "source": [
    "# encoding=utf8\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "import cv2\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.backends.cudnn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose\n",
    "\n",
    "## convert salt coverage to class\n",
    "def cov_to_class_1(mask):\n",
    "    border = 10\n",
    "    outer = np.zeros((101-2*border, 101-2*border), np.float32)\n",
    "    outer = cv2.copyMakeBorder(outer, border, border, border, border, borderType = cv2.BORDER_CONSTANT, value = 1)\n",
    "\n",
    "    cover = (mask>0.5).sum()\n",
    "    if cover < 8:\n",
    "        return 0 # empty\n",
    "    if cover == ((mask*outer) > 0.5).sum():\n",
    "        return 1 #border\n",
    "    if np.all(mask==mask[0]):\n",
    "        return 2 #vertical\n",
    "\n",
    "    percentage = cover/(101*101)\n",
    "    if percentage < 0.15:\n",
    "        return 3\n",
    "    elif percentage < 0.25:\n",
    "        return 4\n",
    "    elif percentage < 0.50:\n",
    "        return 5\n",
    "    elif percentage < 0.75:\n",
    "        return 6\n",
    "    else:\n",
    "        return 7\n",
    "    \n",
    "def cov_to_class_2(val):    \n",
    "    for i in range(0, 11):\n",
    "        if val * 10 <= i :\n",
    "            return i\n",
    "\n",
    "## used to load data from data files\n",
    "class my_DataLoader:\n",
    "    def __init__(self, train=False, test=False, Kfold=False, test_size=0.2):\n",
    "        self.test = test\n",
    "        self.train = train\n",
    "        self.Kfold = Kfold\n",
    "        self.test_size = test_size\n",
    "        self.num_fold = int(1/test_size)\n",
    "            \n",
    "        train_df, self.test_df = self._load_depth()\n",
    "        \n",
    "        if self.train:\n",
    "            self._load_image_mask(train_df)\n",
    "            train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(IMG_ORI_SIZE, 2)\n",
    "            train_df[\"coverage_class\"] = train_df.masks.map(cov_to_class_1)\n",
    "            self.x_train, self.x_valid, self.y_train, self.y_valid = self._get_train_test_split(train_df, self.Kfold, self.num_fold)\n",
    "            \n",
    "        if self.test:\n",
    "            test_df['images'] = self._load_image_test(self.test_df)\n",
    "            self.x_test = np.array(self.test_df.images.tolist()).reshape(-1, IMG_ORI_SIZE, IMG_ORI_SIZE, 1)\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_image_mask(train_df):\n",
    "        # load image data & mask data\n",
    "        train_df['images'] = [np.array(cv2.imread(TRAIN_IMG_PATH + \"{}.png\".format(idx), 0)) for idx in tqdm_notebook(train_df.index)]\n",
    "        train_df['masks'] = [np.array(cv2.imread(TRAIN_MASK_PATH + \"{}.png\".format(idx), 0)) for idx in tqdm_notebook(train_df.index)]\n",
    "        # Normalize image vectors\n",
    "        #train_df['images'] /= 255\n",
    "        #train_df['masks'] /= 255\n",
    "        \n",
    "    @staticmethod\n",
    "    def _load_image_test(test_df):\n",
    "        return [np.array(cv2.imread(TEST_IMG_PATH + \"{}.png\".format(idx), 0)) for idx in tqdm_notebook(test_df.index)]\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_depth():\n",
    "        train_df = pd.read_csv(TRAIN_INFO_PATH, index_col=\"id\", usecols=[0])\n",
    "        depths_df = pd.read_csv(DEPTH_PATH, index_col=\"id\")\n",
    "        depths_df['z'] = depths_df['z'].astype('float')\n",
    "        train_df = train_df.join(depths_df)\n",
    "        test_df = depths_df[~depths_df.index.isin(train_df.index)]\n",
    "        return train_df, test_df\n",
    "\n",
    "    ## get train & validation split stratified by salt coverage\n",
    "    @staticmethod\n",
    "    def _get_train_test_split(train_df, Kfold, num_fold):\n",
    "        x_train, x_valid, y_train, y_valid = [], [], [], []\n",
    "        skf = StratifiedKFold(n_splits=num_fold, random_state=1234, shuffle=True)\n",
    "        for train_index, valid_index in skf.split(train_df.index.values, train_df.coverage_class):\n",
    "            x_tr = np.array(train_df.images[train_index].tolist()).reshape(-1, IMG_ORI_SIZE, IMG_ORI_SIZE, 1)\n",
    "            x_tr = np.append(x_tr, [np.fliplr(x) for x in x_tr], axis=0)\n",
    "            x_train.append(x_tr)\n",
    "            x_valid.append(np.array(train_df.images[valid_index].tolist()).reshape(-1, IMG_ORI_SIZE, IMG_ORI_SIZE, 1))\n",
    "            y_tr = np.array(train_df.masks[train_index].tolist()).reshape(-1, IMG_ORI_SIZE, IMG_ORI_SIZE, 1)\n",
    "            y_tr = np.append(y_tr, [np.fliplr(y) for y in y_tr], axis=0)\n",
    "            y_train.append(y_tr)\n",
    "            y_valid.append(np.array(train_df.masks[valid_index].tolist()).reshape(-1, IMG_ORI_SIZE, IMG_ORI_SIZE, 1))\n",
    "            if not Kfold:\n",
    "                break\n",
    "        return x_train, x_valid, y_train, y_valid\n",
    "\n",
    "    def get_train(self):\n",
    "        return self.x_train, self.y_train\n",
    "    \n",
    "    def get_valid(self):\n",
    "        return self.x_valid, self.y_valid\n",
    "\n",
    "    def get_test_x(self):\n",
    "        return self.x_test\n",
    "\n",
    "    def get_test_df(self):\n",
    "        return self.test_df\n",
    "    \n",
    "class ShipDataset(Dataset):\n",
    "    def __init__(self, data, transform=None, mode='train'):\n",
    "        if mode == 'train' or mode == 'valid':\n",
    "            self.x = data[0]\n",
    "            self.y = data[1]\n",
    "        elif mode == 'test':\n",
    "            self.data = data\n",
    "        else:\n",
    "            raise RuntimeError('MODE_ERROR')\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "        self.pad_method = PAD_METHOD\n",
    "        self.pad_size = (IMG_TAR_SIZE-IMG_ORI_SIZE)//2\n",
    "        \n",
    "        if FIT_METHOD == 'resize_pad':\n",
    "            self.aug_func_eval = partial(resize_pad_seq_eval, self.pad_size)\n",
    "        elif FIT_METHOD == 'resize':\n",
    "            self.aug_func_eval = resize_seq_eval\n",
    "            \n",
    "        if AUG:\n",
    "            if FIT_METHOD == 'resize_pad':\n",
    "                self.aug_func = partial(resize_pad_seq, self.pad_size)\n",
    "            elif FIT_METHOD == 'resize':\n",
    "                self.aug_func = resize_seq\n",
    "        \n",
    "        if INPUT_CHANNEL == 3:\n",
    "            self.depth = np.tile(np.linspace(0,1,IMG_TAR_SIZE),[IMG_TAR_SIZE,1]).T\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.mode == 'train' or self.mode == 'valid':\n",
    "            return len(self.x)\n",
    "        elif self.mode == 'test':\n",
    "            return len(self.data)\n",
    "        else:\n",
    "            raise RuntimeError('MODE_ERROR')\n",
    "               \n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == 'train':\n",
    "            if AUG:\n",
    "                resize_seq_det = self.aug_func().to_deterministic()\n",
    "                new_x_batch = resize_seq_det.augment_image(self.x[idx])\n",
    "                new_x_batch = intensity_seq.augment_image(new_x_batch)/255\n",
    "                new_y_batch = resize_seq_det.augment_image(self.y[idx])/255\n",
    "            else:\n",
    "                resize_seq_det = self.aug_func_eval().to_deterministic()\n",
    "                new_x_batch = resize_seq_det.augment_image(self.x[idx])/255\n",
    "                new_y_batch = resize_seq_det.augment_image(self.y[idx])/255\n",
    "            if INPUT_CHANNEL == 3:\n",
    "                new_x_batch = np.tile(new_x_batch,(1,1,3))\n",
    "                new_x_batch = add_depth_channels(new_x_batch, self.depth)\n",
    "            return new_x_batch, new_y_batch\n",
    "        elif self.mode == 'valid':\n",
    "            resize_seq_det = self.aug_func_eval().to_deterministic()\n",
    "            new_x_batch = resize_seq_det.augment_image(self.x[idx])/255\n",
    "            new_y_batch = resize_seq_det.augment_image(self.y[idx])/255\n",
    "            if INPUT_CHANNEL == 3:\n",
    "                new_x_batch = np.tile(new_x_batch,(1,1,3))\n",
    "                new_x_batch = add_depth_channels(new_x_batch, self.depth)\n",
    "            return new_x_batch, new_y_batch\n",
    "        elif self.mode == 'test':\n",
    "            resize_seq_det = self.aug_func_eval()\n",
    "            test_data = resize_seq_det.augment_image(self.data[idx])/255\n",
    "            if INPUT_CHANNEL == 3:\n",
    "                test_data = np.tile(test_data,(1,1,3))\n",
    "                new_x_batch = add_depth_channels(test_data, self.depth)\n",
    "            return test_data\n",
    "        else:\n",
    "            raise RuntimeError('MODE_ERROR')\n",
    "            \n",
    "def make_loader(data, batch_size, num_workers=4, shuffle=False, transform=None, mode='train'):\n",
    "        return DataLoader(\n",
    "            dataset=ShipDataset(data, transform=transform, mode=mode),\n",
    "            shuffle=shuffle,\n",
    "            num_workers = num_workers,\n",
    "            batch_size = batch_size,\n",
    "            pin_memory=torch.cuda.is_available()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "47a024a662f85e6cbe936b1bce96d1c471533ddc"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f38825f3fdd64139b98ae0f6eb44bb59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8f53e4b959c408c8874219fdefec76c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dl = my_DataLoader(train=True, Kfold=KFOLD)\n",
    "x_train, y_train = dl.get_train()\n",
    "x_valid, y_valid = dl.get_valid()\n",
    "\n",
    "#Data augmentation\n",
    "#x_train = np.append(x_train, [np.fliplr(x) for x in x_train], axis=0)\n",
    "#y_train = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "dc7cb553fc8640deee4f67f53d19128da1e5737b"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "from torchvision import models\n",
    "import torchvision.models.resnet\n",
    "from torchvision.models.resnet import BasicBlock, Bottleneck\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "\"\"\"\n",
    "This script has been taken (and modified) from :\n",
    "https://github.com/ternaus/TernausNet\n",
    "@ARTICLE{arXiv:1801.05746,\n",
    "         author = {V. Iglovikov and A. Shvets},\n",
    "          title = {TernausNet: U-Net with VGG11 Encoder Pre-Trained on ImageNet for Image Segmentation},\n",
    "        journal = {ArXiv e-prints},\n",
    "         eprint = {1801.05746}, \n",
    "           year = 2018\n",
    "        }\n",
    "\"\"\"\n",
    "\n",
    "class ConvBn2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding),\n",
    "                                  nn.BatchNorm2d(out_channels),\n",
    "                                  )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class NoOperation(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "    \n",
    "class CSE(nn.Module):\n",
    "    def __init__(self, in_ch, r=2):\n",
    "        super(CSE, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.linear_1 = nn.Linear(in_ch, in_ch//r)\n",
    "        self.linear_2 = nn.Linear(in_ch//r, in_ch)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, channel_num, _, _ = x.size()\n",
    "        input_x = x\n",
    "\n",
    "        x = self.avg_pool(x).view(batch_size, channel_num)\n",
    "        x = F.relu(self.linear_1(x), inplace=True)\n",
    "        x = self.linear_2(x)\n",
    "        x = x.unsqueeze(-1).unsqueeze(-1)\n",
    "        x = torch.sigmoid(x)\n",
    "\n",
    "        x = torch.mul(x, input_x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class SSE(nn.Module):\n",
    "    def __init__(self, in_ch):\n",
    "        super(SSE, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, 1, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_x = x\n",
    "\n",
    "        x = self.conv(x)\n",
    "        x = torch.sigmoid(x)\n",
    "\n",
    "        x = torch.mul(x, input_x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class SCSE(nn.Module):\n",
    "    def __init__(self, in_ch, r=2):\n",
    "        super(SCSE, self).__init__()\n",
    "\n",
    "        self.cSE = CSE(in_ch, r)\n",
    "        self.sSE = SSE(in_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        cSE = self.cSE(x)\n",
    "        sSE = self.sSE(x)\n",
    "\n",
    "        x = torch.add(cSE,sSE)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_channels, middle_channels, out_channels):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.conv1 = ConvBn2d(in_channels, middle_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = ConvBn2d(middle_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.SCSE = SCSE(out_channels)\n",
    "        \n",
    "    def forward(self, x, e=None):\n",
    "        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        \n",
    "        if e is not None:\n",
    "            x = torch.cat([x,e], 1)\n",
    "            x = F.dropout2d(x, p = 0.50)\n",
    "            \n",
    "        x = F.relu(self.conv1(x), inplace=True)\n",
    "        x = F.relu(self.conv2(x), inplace=True)\n",
    "        x = self.SCSE(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNetResNet34_DS(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout_2d=0.2, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.dropout_2d = dropout_2d\n",
    "\n",
    "        self.resnet = torchvision.models.resnet34(pretrained=pretrained)\n",
    "\n",
    "        self.encoder1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=1, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.encoder2 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            self.resnet.layer1,\n",
    "        )\n",
    "        self.encoder3 = self.resnet.layer2\n",
    "        self.encoder4 = self.resnet.layer3\n",
    "        self.encoder5 = self.resnet.layer4\n",
    "        \n",
    "        self.center = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            )\n",
    "\n",
    "        self.decoder5 = Decoder(256+512, 512, 64)\n",
    "        self.decoder4 = Decoder( 64+256, 256, 64)\n",
    "        self.decoder3 = Decoder( 64+128, 128, 64)\n",
    "        self.decoder2 = Decoder( 64+ 64,  64, 64)\n",
    "        self.decoder1 = Decoder( 64+ 64,  32, 64)\n",
    "        \n",
    "        self.fuse_pixel = nn.Sequential(\n",
    "            nn.Conv2d(320, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.logit_pixel  = nn.Sequential(\n",
    "            nn.Conv2d( 64, 1, kernel_size=1, padding=0),\n",
    "        )\n",
    "        \n",
    "        self.fuse_image = nn.Sequential(\n",
    "            nn.Conv2d(512, 64, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.logit_image = nn.Sequential(\n",
    "            nn.Linear(64, 2),\n",
    "        )\n",
    "        \n",
    "        self.logit = nn.Sequential(\n",
    "            nn.Conv2d(64+64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d( 64,  1, kernel_size=1, padding=0),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, C, H, W = x.shape\n",
    "        mean= [0.485, 0.456, 0.406]\n",
    "        std = [0.229, 0.224, 0.225]\n",
    "        x = torch.cat([\n",
    "            (x-mean[2])/std[2],\n",
    "            (x-mean[1])/std[1],\n",
    "            (x-mean[0])/std[0],\n",
    "        ],1)\n",
    "        \"\"\"\n",
    "        if INPUT_CHANNEL == 1:\n",
    "            x = torch.cat([x,x,x],1)\n",
    "        \"\"\"\n",
    "        \n",
    "        e1 = self.encoder1(x) #;print('e1', e1.size())\n",
    "        e2 = self.encoder2(e1)#;print('e2', e2.size())\n",
    "        e3 = self.encoder3(e2)#;print('e3', e3.size())\n",
    "        e4 = self.encoder4(e3)#;print('e4', e4.size())\n",
    "        e5 = self.encoder5(e4)#;print('e5', e5.size())\n",
    "        \n",
    "        f = self.center(e5)        #;print('f', f.size())\n",
    "        \n",
    "        d5 = self.decoder5(f,e5)   #;print('d5', d5.size())\n",
    "        d4 = self.decoder4(d5,e4)  #;print('d4', d4.size())\n",
    "        d3 = self.decoder3(d4,e3)  #;print('d3', d3.size())\n",
    "        d2 = self.decoder2(d3,e2)  #;print('d2', d2.size())\n",
    "        d1 = self.decoder1(d2,e1)  #;print('d1', d1.size())\n",
    "        \n",
    "        #hyper column\n",
    "        d = torch.cat((\n",
    "            d1,\n",
    "            F.interpolate(d2, scale_factor= 2, mode='bilinear', align_corners=False),\n",
    "            F.interpolate(d3, scale_factor= 4, mode='bilinear', align_corners=False),\n",
    "            F.interpolate(d4, scale_factor= 8, mode='bilinear', align_corners=False),\n",
    "            F.interpolate(d5, scale_factor=16, mode='bilinear', align_corners=False),\n",
    "        ), 1)\n",
    "        d = F.dropout2d(d, p=self.dropout_2d)\n",
    "        fuse_pixel = self.fuse_pixel(d)\n",
    "        logit_pixel = self.logit_pixel(fuse_pixel)\n",
    "        \n",
    "        e = F.adaptive_avg_pool2d(e5, output_size=[1,1])\n",
    "        e = F.dropout(e, p=self.dropout_2d)\n",
    "        fuse_image = self.fuse_image(e)\n",
    "        fuse_image_flatten = fuse_image.view(fuse_image.size(0), -1)\n",
    "        logit_image = self.logit_image(fuse_image_flatten)\n",
    "        \n",
    "        logit = self.logit(torch.cat([\n",
    "            fuse_pixel, \n",
    "            F.interpolate(fuse_image.view(batch_size,-1,1,1,),scale_factor=128, mode='nearest')],1))\n",
    "\n",
    "        return logit, logit_pixel, logit_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "2dcfe44283aa19b30ca4c79883149441d50471db"
   },
   "outputs": [],
   "source": [
    "def validation_phrase0(model, criterion, valid_loader):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    iou = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in valid_loader:\n",
    "            inputs = inputs.permute(0,3,1,2).type(torch.FloatTensor).to(device)\n",
    "            truth_image = get_true_target(targets)\n",
    "            targets = targets.permute(0,3,1,2).type(torch.FloatTensor).to(device)\n",
    "            outputs, outputs_pixel, outputs_image = model(inputs)\n",
    "            loss = criterion(outputs, outputs_pixel, outputs_image, targets, truth_image)\n",
    "            losses += [loss.item()]\n",
    "            iou += [my_iou_metric_pad(get_numpy(targets), get_numpy(outputs))]\n",
    "\n",
    "        valid_loss = np.mean(losses)  # type: float\n",
    "\n",
    "        valid_iou = np.mean(iou)\n",
    "\n",
    "        metrics = {'val_loss': valid_loss, 'val_iou': valid_iou}\n",
    "    return metrics\n",
    "\n",
    "def train_phrase0(model, criterion, train_loader, optimizer, epoch, \n",
    "          scheduler, report_each=10, valid_iou=0):\n",
    "        model.train()\n",
    "        random.seed()\n",
    "        scheduler.step(valid_iou)\n",
    "        lr = optimizer.param_groups[0]['lr']\n",
    "        print('Current learning rate: {:.4f}'.format(lr))\n",
    "        losses = []\n",
    "        ious = []\n",
    "        tl = train_loader\n",
    "        \n",
    "        try:\n",
    "            mean_loss = 0\n",
    "            mean_iou = 0\n",
    "            for i, (inputs, targets) in enumerate(tl):\n",
    "                inputs = inputs.permute(0,3,1,2).type(torch.FloatTensor).to(device)\n",
    "                truth_image = get_true_target(targets)\n",
    "                targets = targets.permute(0,3,1,2).type(torch.FloatTensor).to(device)\n",
    "                outputs, outputs_pixel, outputs_image = model(inputs)\n",
    "                loss = criterion(outputs, outputs_pixel, outputs_image, targets, truth_image)\n",
    "                optimizer.zero_grad()\n",
    "                batch_size = inputs.size(0)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                losses += [loss.item()]\n",
    "                ious += [my_iou_metric_pad(get_numpy(targets), get_numpy(outputs))]\n",
    "                mean_loss = np.mean(losses[-report_each:])\n",
    "                mean_iou = np.mean(ious[-report_each:])\n",
    "\n",
    "                if i % report_each == 0:\n",
    "                    print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                          'Loss {loss:.4f} ({loss_avg:.4f})\\t'\n",
    "                          'IOU {iou:.3f} ({iou_avg:.3f})'.format(\n",
    "                           epoch, i, len(tl), loss=losses[-1], loss_avg=mean_loss, iou=ious[-1], iou_avg=mean_iou))\n",
    "\n",
    "            metrics = {'train_loss': mean_loss, 'train_iou': mean_iou}\n",
    "            return metrics\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print('Ctrl+C, saving snapshot')\n",
    "            print('done.')\n",
    "            return\n",
    "\n",
    "\n",
    "def validation_phrase1(model, criterion, valid_loader):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    iou = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in valid_loader:\n",
    "            inputs = inputs.permute(0,3,1,2).type(torch.FloatTensor).to(device)\n",
    "            truth_image = get_true_target(targets)\n",
    "            targets = targets.permute(0,3,1,2).type(torch.FloatTensor).to(device)\n",
    "            outputs, outputs_pixel, outputs_image = model(inputs)\n",
    "            loss = criterion(outputs, outputs_pixel, outputs_image, targets, truth_image)\n",
    "            losses += [loss.item()]\n",
    "            iou += [my_iou_metric_2(get_numpy(targets), get_numpy(outputs))]\n",
    "\n",
    "        valid_loss = np.mean(losses)  # type: float\n",
    "\n",
    "        valid_iou = np.mean(iou)\n",
    "\n",
    "        metrics = {'val_loss': valid_loss, 'val_iou': valid_iou}\n",
    "    return metrics\n",
    "\n",
    "def train_phrase1(model, criterion, train_loader, optimizer, epoch, \n",
    "          scheduler, report_each=10, valid_iou=0):\n",
    "        model.train()\n",
    "        random.seed()\n",
    "        scheduler.step()\n",
    "        lr = optimizer.param_groups[0]['lr']\n",
    "        print('change learning rate into: {:.4f}'.format(lr))\n",
    "        losses = []\n",
    "        ious = []\n",
    "        tl = train_loader\n",
    "        \n",
    "        try:\n",
    "            mean_loss = 0\n",
    "            mean_iou = 0\n",
    "            for i, (inputs, targets) in enumerate(tl):\n",
    "                inputs = inputs.permute(0,3,1,2).type(torch.FloatTensor).to(device)\n",
    "                truth_image = get_true_target(targets)\n",
    "                targets = targets.permute(0,3,1,2).type(torch.FloatTensor).to(device)\n",
    "                outputs, outputs_pixel, outputs_image = model(inputs)\n",
    "                loss = criterion(outputs, outputs_pixel, outputs_image, targets, truth_image)\n",
    "                optimizer.zero_grad()\n",
    "                batch_size = inputs.size(0)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                losses += [loss.item()]\n",
    "                ious += [my_iou_metric_2(get_numpy(targets), get_numpy(outputs))]\n",
    "                mean_loss = np.mean(losses[-report_each:])\n",
    "                mean_iou = np.mean(ious[-report_each:])\n",
    "                \n",
    "                for param_group in optimizer.param_groups:\n",
    "                    lr = param_group['lr']\n",
    "\n",
    "                if i % report_each == 0:\n",
    "                    print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                          'Loss {loss:.4f} ({loss_avg:.4f})\\t'\n",
    "                          'IOU {iou:.3f} ({iou_avg:.3f})'.format(\n",
    "                           epoch, i, len(tl), loss=losses[-1], loss_avg=mean_loss, iou=ious[-1], iou_avg=mean_iou))\n",
    "\n",
    "            metrics = {'train_loss': mean_loss, 'train_iou': mean_iou}\n",
    "            return metrics\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print('Ctrl+C, saving snapshot')\n",
    "            print('done.')\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "c4583b6471c8dd706f573c121a12ae447cd01f6c"
   },
   "outputs": [],
   "source": [
    "criterion_phrase0 = Fuse_Loss(pixel_loss_func=Dice_Bce_Loss()).to(device)\n",
    "criterion_phrase1 = Fuse_Loss(pixel_loss_func=Lovaz_Loss()).to(device)\n",
    "#early_stop = EarlyStopping(mode='max', min_delta=0, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "83b13bf870a9ae1557884f62cc299b9c2dc3f312"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: [4]\t\n",
      "Current learning rate: 0.0100\n",
      "Epoch: [0][0/201]\tLoss 1.6327 (1.6327)\tIOU 0.088 (0.088)\n",
      "Epoch: [0][20/201]\tLoss 1.4321 (1.5310)\tIOU 0.469 (0.380)\n",
      "Epoch: [0][40/201]\tLoss 1.4405 (1.4412)\tIOU 0.562 (0.438)\n",
      "Epoch: [0][60/201]\tLoss 1.4068 (1.4225)\tIOU 0.312 (0.402)\n",
      "Epoch: [0][80/201]\tLoss 1.4448 (1.4216)\tIOU 0.375 (0.427)\n",
      "Epoch: [0][100/201]\tLoss 1.3599 (1.4093)\tIOU 0.375 (0.411)\n",
      "Epoch: [0][120/201]\tLoss 1.3316 (1.3880)\tIOU 0.344 (0.445)\n",
      "Epoch: [0][140/201]\tLoss 1.4006 (1.3655)\tIOU 0.469 (0.439)\n",
      "Epoch: [0][160/201]\tLoss 1.3353 (1.3884)\tIOU 0.375 (0.458)\n",
      "Epoch: [0][180/201]\tLoss 1.3422 (1.3689)\tIOU 0.344 (0.452)\n",
      "Epoch: [0][200/201]\tLoss 1.5817 (1.3859)\tIOU 0.375 (0.450)\n",
      "Epoch: [0][Validation]\tVal_Loss: 1.36004\tVal_IOU: 0.39045\tBest Val_IOU: 0.39045\n",
      "epoch time:  96.751473903656\n",
      "Current learning rate: 0.0100\n",
      "Epoch: [1][0/201]\tLoss 1.4490 (1.4490)\tIOU 0.500 (0.500)\n",
      "Epoch: [1][20/201]\tLoss 1.4215 (1.3581)\tIOU 0.562 (0.430)\n",
      "Epoch: [1][40/201]\tLoss 1.3839 (1.3425)\tIOU 0.438 (0.422)\n",
      "Epoch: [1][60/201]\tLoss 1.3178 (1.3673)\tIOU 0.312 (0.425)\n",
      "Epoch: [1][80/201]\tLoss 1.3477 (1.3423)\tIOU 0.531 (0.430)\n",
      "Epoch: [1][100/201]\tLoss 1.2809 (1.3631)\tIOU 0.312 (0.436)\n",
      "Epoch: [1][120/201]\tLoss 1.3033 (1.3673)\tIOU 0.469 (0.459)\n",
      "Epoch: [1][140/201]\tLoss 1.4250 (1.3537)\tIOU 0.406 (0.392)\n",
      "Epoch: [1][160/201]\tLoss 1.3103 (1.3519)\tIOU 0.447 (0.463)\n",
      "Epoch: [1][180/201]\tLoss 1.1761 (1.2827)\tIOU 0.734 (0.573)\n",
      "Epoch: [1][200/201]\tLoss 1.0987 (1.2754)\tIOU 0.863 (0.621)\n",
      "Epoch: [1][Validation]\tVal_Loss: 1.26842\tVal_IOU: 0.57845\tBest Val_IOU: 0.57845\n",
      "epoch time:  95.74372720718384\n",
      "Current learning rate: 0.0100\n",
      "Epoch: [2][0/201]\tLoss 1.3279 (1.3279)\tIOU 0.559 (0.559)\n",
      "Epoch: [2][20/201]\tLoss 1.1927 (1.2693)\tIOU 0.613 (0.621)\n",
      "Epoch: [2][40/201]\tLoss 1.2239 (1.2806)\tIOU 0.672 (0.634)\n",
      "Epoch: [2][60/201]\tLoss 1.1917 (1.2723)\tIOU 0.669 (0.643)\n",
      "Epoch: [2][80/201]\tLoss 1.3363 (1.2739)\tIOU 0.637 (0.614)\n",
      "Epoch: [2][100/201]\tLoss 1.1510 (1.2266)\tIOU 0.759 (0.678)\n",
      "Epoch: [2][120/201]\tLoss 1.2023 (1.2539)\tIOU 0.756 (0.642)\n",
      "Epoch: [2][140/201]\tLoss 1.2115 (1.2404)\tIOU 0.756 (0.662)\n",
      "Epoch: [2][160/201]\tLoss 1.2025 (1.2446)\tIOU 0.725 (0.685)\n",
      "Epoch: [2][180/201]\tLoss 1.2967 (1.2290)\tIOU 0.544 (0.695)\n",
      "Epoch: [2][200/201]\tLoss 1.1574 (1.2539)\tIOU 0.662 (0.668)\n",
      "Epoch: [2][Validation]\tVal_Loss: 1.23513\tVal_IOU: 0.71353\tBest Val_IOU: 0.71353\n",
      "epoch time:  96.30938267707825\n",
      "Current learning rate: 0.0100\n",
      "Epoch: [3][0/201]\tLoss 1.2770 (1.2770)\tIOU 0.834 (0.834)\n",
      "Epoch: [3][20/201]\tLoss 1.1859 (1.2451)\tIOU 0.616 (0.686)\n",
      "Epoch: [3][40/201]\tLoss 1.2154 (1.2273)\tIOU 0.688 (0.695)\n",
      "Epoch: [3][60/201]\tLoss 1.2400 (1.2356)\tIOU 0.756 (0.693)\n",
      "Epoch: [3][80/201]\tLoss 1.2807 (1.2378)\tIOU 0.637 (0.679)\n",
      "Epoch: [3][100/201]\tLoss 1.1402 (1.2301)\tIOU 0.744 (0.734)\n",
      "Epoch: [3][120/201]\tLoss 1.2482 (1.2359)\tIOU 0.703 (0.725)\n",
      "Epoch: [3][140/201]\tLoss 1.1431 (1.2329)\tIOU 0.741 (0.731)\n",
      "Epoch: [3][160/201]\tLoss 1.2528 (1.2301)\tIOU 0.675 (0.722)\n",
      "Epoch: [3][180/201]\tLoss 1.3765 (1.2393)\tIOU 0.528 (0.677)\n",
      "Epoch: [3][200/201]\tLoss 1.1612 (1.2427)\tIOU 0.838 (0.719)\n",
      "Epoch: [3][Validation]\tVal_Loss: 1.22894\tVal_IOU: 0.70733\tBest Val_IOU: 0.71353\n",
      "epoch time:  94.54024577140808\n",
      "Current learning rate: 0.0100\n",
      "Epoch: [4][0/201]\tLoss 1.1727 (1.1727)\tIOU 0.719 (0.719)\n",
      "Epoch: [4][20/201]\tLoss 1.2776 (1.2467)\tIOU 0.794 (0.734)\n",
      "Epoch: [4][40/201]\tLoss 1.2784 (1.2217)\tIOU 0.613 (0.735)\n",
      "Epoch: [4][60/201]\tLoss 1.1507 (1.2392)\tIOU 0.772 (0.733)\n",
      "Epoch: [4][80/201]\tLoss 1.2159 (1.2295)\tIOU 0.725 (0.740)\n",
      "Epoch: [4][100/201]\tLoss 1.3439 (1.2219)\tIOU 0.616 (0.730)\n",
      "Epoch: [4][120/201]\tLoss 1.2942 (1.2320)\tIOU 0.650 (0.767)\n",
      "Epoch: [4][140/201]\tLoss 1.0864 (1.2196)\tIOU 0.853 (0.745)\n",
      "Epoch: [4][160/201]\tLoss 1.2009 (1.2471)\tIOU 0.725 (0.720)\n",
      "Epoch: [4][180/201]\tLoss 1.2177 (1.2227)\tIOU 0.606 (0.710)\n",
      "Epoch: [4][200/201]\tLoss 1.0966 (1.1960)\tIOU 0.662 (0.737)\n",
      "Epoch: [4][Validation]\tVal_Loss: 1.23303\tVal_IOU: 0.71908\tBest Val_IOU: 0.71908\n",
      "epoch time:  95.64684915542603\n",
      "Current learning rate: 0.0100\n",
      "Epoch: [5][0/201]\tLoss 1.1925 (1.1925)\tIOU 0.744 (0.744)\n",
      "Epoch: [5][20/201]\tLoss 1.3116 (1.2372)\tIOU 0.659 (0.725)\n",
      "Epoch: [5][40/201]\tLoss 1.2164 (1.2496)\tIOU 0.722 (0.753)\n",
      "Epoch: [5][60/201]\tLoss 1.2063 (1.2200)\tIOU 0.734 (0.742)\n",
      "Epoch: [5][80/201]\tLoss 1.2007 (1.2066)\tIOU 0.769 (0.758)\n",
      "Epoch: [5][100/201]\tLoss 1.1821 (1.1776)\tIOU 0.738 (0.756)\n",
      "Epoch: [5][120/201]\tLoss 1.1603 (1.2541)\tIOU 0.716 (0.729)\n",
      "Epoch: [5][140/201]\tLoss 1.2183 (1.2067)\tIOU 0.616 (0.751)\n",
      "Epoch: [5][160/201]\tLoss 1.2850 (1.2756)\tIOU 0.641 (0.741)\n",
      "Epoch: [5][180/201]\tLoss 1.2993 (1.2161)\tIOU 0.566 (0.742)\n",
      "Epoch: [5][200/201]\tLoss 1.1382 (1.2133)\tIOU 0.850 (0.783)\n",
      "Epoch: [5][Validation]\tVal_Loss: 1.23073\tVal_IOU: 0.73190\tBest Val_IOU: 0.73190\n",
      "epoch time:  96.15927934646606\n",
      "Current learning rate: 0.0100\n",
      "Epoch: [6][0/201]\tLoss 1.0815 (1.0815)\tIOU 0.812 (0.812)\n",
      "Epoch: [6][20/201]\tLoss 1.1997 (1.2128)\tIOU 0.719 (0.742)\n",
      "Epoch: [6][40/201]\tLoss 1.2605 (1.2194)\tIOU 0.819 (0.727)\n",
      "Epoch: [6][60/201]\tLoss 1.1871 (1.2083)\tIOU 0.734 (0.750)\n",
      "Epoch: [6][80/201]\tLoss 1.1612 (1.2233)\tIOU 0.847 (0.742)\n",
      "Epoch: [6][100/201]\tLoss 1.1915 (1.2179)\tIOU 0.719 (0.758)\n",
      "Epoch: [6][120/201]\tLoss 1.2433 (1.2205)\tIOU 0.850 (0.782)\n",
      "Epoch: [6][140/201]\tLoss 1.1808 (1.2211)\tIOU 0.612 (0.761)\n",
      "Epoch: [6][160/201]\tLoss 1.2110 (1.2133)\tIOU 0.747 (0.770)\n",
      "Epoch: [6][180/201]\tLoss 1.1868 (1.2551)\tIOU 0.791 (0.754)\n",
      "Epoch: [6][200/201]\tLoss 1.1777 (1.2469)\tIOU 0.712 (0.747)\n",
      "Epoch: [6][Validation]\tVal_Loss: 1.22488\tVal_IOU: 0.75173\tBest Val_IOU: 0.75173\n",
      "epoch time:  96.04512739181519\n",
      "Current learning rate: 0.0100\n",
      "Epoch: [7][0/201]\tLoss 1.2842 (1.2842)\tIOU 0.787 (0.787)\n",
      "Epoch: [7][20/201]\tLoss 1.2588 (1.1961)\tIOU 0.725 (0.785)\n",
      "Epoch: [7][40/201]\tLoss 1.2229 (1.2197)\tIOU 0.769 (0.770)\n",
      "Epoch: [7][60/201]\tLoss 1.1998 (1.2291)\tIOU 0.784 (0.773)\n",
      "Epoch: [7][80/201]\tLoss 1.3201 (1.1976)\tIOU 0.762 (0.779)\n",
      "Epoch: [7][100/201]\tLoss 1.2595 (1.2194)\tIOU 0.725 (0.748)\n",
      "Epoch: [7][120/201]\tLoss 1.1859 (1.2155)\tIOU 0.838 (0.756)\n",
      "Epoch: [7][140/201]\tLoss 1.1591 (1.1896)\tIOU 0.872 (0.781)\n",
      "Epoch: [7][160/201]\tLoss 1.1531 (1.2205)\tIOU 0.766 (0.776)\n",
      "Epoch: [7][180/201]\tLoss 1.2527 (1.2335)\tIOU 0.672 (0.775)\n",
      "Epoch: [7][200/201]\tLoss 1.4417 (1.2422)\tIOU 0.812 (0.752)\n",
      "Epoch: [7][Validation]\tVal_Loss: 1.22423\tVal_IOU: 0.76532\tBest Val_IOU: 0.76532\n",
      "epoch time:  96.30915951728821\n",
      "Current learning rate: 0.0100\n",
      "Epoch: [8][0/201]\tLoss 1.1347 (1.1347)\tIOU 0.806 (0.806)\n",
      "Epoch: [8][20/201]\tLoss 1.2423 (1.2158)\tIOU 0.841 (0.777)\n",
      "Epoch: [8][40/201]\tLoss 1.2868 (1.2243)\tIOU 0.691 (0.759)\n",
      "Epoch: [8][60/201]\tLoss 1.0963 (1.2094)\tIOU 0.784 (0.754)\n",
      "Epoch: [8][80/201]\tLoss 1.2980 (1.2040)\tIOU 0.759 (0.778)\n",
      "Epoch: [8][100/201]\tLoss 1.1779 (1.2127)\tIOU 0.694 (0.765)\n",
      "Epoch: [8][120/201]\tLoss 1.2629 (1.2283)\tIOU 0.816 (0.754)\n",
      "Epoch: [8][140/201]\tLoss 1.2356 (1.1899)\tIOU 0.794 (0.766)\n",
      "Epoch: [8][160/201]\tLoss 1.3382 (1.2459)\tIOU 0.719 (0.778)\n",
      "Epoch: [8][180/201]\tLoss 1.3839 (1.2280)\tIOU 0.700 (0.760)\n",
      "Epoch: [8][200/201]\tLoss 1.1498 (1.2136)\tIOU 0.812 (0.796)\n",
      "Epoch: [8][Validation]\tVal_Loss: 1.21819\tVal_IOU: 0.75836\tBest Val_IOU: 0.76532\n",
      "epoch time:  94.00385022163391\n",
      "Current learning rate: 0.0100\n",
      "Epoch: [9][0/201]\tLoss 1.0976 (1.0976)\tIOU 0.778 (0.778)\n",
      "Epoch: [9][20/201]\tLoss 1.1392 (1.2083)\tIOU 0.753 (0.784)\n",
      "Epoch: [9][40/201]\tLoss 1.0890 (1.1822)\tIOU 0.894 (0.809)\n",
      "Epoch: [9][60/201]\tLoss 1.2702 (1.2047)\tIOU 0.619 (0.767)\n",
      "Epoch: [9][80/201]\tLoss 1.2242 (1.1843)\tIOU 0.803 (0.782)\n",
      "Epoch: [9][100/201]\tLoss 1.1231 (1.2077)\tIOU 0.744 (0.794)\n",
      "Epoch: [9][120/201]\tLoss 1.5022 (1.2429)\tIOU 0.634 (0.763)\n",
      "Epoch: [9][140/201]\tLoss 1.2446 (1.2259)\tIOU 0.847 (0.772)\n",
      "Epoch: [9][160/201]\tLoss 1.2151 (1.2303)\tIOU 0.834 (0.782)\n",
      "Epoch: [9][180/201]\tLoss 1.2076 (1.2056)\tIOU 0.775 (0.782)\n",
      "Epoch: [9][200/201]\tLoss 1.1661 (1.2258)\tIOU 0.850 (0.784)\n",
      "Epoch: [9][Validation]\tVal_Loss: 1.21394\tVal_IOU: 0.77758\tBest Val_IOU: 0.77758\n",
      "epoch time:  95.94153690338135\n",
      "Current learning rate: 0.0100\n",
      "Epoch: [10][0/201]\tLoss 1.1985 (1.1985)\tIOU 0.837 (0.837)\n",
      "Epoch: [10][20/201]\tLoss 1.2813 (1.2112)\tIOU 0.622 (0.792)\n",
      "Epoch: [10][40/201]\tLoss 1.2467 (1.2191)\tIOU 0.778 (0.797)\n",
      "Epoch: [10][60/201]\tLoss 1.4099 (1.2014)\tIOU 0.656 (0.790)\n",
      "Epoch: [10][80/201]\tLoss 1.1999 (1.1992)\tIOU 0.713 (0.777)\n",
      "Epoch: [10][100/201]\tLoss 1.3928 (1.2216)\tIOU 0.678 (0.759)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][120/201]\tLoss 1.2565 (1.1908)\tIOU 0.762 (0.762)\n",
      "Epoch: [10][140/201]\tLoss 1.2285 (1.2021)\tIOU 0.856 (0.805)\n",
      "Epoch: [10][160/201]\tLoss 1.3878 (1.2466)\tIOU 0.744 (0.777)\n",
      "Epoch: [10][180/201]\tLoss 1.1873 (1.2132)\tIOU 0.881 (0.779)\n",
      "Epoch: [10][200/201]\tLoss 1.1966 (1.2138)\tIOU 0.825 (0.793)\n",
      "Epoch: [10][Validation]\tVal_Loss: 1.21773\tVal_IOU: 0.76690\tBest Val_IOU: 0.77758\n",
      "epoch time:  93.86534810066223\n",
      "Current learning rate: 0.0100\n",
      "Epoch: [11][0/201]\tLoss 1.4025 (1.4025)\tIOU 0.738 (0.738)\n",
      "Epoch: [11][20/201]\tLoss 1.2395 (1.2302)\tIOU 0.762 (0.770)\n",
      "Epoch: [11][40/201]\tLoss 1.1516 (1.1936)\tIOU 0.825 (0.786)\n",
      "Epoch: [11][60/201]\tLoss 1.3477 (1.2282)\tIOU 0.681 (0.764)\n",
      "Epoch: [11][80/201]\tLoss 1.1099 (1.1966)\tIOU 0.728 (0.778)\n",
      "Epoch: [11][100/201]\tLoss 1.1748 (1.1963)\tIOU 0.847 (0.768)\n",
      "Epoch: [11][120/201]\tLoss 1.1903 (1.2087)\tIOU 0.819 (0.792)\n",
      "Epoch: [11][140/201]\tLoss 1.0603 (1.2075)\tIOU 0.753 (0.810)\n",
      "Epoch: [11][160/201]\tLoss 1.1175 (1.2111)\tIOU 0.859 (0.801)\n",
      "Epoch: [11][180/201]\tLoss 1.1946 (1.2098)\tIOU 0.809 (0.797)\n",
      "Epoch: [11][200/201]\tLoss 1.4255 (1.2079)\tIOU 0.500 (0.779)\n",
      "Epoch: [11][Validation]\tVal_Loss: 1.21392\tVal_IOU: 0.78087\tBest Val_IOU: 0.78087\n",
      "epoch time:  95.80400466918945\n",
      "Current learning rate: 0.0100\n",
      "Epoch: [12][0/201]\tLoss 1.2174 (1.2174)\tIOU 0.819 (0.819)\n",
      "Epoch: [12][20/201]\tLoss 1.1973 (1.1764)\tIOU 0.831 (0.824)\n",
      "Epoch: [12][40/201]\tLoss 1.0900 (1.2190)\tIOU 0.825 (0.778)\n",
      "Epoch: [12][60/201]\tLoss 1.1685 (1.1974)\tIOU 0.816 (0.797)\n",
      "Epoch: [12][80/201]\tLoss 1.1564 (1.1953)\tIOU 0.766 (0.760)\n",
      "Epoch: [12][100/201]\tLoss 1.1266 (1.1906)\tIOU 0.831 (0.805)\n",
      "Epoch: [12][120/201]\tLoss 1.2052 (1.2082)\tIOU 0.831 (0.804)\n",
      "Epoch: [12][140/201]\tLoss 1.2254 (1.2321)\tIOU 0.834 (0.793)\n",
      "Epoch: [12][160/201]\tLoss 1.2016 (1.2064)\tIOU 0.847 (0.803)\n",
      "Epoch: [12][180/201]\tLoss 1.3798 (1.2297)\tIOU 0.738 (0.794)\n",
      "Epoch: [12][200/201]\tLoss 1.1081 (1.1909)\tIOU 0.762 (0.803)\n",
      "Epoch: [12][Validation]\tVal_Loss: 1.21478\tVal_IOU: 0.76873\tBest Val_IOU: 0.78087\n",
      "epoch time:  94.92539191246033\n",
      "Current learning rate: 0.0100\n",
      "Epoch: [13][0/201]\tLoss 1.0707 (1.0707)\tIOU 0.847 (0.847)\n",
      "Epoch: [13][20/201]\tLoss 1.2581 (1.2164)\tIOU 0.881 (0.787)\n",
      "Epoch: [13][40/201]\tLoss 1.2324 (1.2138)\tIOU 0.719 (0.784)\n",
      "Epoch: [13][60/201]\tLoss 1.1756 (1.2014)\tIOU 0.803 (0.831)\n",
      "Epoch: [13][80/201]\tLoss 1.0963 (1.2067)\tIOU 0.709 (0.805)\n",
      "Epoch: [13][100/201]\tLoss 1.1719 (1.1943)\tIOU 0.809 (0.819)\n",
      "Epoch: [13][120/201]\tLoss 1.0742 (1.1823)\tIOU 0.847 (0.825)\n",
      "Epoch: [13][140/201]\tLoss 1.2804 (1.1996)\tIOU 0.775 (0.799)\n",
      "Epoch: [13][160/201]\tLoss 1.3695 (1.2209)\tIOU 0.709 (0.799)\n",
      "Epoch: [13][180/201]\tLoss 1.1709 (1.1726)\tIOU 0.881 (0.829)\n",
      "Epoch: [13][200/201]\tLoss 1.1417 (1.2115)\tIOU 0.963 (0.817)\n",
      "Epoch: [13][Validation]\tVal_Loss: 1.21701\tVal_IOU: 0.77431\tBest Val_IOU: 0.78087\n",
      "epoch time:  94.57668161392212\n",
      "Current learning rate: 0.0100\n",
      "Epoch: [14][0/201]\tLoss 1.3345 (1.3345)\tIOU 0.784 (0.784)\n",
      "Epoch: [14][20/201]\tLoss 1.2328 (1.2049)\tIOU 0.809 (0.792)\n",
      "Epoch: [14][40/201]\tLoss 1.1700 (1.1862)\tIOU 0.825 (0.832)\n",
      "Epoch: [14][60/201]\tLoss 1.2488 (1.2003)\tIOU 0.647 (0.791)\n",
      "Epoch: [14][80/201]\tLoss 1.2308 (1.1916)\tIOU 0.753 (0.830)\n",
      "Epoch: [14][100/201]\tLoss 1.2927 (1.1910)\tIOU 0.775 (0.797)\n",
      "Epoch: [14][120/201]\tLoss 1.1367 (1.2075)\tIOU 0.759 (0.808)\n",
      "Epoch: [14][140/201]\tLoss 1.3188 (1.2000)\tIOU 0.728 (0.817)\n",
      "Epoch: [14][160/201]\tLoss 1.1943 (1.2135)\tIOU 0.812 (0.800)\n",
      "Epoch: [14][180/201]\tLoss 1.2084 (1.1886)\tIOU 0.809 (0.820)\n",
      "Epoch: [14][200/201]\tLoss 1.2554 (1.2053)\tIOU 0.638 (0.813)\n",
      "Epoch: [14][Validation]\tVal_Loss: 1.21255\tVal_IOU: 0.78527\tBest Val_IOU: 0.78527\n",
      "epoch time:  96.36250162124634\n",
      "Current learning rate: 0.0100\n",
      "Epoch: [15][0/201]\tLoss 1.0810 (1.0810)\tIOU 0.906 (0.906)\n",
      "Epoch: [15][20/201]\tLoss 1.1813 (1.1890)\tIOU 0.897 (0.805)\n",
      "Epoch: [15][40/201]\tLoss 1.2674 (1.2076)\tIOU 0.725 (0.797)\n",
      "Epoch: [15][60/201]\tLoss 1.2039 (1.1891)\tIOU 0.797 (0.820)\n",
      "Epoch: [15][80/201]\tLoss 1.1015 (1.2200)\tIOU 0.809 (0.815)\n",
      "Epoch: [15][100/201]\tLoss 1.2445 (1.2151)\tIOU 0.725 (0.811)\n",
      "Epoch: [15][120/201]\tLoss 1.1089 (1.1767)\tIOU 0.759 (0.814)\n",
      "Epoch: [15][140/201]\tLoss 1.2850 (1.1841)\tIOU 0.812 (0.816)\n",
      "Epoch: [15][160/201]\tLoss 1.1379 (1.2228)\tIOU 0.772 (0.794)\n",
      "Epoch: [15][180/201]\tLoss 1.2017 (1.1897)\tIOU 0.828 (0.817)\n",
      "Epoch: [15][200/201]\tLoss 1.3537 (1.2059)\tIOU 0.800 (0.817)\n",
      "Epoch: [15][Validation]\tVal_Loss: 1.20941\tVal_IOU: 0.79164\tBest Val_IOU: 0.79164\n",
      "epoch time:  95.83593201637268\n",
      "Current learning rate: 0.0100\n",
      "Epoch: [16][0/201]\tLoss 1.1917 (1.1917)\tIOU 0.856 (0.856)\n",
      "Epoch: [16][20/201]\tLoss 1.0901 (1.2181)\tIOU 0.762 (0.830)\n",
      "Epoch: [16][40/201]\tLoss 1.1690 (1.1736)\tIOU 0.819 (0.825)\n",
      "Epoch: [16][60/201]\tLoss 1.1593 (1.1728)\tIOU 0.753 (0.820)\n",
      "Epoch: [16][80/201]\tLoss 1.2586 (1.2153)\tIOU 0.916 (0.815)\n",
      "Epoch: [16][100/201]\tLoss 1.3232 (1.1989)\tIOU 0.781 (0.811)\n",
      "Epoch: [16][120/201]\tLoss 1.2228 (1.1867)\tIOU 0.912 (0.801)\n",
      "Epoch: [16][140/201]\tLoss 1.2209 (1.2050)\tIOU 0.706 (0.810)\n",
      "Epoch: [16][160/201]\tLoss 1.1634 (1.2145)\tIOU 0.869 (0.813)\n",
      "Epoch: [16][180/201]\tLoss 1.1334 (1.1851)\tIOU 0.856 (0.824)\n",
      "Epoch: [16][200/201]\tLoss 1.3397 (1.2207)\tIOU 0.562 (0.770)\n",
      "Epoch: [16][Validation]\tVal_Loss: 1.21479\tVal_IOU: 0.77636\tBest Val_IOU: 0.79164\n",
      "epoch time:  94.58294582366943\n",
      "Current learning rate: 0.0100\n",
      "Epoch: [17][0/201]\tLoss 1.1891 (1.1891)\tIOU 0.753 (0.753)\n",
      "Epoch: [17][20/201]\tLoss 1.1510 (1.1971)\tIOU 0.887 (0.826)\n",
      "Epoch: [17][40/201]\tLoss 1.1667 (1.2143)\tIOU 0.791 (0.826)\n",
      "Epoch: [17][60/201]\tLoss 1.1989 (1.1705)\tIOU 0.891 (0.850)\n",
      "Epoch: [17][80/201]\tLoss 1.1753 (1.1948)\tIOU 0.716 (0.820)\n",
      "Epoch: [17][100/201]\tLoss 1.1551 (1.2018)\tIOU 0.856 (0.807)\n",
      "Epoch: [17][120/201]\tLoss 1.1638 (1.2189)\tIOU 0.872 (0.809)\n",
      "Epoch: [17][140/201]\tLoss 1.1610 (1.1809)\tIOU 0.859 (0.829)\n",
      "Epoch: [17][160/201]\tLoss 1.2405 (1.1944)\tIOU 0.866 (0.814)\n",
      "Epoch: [17][180/201]\tLoss 1.1420 (1.2068)\tIOU 0.819 (0.811)\n",
      "Epoch: [17][200/201]\tLoss 1.1945 (1.1855)\tIOU 0.537 (0.804)\n",
      "Epoch: [17][Validation]\tVal_Loss: 1.21284\tVal_IOU: 0.78139\tBest Val_IOU: 0.79164\n",
      "epoch time:  94.29663467407227\n",
      "Current learning rate: 0.0100\n",
      "Epoch: [18][0/201]\tLoss 1.1450 (1.1450)\tIOU 0.884 (0.884)\n",
      "Epoch: [18][20/201]\tLoss 1.2472 (1.1954)\tIOU 0.825 (0.811)\n",
      "Epoch: [18][40/201]\tLoss 1.3628 (1.2020)\tIOU 0.613 (0.820)\n",
      "Epoch: [18][60/201]\tLoss 1.1101 (1.1638)\tIOU 0.897 (0.847)\n",
      "Epoch: [18][80/201]\tLoss 1.2616 (1.1924)\tIOU 0.741 (0.838)\n",
      "Epoch: [18][100/201]\tLoss 1.2128 (1.1937)\tIOU 0.822 (0.818)\n",
      "Epoch: [18][120/201]\tLoss 1.1889 (1.2020)\tIOU 0.938 (0.834)\n",
      "Epoch: [18][140/201]\tLoss 1.0415 (1.1800)\tIOU 0.844 (0.823)\n",
      "Epoch: [18][160/201]\tLoss 1.2295 (1.2198)\tIOU 0.797 (0.827)\n",
      "Epoch: [18][180/201]\tLoss 1.0706 (1.1969)\tIOU 0.756 (0.800)\n",
      "Epoch: [18][200/201]\tLoss 1.0988 (1.2004)\tIOU 0.700 (0.800)\n",
      "Epoch: [18][Validation]\tVal_Loss: 1.21374\tVal_IOU: 0.77570\tBest Val_IOU: 0.79164\n",
      "epoch time:  94.78409218788147\n",
      "Current learning rate: 0.0100\n",
      "Epoch: [19][0/201]\tLoss 1.1385 (1.1385)\tIOU 0.841 (0.841)\n",
      "Epoch: [19][20/201]\tLoss 1.1474 (1.1922)\tIOU 0.844 (0.822)\n",
      "Epoch: [19][40/201]\tLoss 1.2907 (1.1891)\tIOU 0.759 (0.809)\n",
      "Epoch: [19][60/201]\tLoss 1.0814 (1.1630)\tIOU 0.819 (0.843)\n",
      "Epoch: [19][80/201]\tLoss 1.1955 (1.1779)\tIOU 0.853 (0.812)\n",
      "Epoch: [19][100/201]\tLoss 1.1844 (1.2155)\tIOU 0.850 (0.826)\n",
      "Epoch: [19][120/201]\tLoss 1.2296 (1.2068)\tIOU 0.812 (0.828)\n",
      "Epoch: [19][140/201]\tLoss 1.1502 (1.1986)\tIOU 0.831 (0.825)\n",
      "Epoch: [19][160/201]\tLoss 1.1280 (1.1853)\tIOU 0.838 (0.823)\n",
      "Epoch: [19][180/201]\tLoss 1.2465 (1.1968)\tIOU 0.750 (0.814)\n",
      "Epoch: [19][200/201]\tLoss 1.7083 (1.2229)\tIOU 0.250 (0.809)\n",
      "Epoch: [19][Validation]\tVal_Loss: 1.21515\tVal_IOU: 0.78022\tBest Val_IOU: 0.79164\n",
      "epoch time:  94.65939712524414\n",
      "Current learning rate: 0.0100\n",
      "Epoch: [20][0/201]\tLoss 1.3720 (1.3720)\tIOU 0.806 (0.806)\n",
      "Epoch: [20][20/201]\tLoss 1.1062 (1.1992)\tIOU 0.900 (0.838)\n",
      "Epoch: [20][40/201]\tLoss 1.2480 (1.1989)\tIOU 0.884 (0.832)\n",
      "Epoch: [20][60/201]\tLoss 1.0573 (1.1922)\tIOU 0.819 (0.816)\n",
      "Epoch: [20][80/201]\tLoss 1.2567 (1.1855)\tIOU 0.806 (0.825)\n",
      "Epoch: [20][100/201]\tLoss 1.1265 (1.1817)\tIOU 0.853 (0.815)\n",
      "Epoch: [20][120/201]\tLoss 1.1992 (1.2037)\tIOU 0.769 (0.798)\n",
      "Epoch: [20][140/201]\tLoss 1.2544 (1.2006)\tIOU 0.803 (0.832)\n",
      "Epoch: [20][160/201]\tLoss 1.2848 (1.2054)\tIOU 0.763 (0.808)\n",
      "Epoch: [20][180/201]\tLoss 1.0865 (1.2015)\tIOU 0.816 (0.819)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [20][200/201]\tLoss 1.5218 (1.2081)\tIOU 0.850 (0.826)\n",
      "Epoch: [20][Validation]\tVal_Loss: 1.21625\tVal_IOU: 0.77349\tBest Val_IOU: 0.79164\n",
      "epoch time:  94.30641198158264\n",
      "Current learning rate: 0.0100\n",
      "Epoch: [21][0/201]\tLoss 1.0805 (1.0805)\tIOU 0.862 (0.862)\n",
      "Epoch: [21][20/201]\tLoss 1.1458 (1.1880)\tIOU 0.869 (0.838)\n",
      "Epoch: [21][40/201]\tLoss 1.1400 (1.1854)\tIOU 0.834 (0.812)\n",
      "Epoch: [21][60/201]\tLoss 1.1763 (1.1973)\tIOU 0.859 (0.842)\n",
      "Epoch: [21][80/201]\tLoss 1.2400 (1.2143)\tIOU 0.803 (0.790)\n",
      "Epoch: [21][100/201]\tLoss 1.1103 (1.2006)\tIOU 0.913 (0.800)\n",
      "Epoch: [21][120/201]\tLoss 1.1429 (1.1758)\tIOU 0.794 (0.827)\n",
      "Epoch: [21][140/201]\tLoss 1.2068 (1.1894)\tIOU 0.812 (0.856)\n",
      "Epoch: [21][160/201]\tLoss 1.2168 (1.2180)\tIOU 0.878 (0.805)\n",
      "Epoch: [21][180/201]\tLoss 1.3397 (1.1809)\tIOU 0.869 (0.848)\n",
      "Epoch: [21][200/201]\tLoss 1.1916 (1.1969)\tIOU 0.625 (0.815)\n",
      "Epoch: [21][Validation]\tVal_Loss: 1.21447\tVal_IOU: 0.78489\tBest Val_IOU: 0.79164\n",
      "epoch time:  94.2219889163971\n",
      "Epoch    22: reducing learning rate of group 0 to 5.0000e-03.\n",
      "Current learning rate: 0.0050\n",
      "Epoch: [22][0/201]\tLoss 1.1333 (1.1333)\tIOU 0.806 (0.806)\n",
      "Epoch: [22][20/201]\tLoss 1.1666 (1.2003)\tIOU 0.791 (0.833)\n",
      "Epoch: [22][40/201]\tLoss 1.1086 (1.1897)\tIOU 0.872 (0.843)\n",
      "Epoch: [22][60/201]\tLoss 1.1080 (1.1903)\tIOU 0.847 (0.839)\n",
      "Epoch: [22][80/201]\tLoss 1.2696 (1.1830)\tIOU 0.809 (0.832)\n",
      "Epoch: [22][100/201]\tLoss 1.2279 (1.1853)\tIOU 0.903 (0.840)\n",
      "Epoch: [22][120/201]\tLoss 1.2218 (1.1760)\tIOU 0.928 (0.858)\n",
      "Epoch: [22][140/201]\tLoss 1.1321 (1.1703)\tIOU 0.794 (0.853)\n",
      "Epoch: [22][160/201]\tLoss 1.2594 (1.1765)\tIOU 0.853 (0.830)\n",
      "Epoch: [22][180/201]\tLoss 1.1020 (1.1853)\tIOU 0.887 (0.844)\n",
      "Epoch: [22][200/201]\tLoss 1.6736 (1.2268)\tIOU 0.375 (0.811)\n",
      "Epoch: [22][Validation]\tVal_Loss: 1.21135\tVal_IOU: 0.79255\tBest Val_IOU: 0.79255\n",
      "epoch time:  96.18278789520264\n",
      "Current learning rate: 0.0050\n",
      "Epoch: [23][0/201]\tLoss 1.1475 (1.1475)\tIOU 0.906 (0.906)\n",
      "Epoch: [23][20/201]\tLoss 1.1241 (1.1601)\tIOU 0.844 (0.852)\n",
      "Epoch: [23][40/201]\tLoss 1.2715 (1.1961)\tIOU 0.912 (0.871)\n",
      "Epoch: [23][60/201]\tLoss 1.1489 (1.2000)\tIOU 0.866 (0.832)\n",
      "Epoch: [23][80/201]\tLoss 1.2557 (1.1887)\tIOU 0.872 (0.838)\n",
      "Epoch: [23][100/201]\tLoss 1.0755 (1.2043)\tIOU 0.906 (0.838)\n",
      "Epoch: [23][120/201]\tLoss 1.3250 (1.1937)\tIOU 0.741 (0.832)\n",
      "Epoch: [23][140/201]\tLoss 1.2300 (1.1621)\tIOU 0.863 (0.858)\n",
      "Epoch: [23][160/201]\tLoss 1.1984 (1.1621)\tIOU 0.831 (0.855)\n",
      "Epoch: [23][180/201]\tLoss 1.1997 (1.1876)\tIOU 0.738 (0.828)\n",
      "Epoch: [23][200/201]\tLoss 1.2068 (1.1958)\tIOU 0.863 (0.865)\n",
      "Epoch: [23][Validation]\tVal_Loss: 1.21171\tVal_IOU: 0.79317\tBest Val_IOU: 0.79317\n",
      "epoch time:  95.92801094055176\n",
      "Current learning rate: 0.0050\n",
      "Epoch: [24][0/201]\tLoss 1.1504 (1.1504)\tIOU 0.853 (0.853)\n",
      "Epoch: [24][20/201]\tLoss 1.1118 (1.1857)\tIOU 0.900 (0.853)\n",
      "Epoch: [24][40/201]\tLoss 1.1720 (1.1938)\tIOU 0.909 (0.848)\n",
      "Epoch: [24][60/201]\tLoss 1.1409 (1.1764)\tIOU 0.869 (0.855)\n",
      "Epoch: [24][80/201]\tLoss 1.2397 (1.1914)\tIOU 0.891 (0.839)\n",
      "Epoch: [24][100/201]\tLoss 1.3189 (1.1895)\tIOU 0.784 (0.863)\n",
      "Epoch: [24][120/201]\tLoss 1.1503 (1.1715)\tIOU 0.797 (0.850)\n",
      "Epoch: [24][140/201]\tLoss 1.2099 (1.2054)\tIOU 0.850 (0.846)\n",
      "Epoch: [24][160/201]\tLoss 1.1338 (1.1675)\tIOU 0.884 (0.852)\n",
      "Epoch: [24][180/201]\tLoss 1.1346 (1.1653)\tIOU 0.894 (0.863)\n",
      "Epoch: [24][200/201]\tLoss 1.2676 (1.1811)\tIOU 0.575 (0.845)\n",
      "Epoch: [24][Validation]\tVal_Loss: 1.21096\tVal_IOU: 0.78748\tBest Val_IOU: 0.79317\n",
      "epoch time:  94.33015632629395\n",
      "Current learning rate: 0.0050\n",
      "Epoch: [25][0/201]\tLoss 1.1813 (1.1813)\tIOU 0.825 (0.825)\n",
      "Epoch: [25][20/201]\tLoss 1.1533 (1.2016)\tIOU 0.844 (0.823)\n",
      "Epoch: [25][40/201]\tLoss 1.2873 (1.1792)\tIOU 0.797 (0.853)\n",
      "Epoch: [25][60/201]\tLoss 1.1633 (1.1815)\tIOU 0.897 (0.839)\n",
      "Epoch: [25][80/201]\tLoss 1.2746 (1.1468)\tIOU 0.756 (0.864)\n",
      "Epoch: [25][100/201]\tLoss 1.1483 (1.2048)\tIOU 0.906 (0.842)\n",
      "Epoch: [25][120/201]\tLoss 1.0813 (1.1668)\tIOU 0.894 (0.850)\n",
      "Epoch: [25][140/201]\tLoss 1.1365 (1.2024)\tIOU 0.863 (0.842)\n",
      "Epoch: [25][160/201]\tLoss 1.3315 (1.1804)\tIOU 0.828 (0.854)\n",
      "Epoch: [25][180/201]\tLoss 1.2428 (1.2026)\tIOU 0.884 (0.839)\n",
      "Epoch: [25][200/201]\tLoss 1.0975 (1.1794)\tIOU 0.712 (0.838)\n",
      "Epoch: [25][Validation]\tVal_Loss: 1.21299\tVal_IOU: 0.78700\tBest Val_IOU: 0.79317\n",
      "epoch time:  93.93724060058594\n",
      "Current learning rate: 0.0050\n",
      "Epoch: [26][0/201]\tLoss 1.0820 (1.0820)\tIOU 0.887 (0.887)\n",
      "Epoch: [26][20/201]\tLoss 1.2458 (1.1880)\tIOU 0.838 (0.853)\n",
      "Epoch: [26][40/201]\tLoss 1.2657 (1.2174)\tIOU 0.869 (0.840)\n",
      "Epoch: [26][60/201]\tLoss 1.2870 (1.2069)\tIOU 0.781 (0.851)\n",
      "Epoch: [26][80/201]\tLoss 1.3210 (1.1679)\tIOU 0.853 (0.859)\n",
      "Epoch: [26][100/201]\tLoss 1.1931 (1.1573)\tIOU 0.831 (0.839)\n",
      "Epoch: [26][120/201]\tLoss 1.3464 (1.1908)\tIOU 0.791 (0.853)\n",
      "Epoch: [26][140/201]\tLoss 1.1220 (1.1762)\tIOU 0.872 (0.858)\n",
      "Epoch: [26][160/201]\tLoss 1.2035 (1.1461)\tIOU 0.831 (0.847)\n",
      "Epoch: [26][180/201]\tLoss 1.1179 (1.1738)\tIOU 0.912 (0.862)\n",
      "Epoch: [26][200/201]\tLoss 1.4144 (1.2150)\tIOU 0.825 (0.843)\n",
      "Epoch: [26][Validation]\tVal_Loss: 1.21206\tVal_IOU: 0.79787\tBest Val_IOU: 0.79787\n",
      "epoch time:  96.27417707443237\n",
      "Current learning rate: 0.0050\n",
      "Epoch: [27][0/201]\tLoss 1.3184 (1.3184)\tIOU 0.819 (0.819)\n",
      "Epoch: [27][20/201]\tLoss 1.1657 (1.2266)\tIOU 0.762 (0.839)\n",
      "Epoch: [27][40/201]\tLoss 1.1437 (1.1531)\tIOU 0.866 (0.851)\n",
      "Epoch: [27][60/201]\tLoss 1.1852 (1.1658)\tIOU 0.878 (0.868)\n",
      "Epoch: [27][80/201]\tLoss 1.2023 (1.2140)\tIOU 0.819 (0.845)\n",
      "Epoch: [27][100/201]\tLoss 1.2429 (1.1784)\tIOU 0.878 (0.849)\n",
      "Epoch: [27][120/201]\tLoss 1.1770 (1.1531)\tIOU 0.831 (0.855)\n",
      "Epoch: [27][140/201]\tLoss 1.2363 (1.1665)\tIOU 0.850 (0.854)\n",
      "Epoch: [27][160/201]\tLoss 1.1941 (1.1791)\tIOU 0.903 (0.856)\n",
      "Epoch: [27][180/201]\tLoss 1.2503 (1.2034)\tIOU 0.831 (0.841)\n",
      "Epoch: [27][200/201]\tLoss 0.9350 (1.1656)\tIOU 0.787 (0.857)\n",
      "Epoch: [27][Validation]\tVal_Loss: 1.21101\tVal_IOU: 0.79128\tBest Val_IOU: 0.79787\n",
      "epoch time:  94.56149435043335\n",
      "Current learning rate: 0.0050\n",
      "Epoch: [28][0/201]\tLoss 1.1762 (1.1762)\tIOU 0.816 (0.816)\n",
      "Epoch: [28][20/201]\tLoss 1.1858 (1.1849)\tIOU 0.825 (0.847)\n",
      "Epoch: [28][40/201]\tLoss 1.1006 (1.1622)\tIOU 0.947 (0.870)\n",
      "Epoch: [28][60/201]\tLoss 1.1737 (1.1773)\tIOU 0.838 (0.847)\n",
      "Epoch: [28][80/201]\tLoss 1.1545 (1.2113)\tIOU 0.859 (0.851)\n",
      "Epoch: [28][100/201]\tLoss 1.2659 (1.1860)\tIOU 0.900 (0.852)\n",
      "Epoch: [28][120/201]\tLoss 1.1913 (1.1719)\tIOU 0.797 (0.862)\n",
      "Epoch: [28][140/201]\tLoss 1.1488 (1.1980)\tIOU 0.819 (0.857)\n",
      "Epoch: [28][160/201]\tLoss 1.1272 (1.1753)\tIOU 0.775 (0.850)\n",
      "Epoch: [28][180/201]\tLoss 1.2644 (1.1572)\tIOU 0.812 (0.847)\n",
      "Epoch: [28][200/201]\tLoss 1.2464 (1.1821)\tIOU 0.812 (0.862)\n",
      "Epoch: [28][Validation]\tVal_Loss: 1.20803\tVal_IOU: 0.80189\tBest Val_IOU: 0.80189\n",
      "epoch time:  96.01024341583252\n",
      "Current learning rate: 0.0050\n",
      "Epoch: [29][0/201]\tLoss 1.2630 (1.2630)\tIOU 0.831 (0.831)\n",
      "Epoch: [29][20/201]\tLoss 1.1682 (1.1618)\tIOU 0.816 (0.850)\n",
      "Epoch: [29][40/201]\tLoss 1.1372 (1.1892)\tIOU 0.794 (0.850)\n",
      "Epoch: [29][60/201]\tLoss 1.1936 (1.1663)\tIOU 0.925 (0.875)\n",
      "Epoch: [29][80/201]\tLoss 1.2387 (1.1902)\tIOU 0.850 (0.868)\n",
      "Epoch: [29][100/201]\tLoss 1.3456 (1.2078)\tIOU 0.806 (0.853)\n",
      "Epoch: [29][120/201]\tLoss 1.2458 (1.1550)\tIOU 0.791 (0.852)\n",
      "Epoch: [29][140/201]\tLoss 1.2583 (1.1901)\tIOU 0.753 (0.840)\n",
      "Epoch: [29][160/201]\tLoss 1.2158 (1.1756)\tIOU 0.828 (0.848)\n",
      "Epoch: [29][180/201]\tLoss 1.2162 (1.2112)\tIOU 0.756 (0.830)\n",
      "Epoch: [29][200/201]\tLoss 1.1512 (1.1636)\tIOU 0.838 (0.855)\n",
      "Epoch: [29][Validation]\tVal_Loss: 1.20900\tVal_IOU: 0.80438\tBest Val_IOU: 0.80438\n",
      "epoch time:  96.09044027328491\n",
      "Current learning rate: 0.0050\n",
      "Epoch: [30][0/201]\tLoss 1.1949 (1.1949)\tIOU 0.881 (0.881)\n",
      "Epoch: [30][20/201]\tLoss 1.2066 (1.1779)\tIOU 0.819 (0.854)\n",
      "Epoch: [30][40/201]\tLoss 1.2579 (1.1926)\tIOU 0.856 (0.852)\n",
      "Epoch: [30][60/201]\tLoss 1.1706 (1.1787)\tIOU 0.878 (0.866)\n",
      "Epoch: [30][80/201]\tLoss 1.2488 (1.1821)\tIOU 0.844 (0.866)\n",
      "Epoch: [30][100/201]\tLoss 1.1947 (1.1820)\tIOU 0.853 (0.846)\n",
      "Epoch: [30][120/201]\tLoss 1.2957 (1.2021)\tIOU 0.803 (0.859)\n",
      "Epoch: [30][140/201]\tLoss 1.2280 (1.1451)\tIOU 0.803 (0.871)\n",
      "Epoch: [30][160/201]\tLoss 1.1990 (1.1772)\tIOU 0.803 (0.855)\n",
      "Epoch: [30][180/201]\tLoss 1.2532 (1.1906)\tIOU 0.763 (0.847)\n",
      "Epoch: [30][200/201]\tLoss 1.2469 (1.1671)\tIOU 0.925 (0.873)\n",
      "Epoch: [30][Validation]\tVal_Loss: 1.21056\tVal_IOU: 0.80489\tBest Val_IOU: 0.80489\n",
      "epoch time:  95.6625907421112\n"
     ]
    }
   ],
   "source": [
    "fold = 0\n",
    "for x_train_f, y_train_f, x_valid_f, y_valid_f in zip(x_train, y_train, x_valid, y_valid):\n",
    "    train_loader = make_loader((x_train_f, y_train_f), num_workers=0, batch_size=32, shuffle=True)\n",
    "    valid_loader = make_loader((x_valid_f, y_valid_f), num_workers=0, batch_size=64, mode='valid')\n",
    "\n",
    "    res_unet = UNetResNet34_DS(dropout_2d=0.5, pretrained=True)\n",
    "    res_unet = res_unet.to(device)\n",
    "    \n",
    "    #model = nn.DataParallel(model, device_ids=None)\n",
    "\n",
    "    n_epochs = 30\n",
    "    start_epoch = 0\n",
    "    report_each = 20\n",
    "    valid_losses = []\n",
    "    valid_ious = []\n",
    "    train_losses = []\n",
    "    train_ious = []\n",
    "    valid_iou = 0\n",
    "    valid_loss = 0\n",
    "    best_iou = 0\n",
    "            \n",
    "    optimizer= SGD(filter(lambda p: p.requires_grad, res_unet.parameters()),\n",
    "                   0.01, weight_decay=0.0002, momentum=0.9)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='max', verbose=True, patience=5, factor=0.5, min_lr=0.0001)\n",
    "        \n",
    "    print('Fold: [{0}]\\t'.format(fold))\n",
    "    for epoch in range(start_epoch, start_epoch + n_epochs + 1):\n",
    "        time0 = time.time()\n",
    "        train_metrics = train_phrase0(res_unet, criterion_phrase0, train_loader, optimizer, \n",
    "                              epoch, scheduler, report_each, valid_iou)\n",
    "        valid_metrics = validation_phrase0(res_unet, criterion_phrase0, valid_loader)\n",
    "\n",
    "        train_loss = train_metrics['train_loss']\n",
    "        train_iou = train_metrics['train_iou']\n",
    "        train_losses += [train_loss]\n",
    "        train_ious += [train_iou]\n",
    "        valid_loss = valid_metrics['val_loss']\n",
    "        valid_iou = valid_metrics['val_iou']\n",
    "        valid_losses += [valid_loss]\n",
    "        valid_ious += [valid_iou]\n",
    "        is_best = best_iou < valid_iou\n",
    "        best_iou = max(valid_iou, best_iou)\n",
    "        print('Epoch: [{0}][Validation]\\t' \n",
    "              'Val_Loss: {val_loss:.5f}\\t' \n",
    "              'Val_IOU: {val_iou:.5f}\\t'\n",
    "              'Best Val_IOU: {best_iou:.5f}'.format(epoch, \n",
    "                                                    val_loss=valid_loss, \n",
    "                                                    val_iou=valid_iou, \n",
    "                                                    best_iou=best_iou))\n",
    "        filename = '{name}_{loss}_{phrase}_{fold}_{mode}_{aug}'.format(name='resnet34',\n",
    "                                                                 loss='bce_dice',\n",
    "                                                                 phrase='0',\n",
    "                                                                 fold=fold,\n",
    "                                                                 mode='iou',\n",
    "                                                                 aug='resizepad',)\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': res_unet.state_dict(),\n",
    "            'best_iou': best_iou,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, is_best, filename)\n",
    "        time1 = time.time()\n",
    "        print('epoch time: ', time1-time0)\n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7e5a810db663502a8f3c0c0d8f1d92762a4adc05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'model_best_resnet34_bce_dice_0_2_iou_resizepad.pth.tar'\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0100\n",
      "Epoch: [0][0/200]\tLoss 1.2659 (1.2659)\tIOU 0.869 (0.869)\n",
      "Epoch: [0][20/200]\tLoss 2.8634 (2.9910)\tIOU 0.666 (0.545)\n",
      "Epoch: [0][40/200]\tLoss 2.2464 (2.4884)\tIOU 0.656 (0.555)\n",
      "Epoch: [0][60/200]\tLoss 2.1685 (2.1939)\tIOU 0.628 (0.634)\n",
      "Epoch: [0][80/200]\tLoss 1.8515 (1.9559)\tIOU 0.712 (0.688)\n",
      "Epoch: [0][100/200]\tLoss 2.2182 (2.0788)\tIOU 0.488 (0.635)\n",
      "Epoch: [0][120/200]\tLoss 1.2518 (1.8549)\tIOU 0.825 (0.694)\n",
      "Epoch: [0][140/200]\tLoss 2.2507 (1.6412)\tIOU 0.556 (0.736)\n",
      "Epoch: [0][160/200]\tLoss 2.5296 (1.7292)\tIOU 0.672 (0.714)\n",
      "Epoch: [0][180/200]\tLoss 1.6726 (1.7506)\tIOU 0.731 (0.710)\n",
      "Epoch: [0][Validation]\tVal_Loss: 1.65892\tVal_IOU: 0.73774\tBest Val_IOU: 0.73774\n",
      "epoch time:  106.4466004371643\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0100\n",
      "Epoch: [1][0/200]\tLoss 2.0718 (2.0718)\tIOU 0.597 (0.597)\n",
      "Epoch: [1][20/200]\tLoss 1.5306 (1.5535)\tIOU 0.725 (0.747)\n",
      "Epoch: [1][40/200]\tLoss 2.0616 (1.7292)\tIOU 0.625 (0.713)\n",
      "Epoch: [1][60/200]\tLoss 1.2836 (1.6318)\tIOU 0.819 (0.733)\n",
      "Epoch: [1][80/200]\tLoss 0.9439 (1.4673)\tIOU 0.906 (0.768)\n",
      "Epoch: [1][100/200]\tLoss 1.3339 (1.5194)\tIOU 0.772 (0.759)\n",
      "Epoch: [1][120/200]\tLoss 1.7064 (1.5255)\tIOU 0.688 (0.747)\n",
      "Epoch: [1][140/200]\tLoss 1.6181 (1.3870)\tIOU 0.750 (0.779)\n",
      "Epoch: [1][160/200]\tLoss 1.5967 (1.5209)\tIOU 0.731 (0.760)\n",
      "Epoch: [1][180/200]\tLoss 1.0676 (1.5747)\tIOU 0.863 (0.751)\n",
      "Epoch: [1][Validation]\tVal_Loss: 1.46880\tVal_IOU: 0.75479\tBest Val_IOU: 0.75479\n",
      "epoch time:  106.85117363929749\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0099\n",
      "Epoch: [2][0/200]\tLoss 1.1017 (1.1017)\tIOU 0.875 (0.875)\n",
      "Epoch: [2][20/200]\tLoss 1.3339 (1.4855)\tIOU 0.797 (0.763)\n",
      "Epoch: [2][40/200]\tLoss 1.6259 (1.4002)\tIOU 0.741 (0.767)\n",
      "Epoch: [2][60/200]\tLoss 1.3253 (1.4274)\tIOU 0.769 (0.774)\n",
      "Epoch: [2][80/200]\tLoss 1.2490 (1.4751)\tIOU 0.816 (0.760)\n",
      "Epoch: [2][100/200]\tLoss 1.5040 (1.5039)\tIOU 0.709 (0.755)\n",
      "Epoch: [2][120/200]\tLoss 1.6141 (1.4372)\tIOU 0.691 (0.756)\n",
      "Epoch: [2][140/200]\tLoss 1.8907 (1.5030)\tIOU 0.634 (0.753)\n",
      "Epoch: [2][160/200]\tLoss 1.2816 (1.3828)\tIOU 0.781 (0.773)\n",
      "Epoch: [2][180/200]\tLoss 1.1955 (1.2264)\tIOU 0.847 (0.800)\n",
      "Epoch: [2][Validation]\tVal_Loss: 1.30497\tVal_IOU: 0.78904\tBest Val_IOU: 0.78904\n",
      "epoch time:  107.0458083152771\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0099\n",
      "Epoch: [3][0/200]\tLoss 1.0662 (1.0662)\tIOU 0.828 (0.828)\n",
      "Epoch: [3][20/200]\tLoss 1.3320 (1.3037)\tIOU 0.762 (0.795)\n",
      "Epoch: [3][40/200]\tLoss 1.8153 (1.2897)\tIOU 0.697 (0.791)\n",
      "Epoch: [3][60/200]\tLoss 1.1719 (1.3413)\tIOU 0.819 (0.796)\n",
      "Epoch: [3][80/200]\tLoss 1.1844 (1.4057)\tIOU 0.772 (0.769)\n",
      "Epoch: [3][100/200]\tLoss 1.3997 (1.5761)\tIOU 0.800 (0.739)\n",
      "Epoch: [3][120/200]\tLoss 1.4679 (1.3968)\tIOU 0.791 (0.794)\n",
      "Epoch: [3][140/200]\tLoss 2.2883 (1.2941)\tIOU 0.622 (0.791)\n",
      "Epoch: [3][160/200]\tLoss 1.0826 (1.4537)\tIOU 0.772 (0.749)\n",
      "Epoch: [3][180/200]\tLoss 2.0692 (1.2542)\tIOU 0.612 (0.793)\n",
      "Epoch: [3][Validation]\tVal_Loss: 1.55949\tVal_IOU: 0.77355\tBest Val_IOU: 0.78904\n",
      "epoch time:  104.56601214408875\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0098\n",
      "Epoch: [4][0/200]\tLoss 1.5468 (1.5468)\tIOU 0.728 (0.728)\n",
      "Epoch: [4][20/200]\tLoss 1.2254 (1.3860)\tIOU 0.819 (0.766)\n",
      "Epoch: [4][40/200]\tLoss 1.1231 (1.2831)\tIOU 0.825 (0.788)\n",
      "Epoch: [4][60/200]\tLoss 1.0364 (1.1991)\tIOU 0.869 (0.823)\n",
      "Epoch: [4][80/200]\tLoss 0.7269 (1.1654)\tIOU 0.897 (0.820)\n",
      "Epoch: [4][100/200]\tLoss 1.1157 (1.2084)\tIOU 0.841 (0.787)\n",
      "Epoch: [4][120/200]\tLoss 1.0239 (1.0817)\tIOU 0.816 (0.842)\n",
      "Epoch: [4][140/200]\tLoss 1.3357 (1.2831)\tIOU 0.800 (0.805)\n",
      "Epoch: [4][160/200]\tLoss 1.2203 (1.4277)\tIOU 0.806 (0.763)\n",
      "Epoch: [4][180/200]\tLoss 1.5560 (1.2620)\tIOU 0.697 (0.783)\n",
      "Epoch: [4][Validation]\tVal_Loss: 1.25266\tVal_IOU: 0.79244\tBest Val_IOU: 0.79244\n",
      "epoch time:  106.67574977874756\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0097\n",
      "Epoch: [5][0/200]\tLoss 0.8698 (0.8698)\tIOU 0.875 (0.875)\n",
      "Epoch: [5][20/200]\tLoss 0.5778 (1.2084)\tIOU 0.928 (0.801)\n",
      "Epoch: [5][40/200]\tLoss 0.8797 (1.1462)\tIOU 0.884 (0.817)\n",
      "Epoch: [5][60/200]\tLoss 0.8719 (1.2685)\tIOU 0.869 (0.793)\n",
      "Epoch: [5][80/200]\tLoss 1.2516 (1.2015)\tIOU 0.884 (0.802)\n",
      "Epoch: [5][100/200]\tLoss 1.1168 (1.1625)\tIOU 0.881 (0.826)\n",
      "Epoch: [5][120/200]\tLoss 1.3790 (1.2522)\tIOU 0.763 (0.801)\n",
      "Epoch: [5][140/200]\tLoss 1.1157 (1.2323)\tIOU 0.809 (0.805)\n",
      "Epoch: [5][160/200]\tLoss 1.4959 (1.2553)\tIOU 0.778 (0.790)\n",
      "Epoch: [5][180/200]\tLoss 1.4255 (1.2184)\tIOU 0.775 (0.814)\n",
      "Epoch: [5][Validation]\tVal_Loss: 1.24894\tVal_IOU: 0.79612\tBest Val_IOU: 0.79612\n",
      "epoch time:  107.64839911460876\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0096\n",
      "Epoch: [6][0/200]\tLoss 1.0257 (1.0257)\tIOU 0.847 (0.847)\n",
      "Epoch: [6][20/200]\tLoss 0.8793 (1.2881)\tIOU 0.900 (0.790)\n",
      "Epoch: [6][40/200]\tLoss 1.2053 (1.0985)\tIOU 0.834 (0.815)\n",
      "Epoch: [6][60/200]\tLoss 1.0150 (1.1652)\tIOU 0.853 (0.819)\n",
      "Epoch: [6][80/200]\tLoss 1.5680 (1.2442)\tIOU 0.738 (0.806)\n",
      "Epoch: [6][100/200]\tLoss 1.3832 (1.0452)\tIOU 0.750 (0.826)\n",
      "Epoch: [6][120/200]\tLoss 1.1048 (1.0799)\tIOU 0.816 (0.824)\n",
      "Epoch: [6][140/200]\tLoss 1.3015 (1.2031)\tIOU 0.772 (0.801)\n",
      "Epoch: [6][160/200]\tLoss 0.6221 (1.1796)\tIOU 0.928 (0.818)\n",
      "Epoch: [6][180/200]\tLoss 1.7681 (1.2344)\tIOU 0.688 (0.788)\n",
      "Epoch: [6][Validation]\tVal_Loss: 1.23159\tVal_IOU: 0.80849\tBest Val_IOU: 0.80849\n",
      "epoch time:  106.20133924484253\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0094\n",
      "Epoch: [7][0/200]\tLoss 1.1877 (1.1877)\tIOU 0.762 (0.762)\n",
      "Epoch: [7][20/200]\tLoss 1.1544 (1.1467)\tIOU 0.831 (0.808)\n",
      "Epoch: [7][40/200]\tLoss 1.1569 (1.1502)\tIOU 0.809 (0.819)\n",
      "Epoch: [7][60/200]\tLoss 1.2311 (1.0464)\tIOU 0.816 (0.838)\n",
      "Epoch: [7][80/200]\tLoss 1.1830 (1.1482)\tIOU 0.878 (0.815)\n",
      "Epoch: [7][100/200]\tLoss 0.8261 (1.2496)\tIOU 0.853 (0.778)\n",
      "Epoch: [7][120/200]\tLoss 1.2230 (1.1827)\tIOU 0.772 (0.812)\n",
      "Epoch: [7][140/200]\tLoss 0.9495 (1.1356)\tIOU 0.856 (0.803)\n",
      "Epoch: [7][160/200]\tLoss 0.7797 (1.1245)\tIOU 0.875 (0.820)\n",
      "Epoch: [7][180/200]\tLoss 1.6909 (1.1618)\tIOU 0.694 (0.808)\n",
      "Epoch: [7][Validation]\tVal_Loss: 1.20177\tVal_IOU: 0.80498\tBest Val_IOU: 0.80849\n",
      "epoch time:  104.66360473632812\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0093\n",
      "Epoch: [8][0/200]\tLoss 1.1483 (1.1483)\tIOU 0.772 (0.772)\n",
      "Epoch: [8][20/200]\tLoss 0.6144 (1.0424)\tIOU 0.944 (0.828)\n",
      "Epoch: [8][40/200]\tLoss 1.3895 (1.0932)\tIOU 0.725 (0.820)\n",
      "Epoch: [8][60/200]\tLoss 1.2838 (1.0747)\tIOU 0.788 (0.829)\n",
      "Epoch: [8][80/200]\tLoss 1.2515 (1.1415)\tIOU 0.766 (0.816)\n",
      "Epoch: [8][100/200]\tLoss 1.1354 (1.0763)\tIOU 0.809 (0.820)\n",
      "Epoch: [8][120/200]\tLoss 1.2916 (1.0592)\tIOU 0.841 (0.833)\n",
      "Epoch: [8][140/200]\tLoss 0.9351 (1.1025)\tIOU 0.853 (0.822)\n",
      "Epoch: [8][160/200]\tLoss 1.0823 (1.1451)\tIOU 0.825 (0.801)\n",
      "Epoch: [8][180/200]\tLoss 1.1232 (1.0718)\tIOU 0.816 (0.813)\n",
      "Epoch: [8][Validation]\tVal_Loss: 1.24413\tVal_IOU: 0.80220\tBest Val_IOU: 0.80849\n",
      "epoch time:  105.55132341384888\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0091\n",
      "Epoch: [9][0/200]\tLoss 0.8590 (0.8590)\tIOU 0.828 (0.828)\n",
      "Epoch: [9][20/200]\tLoss 0.7197 (1.0152)\tIOU 0.875 (0.833)\n",
      "Epoch: [9][40/200]\tLoss 1.2497 (1.1013)\tIOU 0.800 (0.819)\n",
      "Epoch: [9][60/200]\tLoss 1.2597 (1.0837)\tIOU 0.756 (0.819)\n",
      "Epoch: [9][80/200]\tLoss 1.1777 (1.1018)\tIOU 0.841 (0.812)\n",
      "Epoch: [9][100/200]\tLoss 0.8075 (1.0788)\tIOU 0.875 (0.829)\n",
      "Epoch: [9][120/200]\tLoss 1.0520 (1.1840)\tIOU 0.803 (0.806)\n",
      "Epoch: [9][140/200]\tLoss 0.8690 (1.0591)\tIOU 0.859 (0.830)\n",
      "Epoch: [9][160/200]\tLoss 1.5897 (1.0692)\tIOU 0.728 (0.816)\n",
      "Epoch: [9][180/200]\tLoss 1.1073 (1.1430)\tIOU 0.787 (0.802)\n",
      "Epoch: [9][Validation]\tVal_Loss: 1.26233\tVal_IOU: 0.79496\tBest Val_IOU: 0.80849\n",
      "epoch time:  105.46874713897705\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0090\n",
      "Epoch: [10][0/200]\tLoss 1.1739 (1.1739)\tIOU 0.822 (0.822)\n",
      "Epoch: [10][20/200]\tLoss 1.0120 (1.1119)\tIOU 0.859 (0.821)\n",
      "Epoch: [10][40/200]\tLoss 0.6951 (0.9828)\tIOU 0.878 (0.844)\n",
      "Epoch: [10][60/200]\tLoss 0.7955 (1.0829)\tIOU 0.863 (0.817)\n",
      "Epoch: [10][80/200]\tLoss 0.8581 (1.0483)\tIOU 0.884 (0.839)\n",
      "Epoch: [10][100/200]\tLoss 1.3204 (1.1112)\tIOU 0.806 (0.812)\n",
      "Epoch: [10][120/200]\tLoss 0.9499 (0.9694)\tIOU 0.872 (0.842)\n",
      "Epoch: [10][140/200]\tLoss 1.0220 (1.1442)\tIOU 0.863 (0.807)\n",
      "Epoch: [10][160/200]\tLoss 1.1779 (1.0319)\tIOU 0.788 (0.830)\n",
      "Epoch: [10][180/200]\tLoss 1.0730 (1.0221)\tIOU 0.828 (0.840)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][Validation]\tVal_Loss: 1.12537\tVal_IOU: 0.81529\tBest Val_IOU: 0.81529\n",
      "epoch time:  106.85633444786072\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0088\n",
      "Epoch: [11][0/200]\tLoss 0.6939 (0.6939)\tIOU 0.906 (0.906)\n",
      "Epoch: [11][20/200]\tLoss 1.0837 (0.9997)\tIOU 0.806 (0.834)\n",
      "Epoch: [11][40/200]\tLoss 0.7725 (0.9590)\tIOU 0.869 (0.850)\n",
      "Epoch: [11][60/200]\tLoss 1.4208 (0.9369)\tIOU 0.787 (0.843)\n",
      "Epoch: [11][80/200]\tLoss 0.9319 (1.0471)\tIOU 0.884 (0.840)\n",
      "Epoch: [11][100/200]\tLoss 1.0421 (0.9162)\tIOU 0.822 (0.864)\n",
      "Epoch: [11][120/200]\tLoss 1.0576 (1.0985)\tIOU 0.812 (0.813)\n",
      "Epoch: [11][140/200]\tLoss 1.0266 (1.1072)\tIOU 0.844 (0.836)\n",
      "Epoch: [11][160/200]\tLoss 0.8207 (1.0401)\tIOU 0.850 (0.820)\n",
      "Epoch: [11][180/200]\tLoss 0.4532 (1.0272)\tIOU 0.944 (0.827)\n",
      "Epoch: [11][Validation]\tVal_Loss: 1.23039\tVal_IOU: 0.80425\tBest Val_IOU: 0.81529\n",
      "epoch time:  106.11326122283936\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0086\n",
      "Epoch: [12][0/200]\tLoss 0.7826 (0.7826)\tIOU 0.866 (0.866)\n",
      "Epoch: [12][20/200]\tLoss 1.7658 (1.0844)\tIOU 0.700 (0.814)\n",
      "Epoch: [12][40/200]\tLoss 0.9123 (0.9515)\tIOU 0.859 (0.845)\n",
      "Epoch: [12][60/200]\tLoss 0.8009 (0.8754)\tIOU 0.887 (0.859)\n",
      "Epoch: [12][80/200]\tLoss 0.9542 (0.9509)\tIOU 0.812 (0.841)\n",
      "Epoch: [12][100/200]\tLoss 0.7183 (1.0854)\tIOU 0.884 (0.818)\n",
      "Epoch: [12][120/200]\tLoss 0.9501 (1.0554)\tIOU 0.784 (0.824)\n",
      "Epoch: [12][140/200]\tLoss 0.5588 (0.9106)\tIOU 0.931 (0.850)\n",
      "Epoch: [12][160/200]\tLoss 0.4115 (0.9326)\tIOU 0.950 (0.848)\n",
      "Epoch: [12][180/200]\tLoss 0.8618 (1.0954)\tIOU 0.856 (0.820)\n",
      "Epoch: [12][Validation]\tVal_Loss: 1.23401\tVal_IOU: 0.80973\tBest Val_IOU: 0.81529\n",
      "epoch time:  105.79524183273315\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0084\n",
      "Epoch: [13][0/200]\tLoss 0.8988 (0.8988)\tIOU 0.863 (0.863)\n",
      "Epoch: [13][20/200]\tLoss 0.9055 (0.9309)\tIOU 0.844 (0.848)\n",
      "Epoch: [13][40/200]\tLoss 0.8884 (0.9122)\tIOU 0.869 (0.854)\n",
      "Epoch: [13][60/200]\tLoss 0.7956 (0.9328)\tIOU 0.859 (0.848)\n",
      "Epoch: [13][80/200]\tLoss 1.4994 (0.9895)\tIOU 0.747 (0.831)\n",
      "Epoch: [13][100/200]\tLoss 1.0227 (0.9407)\tIOU 0.822 (0.840)\n",
      "Epoch: [13][120/200]\tLoss 1.0632 (0.9910)\tIOU 0.822 (0.848)\n",
      "Epoch: [13][140/200]\tLoss 1.0217 (0.9813)\tIOU 0.828 (0.844)\n",
      "Epoch: [13][160/200]\tLoss 0.5345 (0.9763)\tIOU 0.900 (0.839)\n",
      "Epoch: [13][180/200]\tLoss 0.9950 (0.9905)\tIOU 0.825 (0.845)\n",
      "Epoch: [13][Validation]\tVal_Loss: 1.18759\tVal_IOU: 0.80807\tBest Val_IOU: 0.81529\n",
      "epoch time:  105.16366028785706\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0081\n",
      "Epoch: [14][0/200]\tLoss 0.6424 (0.6424)\tIOU 0.909 (0.909)\n",
      "Epoch: [14][20/200]\tLoss 1.0230 (1.0190)\tIOU 0.797 (0.833)\n",
      "Epoch: [14][40/200]\tLoss 1.1033 (1.0866)\tIOU 0.859 (0.825)\n",
      "Epoch: [14][60/200]\tLoss 0.6723 (0.9001)\tIOU 0.909 (0.867)\n",
      "Epoch: [14][80/200]\tLoss 1.0168 (0.9270)\tIOU 0.906 (0.853)\n",
      "Epoch: [14][100/200]\tLoss 0.9103 (0.8489)\tIOU 0.878 (0.868)\n",
      "Epoch: [14][120/200]\tLoss 1.2235 (0.8090)\tIOU 0.766 (0.864)\n",
      "Epoch: [14][140/200]\tLoss 1.0146 (0.9276)\tIOU 0.806 (0.840)\n",
      "Epoch: [14][160/200]\tLoss 0.9597 (0.8576)\tIOU 0.800 (0.855)\n",
      "Epoch: [14][180/200]\tLoss 1.3166 (1.0437)\tIOU 0.762 (0.827)\n",
      "Epoch: [14][Validation]\tVal_Loss: 1.17120\tVal_IOU: 0.81178\tBest Val_IOU: 0.81529\n",
      "epoch time:  105.16438031196594\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0079\n",
      "Epoch: [15][0/200]\tLoss 1.3006 (1.3006)\tIOU 0.759 (0.759)\n",
      "Epoch: [15][20/200]\tLoss 0.8768 (0.9145)\tIOU 0.837 (0.836)\n",
      "Epoch: [15][40/200]\tLoss 0.9309 (0.8439)\tIOU 0.863 (0.863)\n",
      "Epoch: [15][60/200]\tLoss 1.0806 (0.9279)\tIOU 0.822 (0.848)\n",
      "Epoch: [15][80/200]\tLoss 1.1544 (0.9796)\tIOU 0.844 (0.847)\n",
      "Epoch: [15][100/200]\tLoss 1.0389 (0.9093)\tIOU 0.828 (0.850)\n",
      "Epoch: [15][120/200]\tLoss 0.8030 (0.8172)\tIOU 0.872 (0.872)\n",
      "Epoch: [15][140/200]\tLoss 0.7297 (0.8576)\tIOU 0.912 (0.868)\n",
      "Epoch: [15][160/200]\tLoss 0.5995 (0.8433)\tIOU 0.900 (0.865)\n",
      "Epoch: [15][180/200]\tLoss 1.3984 (1.0085)\tIOU 0.769 (0.833)\n",
      "Epoch: [15][Validation]\tVal_Loss: 1.18759\tVal_IOU: 0.81220\tBest Val_IOU: 0.81529\n",
      "epoch time:  104.93704915046692\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0077\n",
      "Epoch: [16][0/200]\tLoss 0.9800 (0.9800)\tIOU 0.825 (0.825)\n",
      "Epoch: [16][20/200]\tLoss 1.1695 (0.7512)\tIOU 0.784 (0.879)\n",
      "Epoch: [16][40/200]\tLoss 0.9455 (0.8854)\tIOU 0.863 (0.862)\n",
      "Epoch: [16][60/200]\tLoss 0.4617 (0.9512)\tIOU 0.941 (0.846)\n",
      "Epoch: [16][80/200]\tLoss 1.0180 (0.9272)\tIOU 0.803 (0.845)\n",
      "Epoch: [16][100/200]\tLoss 0.6664 (0.9534)\tIOU 0.884 (0.845)\n",
      "Epoch: [16][120/200]\tLoss 0.7799 (0.9586)\tIOU 0.850 (0.847)\n",
      "Epoch: [16][140/200]\tLoss 0.7668 (1.0127)\tIOU 0.900 (0.835)\n",
      "Epoch: [16][160/200]\tLoss 1.0364 (0.9455)\tIOU 0.806 (0.847)\n",
      "Epoch: [16][180/200]\tLoss 0.7723 (0.9557)\tIOU 0.875 (0.838)\n",
      "Epoch: [16][Validation]\tVal_Loss: 1.12086\tVal_IOU: 0.82084\tBest Val_IOU: 0.82084\n",
      "epoch time:  106.76539444923401\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0074\n",
      "Epoch: [17][0/200]\tLoss 1.2663 (1.2663)\tIOU 0.753 (0.753)\n",
      "Epoch: [17][20/200]\tLoss 1.3165 (0.8262)\tIOU 0.803 (0.873)\n",
      "Epoch: [17][40/200]\tLoss 0.6446 (0.9845)\tIOU 0.916 (0.848)\n",
      "Epoch: [17][60/200]\tLoss 0.9197 (0.9385)\tIOU 0.781 (0.836)\n",
      "Epoch: [17][80/200]\tLoss 0.7281 (0.8455)\tIOU 0.869 (0.858)\n",
      "Epoch: [17][100/200]\tLoss 0.7554 (0.9179)\tIOU 0.853 (0.844)\n",
      "Epoch: [17][120/200]\tLoss 0.6932 (0.9378)\tIOU 0.906 (0.838)\n",
      "Epoch: [17][140/200]\tLoss 0.8702 (0.8208)\tIOU 0.869 (0.867)\n",
      "Epoch: [17][160/200]\tLoss 0.6133 (0.8950)\tIOU 0.897 (0.853)\n",
      "Epoch: [17][180/200]\tLoss 1.1583 (0.9836)\tIOU 0.816 (0.831)\n",
      "Epoch: [17][Validation]\tVal_Loss: 1.15377\tVal_IOU: 0.82181\tBest Val_IOU: 0.82181\n",
      "epoch time:  106.29188942909241\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0072\n",
      "Epoch: [18][0/200]\tLoss 1.0039 (1.0039)\tIOU 0.831 (0.831)\n",
      "Epoch: [18][20/200]\tLoss 0.9866 (0.8860)\tIOU 0.834 (0.857)\n",
      "Epoch: [18][40/200]\tLoss 1.1367 (0.8951)\tIOU 0.766 (0.844)\n",
      "Epoch: [18][60/200]\tLoss 0.5705 (0.8600)\tIOU 0.950 (0.862)\n",
      "Epoch: [18][80/200]\tLoss 0.4344 (0.8157)\tIOU 0.934 (0.862)\n",
      "Epoch: [18][100/200]\tLoss 0.8571 (0.8116)\tIOU 0.881 (0.878)\n",
      "Epoch: [18][120/200]\tLoss 0.8144 (0.8240)\tIOU 0.891 (0.864)\n",
      "Epoch: [18][140/200]\tLoss 1.1355 (1.0453)\tIOU 0.753 (0.825)\n",
      "Epoch: [18][160/200]\tLoss 1.0970 (0.8692)\tIOU 0.841 (0.861)\n",
      "Epoch: [18][180/200]\tLoss 0.6980 (0.8217)\tIOU 0.913 (0.864)\n",
      "Epoch: [18][Validation]\tVal_Loss: 1.22213\tVal_IOU: 0.81726\tBest Val_IOU: 0.82181\n",
      "epoch time:  104.79161524772644\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0069\n",
      "Epoch: [19][0/200]\tLoss 0.8308 (0.8308)\tIOU 0.881 (0.881)\n",
      "Epoch: [19][20/200]\tLoss 0.7684 (0.8227)\tIOU 0.872 (0.862)\n",
      "Epoch: [19][40/200]\tLoss 0.7793 (0.8267)\tIOU 0.894 (0.860)\n",
      "Epoch: [19][60/200]\tLoss 0.9308 (0.8483)\tIOU 0.856 (0.860)\n",
      "Epoch: [19][80/200]\tLoss 0.7007 (0.7826)\tIOU 0.853 (0.866)\n",
      "Epoch: [19][100/200]\tLoss 0.8520 (0.8663)\tIOU 0.847 (0.849)\n",
      "Epoch: [19][120/200]\tLoss 0.6841 (0.8170)\tIOU 0.878 (0.862)\n",
      "Epoch: [19][140/200]\tLoss 0.7130 (0.8198)\tIOU 0.922 (0.869)\n",
      "Epoch: [19][160/200]\tLoss 0.8275 (0.8402)\tIOU 0.856 (0.858)\n",
      "Epoch: [19][180/200]\tLoss 0.6958 (0.7753)\tIOU 0.884 (0.879)\n",
      "Epoch: [19][Validation]\tVal_Loss: 1.21406\tVal_IOU: 0.82331\tBest Val_IOU: 0.82331\n",
      "epoch time:  107.19723463058472\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0066\n",
      "Epoch: [20][0/200]\tLoss 0.8710 (0.8710)\tIOU 0.828 (0.828)\n",
      "Epoch: [20][20/200]\tLoss 0.9117 (0.7847)\tIOU 0.847 (0.870)\n",
      "Epoch: [20][40/200]\tLoss 1.0426 (0.7811)\tIOU 0.825 (0.870)\n",
      "Epoch: [20][60/200]\tLoss 0.6234 (0.8192)\tIOU 0.894 (0.864)\n",
      "Epoch: [20][80/200]\tLoss 0.4043 (0.7958)\tIOU 0.950 (0.875)\n",
      "Epoch: [20][100/200]\tLoss 0.6542 (0.8178)\tIOU 0.894 (0.867)\n",
      "Epoch: [20][120/200]\tLoss 1.0627 (0.7912)\tIOU 0.775 (0.869)\n",
      "Epoch: [20][140/200]\tLoss 1.6755 (0.8466)\tIOU 0.709 (0.850)\n",
      "Epoch: [20][160/200]\tLoss 0.9863 (0.7771)\tIOU 0.841 (0.875)\n",
      "Epoch: [20][180/200]\tLoss 0.8415 (0.8482)\tIOU 0.859 (0.865)\n",
      "Epoch: [20][Validation]\tVal_Loss: 1.22155\tVal_IOU: 0.81634\tBest Val_IOU: 0.82331\n",
      "epoch time:  105.24904155731201\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0063\n",
      "Epoch: [21][0/200]\tLoss 0.6285 (0.6285)\tIOU 0.928 (0.928)\n",
      "Epoch: [21][20/200]\tLoss 0.9297 (0.7788)\tIOU 0.812 (0.877)\n",
      "Epoch: [21][40/200]\tLoss 1.2528 (0.7531)\tIOU 0.766 (0.874)\n",
      "Epoch: [21][60/200]\tLoss 0.8706 (0.8362)\tIOU 0.834 (0.869)\n",
      "Epoch: [21][80/200]\tLoss 0.3637 (0.7048)\tIOU 0.956 (0.884)\n",
      "Epoch: [21][100/200]\tLoss 0.7195 (0.8080)\tIOU 0.869 (0.860)\n",
      "Epoch: [21][120/200]\tLoss 1.0267 (0.8593)\tIOU 0.809 (0.853)\n",
      "Epoch: [21][140/200]\tLoss 0.6354 (0.6975)\tIOU 0.903 (0.886)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [21][160/200]\tLoss 0.5261 (0.8165)\tIOU 0.928 (0.862)\n",
      "Epoch: [21][180/200]\tLoss 0.9924 (0.8321)\tIOU 0.831 (0.863)\n",
      "Epoch: [21][Validation]\tVal_Loss: 1.13430\tVal_IOU: 0.81423\tBest Val_IOU: 0.82331\n",
      "epoch time:  104.91370606422424\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0061\n",
      "Epoch: [22][0/200]\tLoss 0.8335 (0.8335)\tIOU 0.859 (0.859)\n",
      "Epoch: [22][20/200]\tLoss 0.8928 (0.7288)\tIOU 0.847 (0.879)\n",
      "Epoch: [22][40/200]\tLoss 0.5824 (0.8079)\tIOU 0.934 (0.870)\n",
      "Epoch: [22][60/200]\tLoss 1.2279 (0.8405)\tIOU 0.841 (0.858)\n",
      "Epoch: [22][80/200]\tLoss 0.4209 (0.7336)\tIOU 0.947 (0.875)\n",
      "Epoch: [22][100/200]\tLoss 0.4855 (0.8602)\tIOU 0.944 (0.857)\n",
      "Epoch: [22][120/200]\tLoss 0.6883 (0.7728)\tIOU 0.913 (0.872)\n",
      "Epoch: [22][140/200]\tLoss 0.7685 (0.7824)\tIOU 0.853 (0.876)\n",
      "Epoch: [22][160/200]\tLoss 1.2389 (0.8096)\tIOU 0.797 (0.865)\n",
      "Epoch: [22][180/200]\tLoss 0.8470 (0.8777)\tIOU 0.828 (0.860)\n",
      "Epoch: [22][Validation]\tVal_Loss: 1.09401\tVal_IOU: 0.82301\tBest Val_IOU: 0.82331\n",
      "epoch time:  105.90518450737\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0058\n",
      "Epoch: [23][0/200]\tLoss 0.6119 (0.6119)\tIOU 0.909 (0.909)\n",
      "Epoch: [23][20/200]\tLoss 0.7962 (0.7611)\tIOU 0.884 (0.875)\n",
      "Epoch: [23][40/200]\tLoss 0.5160 (0.7379)\tIOU 0.934 (0.877)\n",
      "Epoch: [23][60/200]\tLoss 0.8074 (0.7421)\tIOU 0.844 (0.876)\n",
      "Epoch: [23][80/200]\tLoss 0.8045 (0.7208)\tIOU 0.847 (0.878)\n",
      "Epoch: [23][100/200]\tLoss 0.3475 (0.6626)\tIOU 0.975 (0.898)\n",
      "Epoch: [23][120/200]\tLoss 0.8135 (0.8437)\tIOU 0.838 (0.859)\n",
      "Epoch: [23][140/200]\tLoss 0.3521 (0.8554)\tIOU 0.944 (0.850)\n",
      "Epoch: [23][160/200]\tLoss 0.7013 (0.7454)\tIOU 0.891 (0.873)\n",
      "Epoch: [23][180/200]\tLoss 0.7918 (0.7874)\tIOU 0.856 (0.873)\n",
      "Epoch: [23][Validation]\tVal_Loss: 1.14528\tVal_IOU: 0.82278\tBest Val_IOU: 0.82331\n",
      "epoch time:  105.58264994621277\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0055\n",
      "Epoch: [24][0/200]\tLoss 0.6933 (0.6933)\tIOU 0.866 (0.866)\n",
      "Epoch: [24][20/200]\tLoss 0.5706 (0.7443)\tIOU 0.891 (0.871)\n",
      "Epoch: [24][40/200]\tLoss 0.7102 (0.7526)\tIOU 0.856 (0.880)\n",
      "Epoch: [24][60/200]\tLoss 1.1431 (0.7305)\tIOU 0.800 (0.879)\n",
      "Epoch: [24][80/200]\tLoss 0.6516 (0.7758)\tIOU 0.887 (0.871)\n",
      "Epoch: [24][100/200]\tLoss 0.5754 (0.7267)\tIOU 0.903 (0.880)\n",
      "Epoch: [24][120/200]\tLoss 1.1360 (0.8343)\tIOU 0.756 (0.857)\n",
      "Epoch: [24][140/200]\tLoss 0.5174 (0.7013)\tIOU 0.947 (0.880)\n",
      "Epoch: [24][160/200]\tLoss 0.5415 (0.7684)\tIOU 0.941 (0.876)\n",
      "Epoch: [24][180/200]\tLoss 0.5774 (0.8236)\tIOU 0.903 (0.852)\n",
      "Epoch: [24][Validation]\tVal_Loss: 1.22793\tVal_IOU: 0.82157\tBest Val_IOU: 0.82331\n",
      "epoch time:  105.31411790847778\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0052\n",
      "Epoch: [25][0/200]\tLoss 0.8412 (0.8412)\tIOU 0.856 (0.856)\n",
      "Epoch: [25][20/200]\tLoss 0.6419 (0.6855)\tIOU 0.900 (0.892)\n",
      "Epoch: [25][40/200]\tLoss 0.4480 (0.7161)\tIOU 0.934 (0.884)\n",
      "Epoch: [25][60/200]\tLoss 0.6997 (0.7299)\tIOU 0.891 (0.884)\n",
      "Epoch: [25][80/200]\tLoss 0.4127 (0.7000)\tIOU 0.959 (0.892)\n",
      "Epoch: [25][100/200]\tLoss 0.6088 (0.8170)\tIOU 0.906 (0.859)\n",
      "Epoch: [25][120/200]\tLoss 0.8616 (0.6762)\tIOU 0.847 (0.892)\n",
      "Epoch: [25][140/200]\tLoss 0.4428 (0.7731)\tIOU 0.950 (0.866)\n",
      "Epoch: [25][160/200]\tLoss 0.8499 (0.7218)\tIOU 0.844 (0.880)\n",
      "Epoch: [25][180/200]\tLoss 1.2468 (0.7243)\tIOU 0.788 (0.880)\n",
      "Epoch: [25][Validation]\tVal_Loss: 1.17831\tVal_IOU: 0.83262\tBest Val_IOU: 0.83262\n",
      "epoch time:  106.4602882862091\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0049\n",
      "Epoch: [26][0/200]\tLoss 0.8078 (0.8078)\tIOU 0.853 (0.853)\n",
      "Epoch: [26][20/200]\tLoss 1.0340 (0.7100)\tIOU 0.847 (0.884)\n",
      "Epoch: [26][40/200]\tLoss 0.2715 (0.6519)\tIOU 0.972 (0.890)\n",
      "Epoch: [26][60/200]\tLoss 0.6495 (0.6094)\tIOU 0.878 (0.903)\n",
      "Epoch: [26][80/200]\tLoss 0.5723 (0.7033)\tIOU 0.884 (0.882)\n",
      "Epoch: [26][100/200]\tLoss 0.9076 (0.6628)\tIOU 0.878 (0.890)\n",
      "Epoch: [26][120/200]\tLoss 0.5672 (0.7076)\tIOU 0.887 (0.881)\n",
      "Epoch: [26][140/200]\tLoss 0.3222 (0.7493)\tIOU 0.966 (0.881)\n",
      "Epoch: [26][160/200]\tLoss 1.0536 (0.8579)\tIOU 0.866 (0.865)\n",
      "Epoch: [26][180/200]\tLoss 0.4944 (0.7833)\tIOU 0.934 (0.859)\n",
      "Epoch: [26][Validation]\tVal_Loss: 1.16148\tVal_IOU: 0.83433\tBest Val_IOU: 0.83433\n",
      "epoch time:  106.6443498134613\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0047\n",
      "Epoch: [27][0/200]\tLoss 0.7707 (0.7707)\tIOU 0.853 (0.853)\n",
      "Epoch: [27][20/200]\tLoss 0.6450 (0.6773)\tIOU 0.875 (0.877)\n",
      "Epoch: [27][40/200]\tLoss 0.8833 (0.6794)\tIOU 0.866 (0.887)\n",
      "Epoch: [27][60/200]\tLoss 0.7665 (0.7410)\tIOU 0.906 (0.883)\n",
      "Epoch: [27][80/200]\tLoss 0.9232 (0.7635)\tIOU 0.809 (0.870)\n",
      "Epoch: [27][100/200]\tLoss 0.4461 (0.6944)\tIOU 0.938 (0.885)\n",
      "Epoch: [27][120/200]\tLoss 0.6267 (0.7324)\tIOU 0.884 (0.874)\n",
      "Epoch: [27][140/200]\tLoss 0.7357 (0.6852)\tIOU 0.853 (0.889)\n",
      "Epoch: [27][160/200]\tLoss 0.5459 (0.6609)\tIOU 0.900 (0.890)\n",
      "Epoch: [27][180/200]\tLoss 1.0931 (0.6409)\tIOU 0.825 (0.900)\n",
      "Epoch: [27][Validation]\tVal_Loss: 1.08613\tVal_IOU: 0.83828\tBest Val_IOU: 0.83828\n",
      "epoch time:  107.01618361473083\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0044\n",
      "Epoch: [28][0/200]\tLoss 0.8941 (0.8941)\tIOU 0.822 (0.822)\n",
      "Epoch: [28][20/200]\tLoss 0.3479 (0.6574)\tIOU 0.953 (0.892)\n",
      "Epoch: [28][40/200]\tLoss 1.1033 (0.7252)\tIOU 0.806 (0.884)\n",
      "Epoch: [28][60/200]\tLoss 0.6780 (0.6938)\tIOU 0.878 (0.880)\n",
      "Epoch: [28][80/200]\tLoss 0.8243 (0.6953)\tIOU 0.891 (0.882)\n",
      "Epoch: [28][100/200]\tLoss 0.6613 (0.6355)\tIOU 0.878 (0.897)\n",
      "Epoch: [28][120/200]\tLoss 0.7205 (0.6329)\tIOU 0.878 (0.899)\n",
      "Epoch: [28][140/200]\tLoss 0.5641 (0.5835)\tIOU 0.903 (0.906)\n",
      "Epoch: [28][160/200]\tLoss 1.0652 (0.6809)\tIOU 0.828 (0.882)\n",
      "Epoch: [28][180/200]\tLoss 0.5482 (0.6517)\tIOU 0.922 (0.899)\n",
      "Epoch: [28][Validation]\tVal_Loss: 1.16516\tVal_IOU: 0.82385\tBest Val_IOU: 0.83828\n",
      "epoch time:  105.69078350067139\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0041\n",
      "Epoch: [29][0/200]\tLoss 0.7921 (0.7921)\tIOU 0.866 (0.866)\n",
      "Epoch: [29][20/200]\tLoss 0.6158 (0.6240)\tIOU 0.884 (0.900)\n",
      "Epoch: [29][40/200]\tLoss 0.4648 (0.6668)\tIOU 0.938 (0.890)\n",
      "Epoch: [29][60/200]\tLoss 0.4747 (0.7301)\tIOU 0.925 (0.881)\n",
      "Epoch: [29][80/200]\tLoss 0.6241 (0.7082)\tIOU 0.903 (0.877)\n",
      "Epoch: [29][100/200]\tLoss 0.5439 (0.6510)\tIOU 0.906 (0.894)\n",
      "Epoch: [29][120/200]\tLoss 0.7836 (0.6757)\tIOU 0.875 (0.893)\n",
      "Epoch: [29][140/200]\tLoss 0.5896 (0.6371)\tIOU 0.897 (0.897)\n",
      "Epoch: [29][160/200]\tLoss 0.2594 (0.6713)\tIOU 0.984 (0.895)\n",
      "Epoch: [29][180/200]\tLoss 0.8632 (0.7016)\tIOU 0.844 (0.877)\n",
      "Epoch: [29][Validation]\tVal_Loss: 1.10508\tVal_IOU: 0.82623\tBest Val_IOU: 0.83828\n",
      "epoch time:  104.57651042938232\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0038\n",
      "Epoch: [30][0/200]\tLoss 0.8046 (0.8046)\tIOU 0.853 (0.853)\n",
      "Epoch: [30][20/200]\tLoss 0.2647 (0.5890)\tIOU 0.972 (0.902)\n",
      "Epoch: [30][40/200]\tLoss 0.2504 (0.6376)\tIOU 0.988 (0.898)\n",
      "Epoch: [30][60/200]\tLoss 0.7319 (0.6898)\tIOU 0.894 (0.890)\n",
      "Epoch: [30][80/200]\tLoss 0.5598 (0.6902)\tIOU 0.887 (0.890)\n",
      "Epoch: [30][100/200]\tLoss 0.5434 (0.6351)\tIOU 0.903 (0.891)\n",
      "Epoch: [30][120/200]\tLoss 0.7404 (0.6025)\tIOU 0.891 (0.905)\n",
      "Epoch: [30][140/200]\tLoss 0.6540 (0.6495)\tIOU 0.887 (0.891)\n",
      "Epoch: [30][160/200]\tLoss 0.6346 (0.7198)\tIOU 0.891 (0.876)\n",
      "Epoch: [30][180/200]\tLoss 1.0096 (0.7307)\tIOU 0.803 (0.878)\n",
      "Epoch: [30][Validation]\tVal_Loss: 1.28453\tVal_IOU: 0.83454\tBest Val_IOU: 0.83828\n",
      "epoch time:  104.51204085350037\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0036\n",
      "Epoch: [31][0/200]\tLoss 0.6698 (0.6698)\tIOU 0.906 (0.906)\n",
      "Epoch: [31][20/200]\tLoss 0.4077 (0.6886)\tIOU 0.959 (0.882)\n",
      "Epoch: [31][40/200]\tLoss 0.8001 (0.6034)\tIOU 0.894 (0.909)\n",
      "Epoch: [31][60/200]\tLoss 0.6282 (0.5776)\tIOU 0.866 (0.906)\n",
      "Epoch: [31][80/200]\tLoss 0.5240 (0.6964)\tIOU 0.931 (0.882)\n",
      "Epoch: [31][100/200]\tLoss 0.9401 (0.6365)\tIOU 0.803 (0.898)\n",
      "Epoch: [31][120/200]\tLoss 0.5542 (0.5437)\tIOU 0.925 (0.918)\n",
      "Epoch: [31][140/200]\tLoss 0.7344 (0.6416)\tIOU 0.878 (0.891)\n",
      "Epoch: [31][160/200]\tLoss 0.7472 (0.5734)\tIOU 0.844 (0.909)\n",
      "Epoch: [31][180/200]\tLoss 0.3828 (0.6812)\tIOU 0.947 (0.887)\n",
      "Epoch: [31][Validation]\tVal_Loss: 1.11545\tVal_IOU: 0.83791\tBest Val_IOU: 0.83828\n",
      "epoch time:  105.2170832157135\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0033\n",
      "Epoch: [32][0/200]\tLoss 0.7382 (0.7382)\tIOU 0.872 (0.872)\n",
      "Epoch: [32][20/200]\tLoss 0.5031 (0.5434)\tIOU 0.913 (0.908)\n",
      "Epoch: [32][40/200]\tLoss 0.7007 (0.6546)\tIOU 0.887 (0.890)\n",
      "Epoch: [32][60/200]\tLoss 0.8786 (0.5953)\tIOU 0.831 (0.902)\n",
      "Epoch: [32][80/200]\tLoss 0.5653 (0.6159)\tIOU 0.900 (0.899)\n",
      "Epoch: [32][100/200]\tLoss 0.7261 (0.6319)\tIOU 0.881 (0.890)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [32][120/200]\tLoss 0.8099 (0.6682)\tIOU 0.863 (0.888)\n",
      "Epoch: [32][140/200]\tLoss 0.5240 (0.5956)\tIOU 0.903 (0.898)\n",
      "Epoch: [32][160/200]\tLoss 0.6540 (0.5715)\tIOU 0.875 (0.906)\n",
      "Epoch: [32][180/200]\tLoss 0.5263 (0.5846)\tIOU 0.925 (0.901)\n",
      "Epoch: [32][Validation]\tVal_Loss: 1.11326\tVal_IOU: 0.83647\tBest Val_IOU: 0.83828\n",
      "epoch time:  104.56745076179504\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0031\n",
      "Epoch: [33][0/200]\tLoss 0.3107 (0.3107)\tIOU 0.953 (0.953)\n",
      "Epoch: [33][20/200]\tLoss 0.8164 (0.6222)\tIOU 0.866 (0.896)\n",
      "Epoch: [33][40/200]\tLoss 0.6000 (0.6916)\tIOU 0.909 (0.887)\n",
      "Epoch: [33][60/200]\tLoss 0.6083 (0.6228)\tIOU 0.878 (0.895)\n",
      "Epoch: [33][80/200]\tLoss 0.5274 (0.5579)\tIOU 0.931 (0.907)\n",
      "Epoch: [33][100/200]\tLoss 0.4672 (0.5954)\tIOU 0.919 (0.902)\n",
      "Epoch: [33][120/200]\tLoss 0.5191 (0.6382)\tIOU 0.916 (0.900)\n",
      "Epoch: [33][140/200]\tLoss 0.5629 (0.5535)\tIOU 0.891 (0.901)\n",
      "Epoch: [33][160/200]\tLoss 0.2728 (0.5719)\tIOU 0.966 (0.908)\n",
      "Epoch: [33][180/200]\tLoss 0.5970 (0.5464)\tIOU 0.897 (0.910)\n",
      "Epoch: [33][Validation]\tVal_Loss: 1.22024\tVal_IOU: 0.83383\tBest Val_IOU: 0.83828\n",
      "epoch time:  104.51769733428955\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0029\n",
      "Epoch: [34][0/200]\tLoss 0.2524 (0.2524)\tIOU 0.978 (0.978)\n",
      "Epoch: [34][20/200]\tLoss 0.5959 (0.6454)\tIOU 0.878 (0.884)\n",
      "Epoch: [34][40/200]\tLoss 0.6086 (0.6213)\tIOU 0.884 (0.897)\n",
      "Epoch: [34][60/200]\tLoss 0.5797 (0.6051)\tIOU 0.894 (0.900)\n",
      "Epoch: [34][80/200]\tLoss 0.3336 (0.5559)\tIOU 0.991 (0.907)\n",
      "Epoch: [34][100/200]\tLoss 0.4985 (0.5725)\tIOU 0.928 (0.915)\n",
      "Epoch: [34][120/200]\tLoss 0.5906 (0.5519)\tIOU 0.906 (0.902)\n",
      "Epoch: [34][140/200]\tLoss 0.4982 (0.6108)\tIOU 0.913 (0.895)\n",
      "Epoch: [34][160/200]\tLoss 0.4100 (0.5487)\tIOU 0.938 (0.905)\n",
      "Epoch: [34][180/200]\tLoss 0.5206 (0.5540)\tIOU 0.950 (0.913)\n",
      "Epoch: [34][Validation]\tVal_Loss: 1.17299\tVal_IOU: 0.83714\tBest Val_IOU: 0.83828\n",
      "epoch time:  103.982248544693\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0026\n",
      "Epoch: [35][0/200]\tLoss 0.2788 (0.2788)\tIOU 0.988 (0.988)\n",
      "Epoch: [35][20/200]\tLoss 0.5203 (0.5290)\tIOU 0.931 (0.915)\n",
      "Epoch: [35][40/200]\tLoss 0.7378 (0.5503)\tIOU 0.866 (0.909)\n",
      "Epoch: [35][60/200]\tLoss 0.7638 (0.5747)\tIOU 0.847 (0.902)\n",
      "Epoch: [35][80/200]\tLoss 0.5738 (0.5240)\tIOU 0.891 (0.910)\n",
      "Epoch: [35][100/200]\tLoss 0.5226 (0.5199)\tIOU 0.941 (0.913)\n",
      "Epoch: [35][120/200]\tLoss 0.8090 (0.6265)\tIOU 0.838 (0.892)\n",
      "Epoch: [35][140/200]\tLoss 0.5683 (0.5345)\tIOU 0.909 (0.911)\n",
      "Epoch: [35][160/200]\tLoss 0.8644 (0.5529)\tIOU 0.847 (0.910)\n",
      "Epoch: [35][180/200]\tLoss 0.7222 (0.5132)\tIOU 0.878 (0.919)\n",
      "Epoch: [35][Validation]\tVal_Loss: 1.15764\tVal_IOU: 0.83335\tBest Val_IOU: 0.83828\n",
      "epoch time:  105.55650448799133\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0024\n",
      "Epoch: [36][0/200]\tLoss 0.5142 (0.5142)\tIOU 0.912 (0.912)\n",
      "Epoch: [36][20/200]\tLoss 0.3730 (0.5654)\tIOU 0.950 (0.905)\n",
      "Epoch: [36][40/200]\tLoss 0.5825 (0.5898)\tIOU 0.891 (0.897)\n",
      "Epoch: [36][60/200]\tLoss 0.7166 (0.5857)\tIOU 0.881 (0.900)\n",
      "Epoch: [36][80/200]\tLoss 0.4955 (0.5564)\tIOU 0.906 (0.910)\n",
      "Epoch: [36][100/200]\tLoss 0.7657 (0.5140)\tIOU 0.887 (0.919)\n",
      "Epoch: [36][120/200]\tLoss 0.6289 (0.6164)\tIOU 0.900 (0.898)\n",
      "Epoch: [36][140/200]\tLoss 0.3096 (0.6126)\tIOU 0.962 (0.896)\n",
      "Epoch: [36][160/200]\tLoss 0.6805 (0.5836)\tIOU 0.863 (0.902)\n",
      "Epoch: [36][180/200]\tLoss 1.0126 (0.5146)\tIOU 0.822 (0.919)\n",
      "Epoch: [36][Validation]\tVal_Loss: 1.15647\tVal_IOU: 0.83326\tBest Val_IOU: 0.83828\n",
      "epoch time:  105.17398762702942\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0022\n",
      "Epoch: [37][0/200]\tLoss 0.2871 (0.2871)\tIOU 0.963 (0.963)\n",
      "Epoch: [37][20/200]\tLoss 0.7192 (0.6617)\tIOU 0.869 (0.886)\n",
      "Epoch: [37][40/200]\tLoss 0.5839 (0.5419)\tIOU 0.891 (0.910)\n",
      "Epoch: [37][60/200]\tLoss 0.6086 (0.4902)\tIOU 0.866 (0.923)\n",
      "Epoch: [37][80/200]\tLoss 0.3892 (0.5527)\tIOU 0.944 (0.911)\n",
      "Epoch: [37][100/200]\tLoss 0.4283 (0.5343)\tIOU 0.938 (0.915)\n",
      "Epoch: [37][120/200]\tLoss 0.4697 (0.6127)\tIOU 0.912 (0.897)\n",
      "Epoch: [37][140/200]\tLoss 0.6154 (0.5503)\tIOU 0.887 (0.913)\n",
      "Epoch: [37][160/200]\tLoss 0.5135 (0.5281)\tIOU 0.909 (0.907)\n",
      "Epoch: [37][180/200]\tLoss 0.5658 (0.5646)\tIOU 0.909 (0.910)\n",
      "Epoch: [37][Validation]\tVal_Loss: 1.14427\tVal_IOU: 0.83851\tBest Val_IOU: 0.83851\n",
      "epoch time:  106.51418495178223\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0020\n",
      "Epoch: [38][0/200]\tLoss 0.7729 (0.7729)\tIOU 0.856 (0.856)\n",
      "Epoch: [38][20/200]\tLoss 0.3934 (0.5088)\tIOU 0.950 (0.919)\n",
      "Epoch: [38][40/200]\tLoss 0.4689 (0.5746)\tIOU 0.919 (0.907)\n",
      "Epoch: [38][60/200]\tLoss 0.3687 (0.5258)\tIOU 0.947 (0.914)\n",
      "Epoch: [38][80/200]\tLoss 0.4721 (0.4944)\tIOU 0.897 (0.926)\n",
      "Epoch: [38][100/200]\tLoss 0.6869 (0.5370)\tIOU 0.887 (0.911)\n",
      "Epoch: [38][120/200]\tLoss 0.4140 (0.5533)\tIOU 0.925 (0.906)\n",
      "Epoch: [38][140/200]\tLoss 0.2298 (0.5304)\tIOU 0.988 (0.912)\n",
      "Epoch: [38][160/200]\tLoss 0.3886 (0.5669)\tIOU 0.928 (0.895)\n",
      "Epoch: [38][180/200]\tLoss 0.6542 (0.5092)\tIOU 0.859 (0.920)\n",
      "Epoch: [38][Validation]\tVal_Loss: 1.17632\tVal_IOU: 0.82601\tBest Val_IOU: 0.83851\n",
      "epoch time:  105.08627796173096\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0019\n",
      "Epoch: [39][0/200]\tLoss 0.4882 (0.4882)\tIOU 0.919 (0.919)\n",
      "Epoch: [39][20/200]\tLoss 0.6622 (0.5301)\tIOU 0.875 (0.912)\n",
      "Epoch: [39][40/200]\tLoss 0.8929 (0.5107)\tIOU 0.831 (0.913)\n",
      "Epoch: [39][60/200]\tLoss 0.4536 (0.5067)\tIOU 0.941 (0.918)\n",
      "Epoch: [39][80/200]\tLoss 1.4913 (0.5371)\tIOU 0.822 (0.915)\n",
      "Epoch: [39][100/200]\tLoss 0.5268 (0.5608)\tIOU 0.925 (0.906)\n",
      "Epoch: [39][120/200]\tLoss 0.5179 (0.5117)\tIOU 0.919 (0.914)\n",
      "Epoch: [39][140/200]\tLoss 0.4285 (0.5525)\tIOU 0.944 (0.908)\n",
      "Epoch: [39][160/200]\tLoss 0.7239 (0.4898)\tIOU 0.831 (0.914)\n",
      "Epoch: [39][180/200]\tLoss 0.5460 (0.5750)\tIOU 0.903 (0.901)\n",
      "Epoch: [39][Validation]\tVal_Loss: 1.15290\tVal_IOU: 0.83935\tBest Val_IOU: 0.83935\n",
      "epoch time:  106.70852303504944\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0017\n",
      "Epoch: [40][0/200]\tLoss 0.3742 (0.3742)\tIOU 0.956 (0.956)\n",
      "Epoch: [40][20/200]\tLoss 0.9082 (0.5429)\tIOU 0.859 (0.907)\n",
      "Epoch: [40][40/200]\tLoss 0.4819 (0.5588)\tIOU 0.919 (0.906)\n",
      "Epoch: [40][60/200]\tLoss 0.3740 (0.5713)\tIOU 0.953 (0.907)\n",
      "Epoch: [40][80/200]\tLoss 0.2999 (0.4869)\tIOU 0.953 (0.922)\n",
      "Epoch: [40][100/200]\tLoss 0.4489 (0.4927)\tIOU 0.919 (0.916)\n",
      "Epoch: [40][120/200]\tLoss 0.3149 (0.4579)\tIOU 0.953 (0.923)\n",
      "Epoch: [40][140/200]\tLoss 0.5085 (0.5613)\tIOU 0.919 (0.910)\n",
      "Epoch: [40][160/200]\tLoss 0.4418 (0.5246)\tIOU 0.925 (0.909)\n",
      "Epoch: [40][180/200]\tLoss 0.4359 (0.4868)\tIOU 0.931 (0.925)\n",
      "Epoch: [40][Validation]\tVal_Loss: 1.16319\tVal_IOU: 0.83694\tBest Val_IOU: 0.83935\n",
      "epoch time:  104.86144948005676\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0016\n",
      "Epoch: [41][0/200]\tLoss 0.4312 (0.4312)\tIOU 0.944 (0.944)\n",
      "Epoch: [41][20/200]\tLoss 0.5346 (0.4962)\tIOU 0.900 (0.918)\n",
      "Epoch: [41][40/200]\tLoss 0.5544 (0.5140)\tIOU 0.891 (0.917)\n",
      "Epoch: [41][60/200]\tLoss 0.3877 (0.4291)\tIOU 0.947 (0.931)\n",
      "Epoch: [41][80/200]\tLoss 0.7537 (0.4847)\tIOU 0.850 (0.921)\n",
      "Epoch: [41][100/200]\tLoss 0.2512 (0.4924)\tIOU 0.981 (0.921)\n",
      "Epoch: [41][120/200]\tLoss 1.0453 (0.5031)\tIOU 0.825 (0.920)\n",
      "Epoch: [41][140/200]\tLoss 0.5162 (0.4852)\tIOU 0.934 (0.925)\n",
      "Epoch: [41][160/200]\tLoss 0.3126 (0.5374)\tIOU 0.950 (0.905)\n",
      "Epoch: [41][180/200]\tLoss 0.7744 (0.5269)\tIOU 0.891 (0.916)\n",
      "Epoch: [41][Validation]\tVal_Loss: 1.14135\tVal_IOU: 0.84032\tBest Val_IOU: 0.84032\n",
      "epoch time:  107.69360113143921\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0014\n",
      "Epoch: [42][0/200]\tLoss 0.5398 (0.5398)\tIOU 0.916 (0.916)\n",
      "Epoch: [42][20/200]\tLoss 0.7173 (0.4869)\tIOU 0.859 (0.922)\n",
      "Epoch: [42][40/200]\tLoss 0.3580 (0.5415)\tIOU 0.966 (0.912)\n",
      "Epoch: [42][60/200]\tLoss 0.4944 (0.5096)\tIOU 0.909 (0.915)\n",
      "Epoch: [42][80/200]\tLoss 0.4850 (0.4828)\tIOU 0.916 (0.922)\n",
      "Epoch: [42][100/200]\tLoss 0.3338 (0.5236)\tIOU 0.947 (0.914)\n",
      "Epoch: [42][120/200]\tLoss 0.5250 (0.5080)\tIOU 0.947 (0.915)\n",
      "Epoch: [42][140/200]\tLoss 0.4084 (0.4849)\tIOU 0.950 (0.921)\n",
      "Epoch: [42][160/200]\tLoss 0.6690 (0.5657)\tIOU 0.891 (0.907)\n",
      "Epoch: [42][180/200]\tLoss 0.6436 (0.4575)\tIOU 0.934 (0.927)\n",
      "Epoch: [42][Validation]\tVal_Loss: 1.17336\tVal_IOU: 0.83634\tBest Val_IOU: 0.84032\n",
      "epoch time:  105.77137327194214\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0013\n",
      "Epoch: [43][0/200]\tLoss 0.4479 (0.4479)\tIOU 0.919 (0.919)\n",
      "Epoch: [43][20/200]\tLoss 0.3387 (0.5352)\tIOU 0.959 (0.916)\n",
      "Epoch: [43][40/200]\tLoss 0.6526 (0.4749)\tIOU 0.875 (0.924)\n",
      "Epoch: [43][60/200]\tLoss 0.4430 (0.4480)\tIOU 0.934 (0.932)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [43][80/200]\tLoss 0.4982 (0.4733)\tIOU 0.928 (0.923)\n",
      "Epoch: [43][100/200]\tLoss 0.5094 (0.5012)\tIOU 0.912 (0.918)\n",
      "Epoch: [43][120/200]\tLoss 0.8229 (0.5270)\tIOU 0.806 (0.906)\n",
      "Epoch: [43][140/200]\tLoss 0.3316 (0.4731)\tIOU 0.959 (0.927)\n",
      "Epoch: [43][160/200]\tLoss 0.6101 (0.4325)\tIOU 0.897 (0.932)\n",
      "Epoch: [43][180/200]\tLoss 0.5533 (0.5580)\tIOU 0.894 (0.910)\n",
      "Epoch: [43][Validation]\tVal_Loss: 1.18573\tVal_IOU: 0.83383\tBest Val_IOU: 0.84032\n",
      "epoch time:  105.81598472595215\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0012\n",
      "Epoch: [44][0/200]\tLoss 0.2798 (0.2798)\tIOU 0.969 (0.969)\n",
      "Epoch: [44][20/200]\tLoss 0.5033 (0.5594)\tIOU 0.906 (0.905)\n",
      "Epoch: [44][40/200]\tLoss 0.5490 (0.4757)\tIOU 0.884 (0.920)\n",
      "Epoch: [44][60/200]\tLoss 0.3403 (0.4356)\tIOU 0.947 (0.930)\n",
      "Epoch: [44][80/200]\tLoss 0.8651 (0.4920)\tIOU 0.853 (0.918)\n",
      "Epoch: [44][100/200]\tLoss 0.4369 (0.4459)\tIOU 0.922 (0.928)\n",
      "Epoch: [44][120/200]\tLoss 0.5673 (0.5265)\tIOU 0.922 (0.912)\n",
      "Epoch: [44][140/200]\tLoss 0.7140 (0.5297)\tIOU 0.859 (0.908)\n",
      "Epoch: [44][160/200]\tLoss 0.3855 (0.4768)\tIOU 0.966 (0.925)\n",
      "Epoch: [44][180/200]\tLoss 0.3397 (0.4655)\tIOU 0.950 (0.925)\n",
      "Epoch: [44][Validation]\tVal_Loss: 1.20192\tVal_IOU: 0.83587\tBest Val_IOU: 0.84032\n",
      "epoch time:  105.69611835479736\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0011\n",
      "Epoch: [45][0/200]\tLoss 0.6137 (0.6137)\tIOU 0.903 (0.903)\n",
      "Epoch: [45][20/200]\tLoss 0.4957 (0.4549)\tIOU 0.925 (0.926)\n",
      "Epoch: [45][40/200]\tLoss 0.6565 (0.4324)\tIOU 0.853 (0.934)\n",
      "Epoch: [45][60/200]\tLoss 0.9214 (0.4910)\tIOU 0.891 (0.925)\n",
      "Epoch: [45][80/200]\tLoss 0.6189 (0.5624)\tIOU 0.891 (0.898)\n",
      "Epoch: [45][100/200]\tLoss 0.6548 (0.4630)\tIOU 0.881 (0.924)\n",
      "Epoch: [45][120/200]\tLoss 0.3640 (0.4610)\tIOU 0.944 (0.924)\n",
      "Epoch: [45][140/200]\tLoss 0.3365 (0.4653)\tIOU 0.969 (0.920)\n",
      "Epoch: [45][160/200]\tLoss 0.5143 (0.4612)\tIOU 0.909 (0.925)\n",
      "Epoch: [45][180/200]\tLoss 0.5567 (0.4894)\tIOU 0.913 (0.919)\n",
      "Epoch: [45][Validation]\tVal_Loss: 1.17966\tVal_IOU: 0.84092\tBest Val_IOU: 0.84092\n",
      "epoch time:  107.27882981300354\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0011\n",
      "Epoch: [46][0/200]\tLoss 0.5426 (0.5426)\tIOU 0.891 (0.891)\n",
      "Epoch: [46][20/200]\tLoss 0.7192 (0.5060)\tIOU 0.900 (0.915)\n",
      "Epoch: [46][40/200]\tLoss 0.3068 (0.4902)\tIOU 0.978 (0.926)\n",
      "Epoch: [46][60/200]\tLoss 0.5342 (0.5350)\tIOU 0.906 (0.912)\n",
      "Epoch: [46][80/200]\tLoss 0.6817 (0.5136)\tIOU 0.897 (0.915)\n",
      "Epoch: [46][100/200]\tLoss 0.6697 (0.4322)\tIOU 0.875 (0.932)\n",
      "Epoch: [46][120/200]\tLoss 0.9656 (0.4665)\tIOU 0.781 (0.924)\n",
      "Epoch: [46][140/200]\tLoss 0.4225 (0.5075)\tIOU 0.941 (0.914)\n",
      "Epoch: [46][160/200]\tLoss 0.1977 (0.4521)\tIOU 0.988 (0.925)\n",
      "Epoch: [46][180/200]\tLoss 0.3782 (0.4422)\tIOU 0.944 (0.928)\n",
      "Epoch: [46][Validation]\tVal_Loss: 1.15290\tVal_IOU: 0.83863\tBest Val_IOU: 0.84092\n",
      "epoch time:  105.66074419021606\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0010\n",
      "Epoch: [47][0/200]\tLoss 0.4800 (0.4800)\tIOU 0.906 (0.906)\n",
      "Epoch: [47][20/200]\tLoss 0.3476 (0.4163)\tIOU 0.953 (0.934)\n",
      "Epoch: [47][40/200]\tLoss 0.4301 (0.4878)\tIOU 0.931 (0.920)\n",
      "Epoch: [47][60/200]\tLoss 0.8357 (0.4570)\tIOU 0.819 (0.925)\n",
      "Epoch: [47][80/200]\tLoss 0.7620 (0.5232)\tIOU 0.866 (0.914)\n",
      "Epoch: [47][100/200]\tLoss 0.5071 (0.4988)\tIOU 0.903 (0.912)\n",
      "Epoch: [47][120/200]\tLoss 0.3471 (0.4913)\tIOU 0.956 (0.922)\n",
      "Epoch: [47][140/200]\tLoss 0.6317 (0.5025)\tIOU 0.909 (0.919)\n",
      "Epoch: [47][160/200]\tLoss 0.4364 (0.4627)\tIOU 0.953 (0.930)\n",
      "Epoch: [47][180/200]\tLoss 0.3972 (0.4845)\tIOU 0.959 (0.925)\n",
      "Epoch: [47][Validation]\tVal_Loss: 1.15640\tVal_IOU: 0.83190\tBest Val_IOU: 0.84092\n",
      "epoch time:  105.62170052528381\n",
      "Fold/Cycle: [2/0]\t\n",
      "change learning rate into: 0.0010\n",
      "Epoch: [48][0/200]\tLoss 0.4333 (0.4333)\tIOU 0.953 (0.953)\n",
      "Epoch: [48][20/200]\tLoss 0.4458 (0.5322)\tIOU 0.944 (0.913)\n",
      "Epoch: [48][40/200]\tLoss 0.4718 (0.4579)\tIOU 0.916 (0.927)\n",
      "Epoch: [48][60/200]\tLoss 0.7104 (0.5037)\tIOU 0.866 (0.916)\n",
      "Epoch: [48][80/200]\tLoss 0.2120 (0.4650)\tIOU 0.981 (0.921)\n",
      "Epoch: [48][100/200]\tLoss 0.8221 (0.4464)\tIOU 0.809 (0.922)\n",
      "Epoch: [48][120/200]\tLoss 0.4635 (0.4362)\tIOU 0.934 (0.929)\n",
      "Epoch: [48][140/200]\tLoss 0.1604 (0.4725)\tIOU 0.988 (0.924)\n",
      "Epoch: [48][160/200]\tLoss 0.5700 (0.4598)\tIOU 0.925 (0.928)\n",
      "Epoch: [48][180/200]\tLoss 0.6660 (0.4958)\tIOU 0.853 (0.914)\n",
      "Epoch: [48][Validation]\tVal_Loss: 1.18165\tVal_IOU: 0.83730\tBest Val_IOU: 0.84092\n",
      "epoch time:  105.49311852455139\n",
      "Fold/Cycle: [2/0]\t\n",
      "restart at epoch 050\n",
      "change learning rate into: 0.0010\n",
      "Epoch: [49][0/200]\tLoss 0.1688 (0.1688)\tIOU 0.966 (0.966)\n",
      "Epoch: [49][20/200]\tLoss 0.3861 (0.5065)\tIOU 0.963 (0.918)\n",
      "Epoch: [49][40/200]\tLoss 0.5167 (0.4311)\tIOU 0.900 (0.931)\n",
      "Epoch: [49][60/200]\tLoss 0.3308 (0.5138)\tIOU 0.953 (0.907)\n",
      "Epoch: [49][80/200]\tLoss 0.4404 (0.4325)\tIOU 0.900 (0.932)\n",
      "Epoch: [49][100/200]\tLoss 0.3277 (0.4405)\tIOU 0.959 (0.927)\n",
      "Epoch: [49][120/200]\tLoss 0.6842 (0.4580)\tIOU 0.891 (0.928)\n",
      "Epoch: [49][140/200]\tLoss 0.2880 (0.4656)\tIOU 0.953 (0.927)\n",
      "Epoch: [49][160/200]\tLoss 0.4769 (0.4241)\tIOU 0.928 (0.933)\n",
      "Epoch: [49][180/200]\tLoss 0.5703 (0.4623)\tIOU 0.934 (0.929)\n",
      "Epoch: [49][Validation]\tVal_Loss: 1.16641\tVal_IOU: 0.84272\tBest Val_IOU: 0.84272\n",
      "epoch time:  107.46001815795898\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0100\n",
      "Epoch: [0][0/200]\tLoss 0.7163 (0.7163)\tIOU 0.863 (0.863)\n",
      "Epoch: [0][20/200]\tLoss 1.3455 (0.5916)\tIOU 0.750 (0.907)\n",
      "Epoch: [0][40/200]\tLoss 1.2182 (1.0324)\tIOU 0.812 (0.834)\n",
      "Epoch: [0][60/200]\tLoss 1.1292 (0.9994)\tIOU 0.806 (0.840)\n",
      "Epoch: [0][80/200]\tLoss 0.5408 (0.9115)\tIOU 0.938 (0.851)\n",
      "Epoch: [0][100/200]\tLoss 0.8980 (0.9823)\tIOU 0.872 (0.835)\n",
      "Epoch: [0][120/200]\tLoss 1.0329 (0.9351)\tIOU 0.797 (0.842)\n",
      "Epoch: [0][140/200]\tLoss 1.0966 (0.9836)\tIOU 0.806 (0.840)\n",
      "Epoch: [0][160/200]\tLoss 0.6916 (0.8849)\tIOU 0.903 (0.862)\n",
      "Epoch: [0][180/200]\tLoss 0.9410 (0.8035)\tIOU 0.837 (0.866)\n",
      "Epoch: [0][Validation]\tVal_Loss: 1.38288\tVal_IOU: 0.80034\tBest Val_IOU: 0.80034\n",
      "epoch time:  104.86856484413147\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0100\n",
      "Epoch: [1][0/200]\tLoss 0.6767 (0.6767)\tIOU 0.909 (0.909)\n",
      "Epoch: [1][20/200]\tLoss 0.9755 (0.8972)\tIOU 0.863 (0.850)\n",
      "Epoch: [1][40/200]\tLoss 1.5563 (0.9538)\tIOU 0.762 (0.839)\n",
      "Epoch: [1][60/200]\tLoss 1.2637 (0.7920)\tIOU 0.747 (0.872)\n",
      "Epoch: [1][80/200]\tLoss 0.8592 (0.7782)\tIOU 0.834 (0.875)\n",
      "Epoch: [1][100/200]\tLoss 1.1188 (0.9146)\tIOU 0.772 (0.855)\n",
      "Epoch: [1][120/200]\tLoss 0.8370 (0.7939)\tIOU 0.866 (0.866)\n",
      "Epoch: [1][140/200]\tLoss 0.5207 (0.8070)\tIOU 0.925 (0.872)\n",
      "Epoch: [1][160/200]\tLoss 0.7126 (0.7776)\tIOU 0.900 (0.870)\n",
      "Epoch: [1][180/200]\tLoss 0.7153 (0.8239)\tIOU 0.884 (0.862)\n",
      "Epoch: [1][Validation]\tVal_Loss: 1.49090\tVal_IOU: 0.80399\tBest Val_IOU: 0.80399\n",
      "epoch time:  108.42932152748108\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0099\n",
      "Epoch: [2][0/200]\tLoss 1.0175 (1.0175)\tIOU 0.791 (0.791)\n",
      "Epoch: [2][20/200]\tLoss 0.5380 (0.7522)\tIOU 0.931 (0.885)\n",
      "Epoch: [2][40/200]\tLoss 0.8895 (0.8208)\tIOU 0.884 (0.875)\n",
      "Epoch: [2][60/200]\tLoss 0.8812 (0.7867)\tIOU 0.859 (0.866)\n",
      "Epoch: [2][80/200]\tLoss 0.6143 (0.8101)\tIOU 0.897 (0.869)\n",
      "Epoch: [2][100/200]\tLoss 0.7293 (0.8560)\tIOU 0.884 (0.845)\n",
      "Epoch: [2][120/200]\tLoss 0.6975 (0.9407)\tIOU 0.878 (0.853)\n",
      "Epoch: [2][140/200]\tLoss 0.5319 (0.8522)\tIOU 0.941 (0.870)\n",
      "Epoch: [2][160/200]\tLoss 0.8572 (0.7724)\tIOU 0.856 (0.872)\n",
      "Epoch: [2][180/200]\tLoss 0.7834 (0.8630)\tIOU 0.894 (0.861)\n",
      "Epoch: [2][Validation]\tVal_Loss: 1.19804\tVal_IOU: 0.82673\tBest Val_IOU: 0.82673\n",
      "epoch time:  107.62791061401367\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0099\n",
      "Epoch: [3][0/200]\tLoss 0.5850 (0.5850)\tIOU 0.887 (0.887)\n",
      "Epoch: [3][20/200]\tLoss 0.6665 (0.7699)\tIOU 0.903 (0.871)\n",
      "Epoch: [3][40/200]\tLoss 0.7892 (0.8677)\tIOU 0.859 (0.855)\n",
      "Epoch: [3][60/200]\tLoss 0.7102 (0.9383)\tIOU 0.878 (0.844)\n",
      "Epoch: [3][80/200]\tLoss 0.4737 (0.8052)\tIOU 0.919 (0.867)\n",
      "Epoch: [3][100/200]\tLoss 1.1563 (0.8751)\tIOU 0.800 (0.859)\n",
      "Epoch: [3][120/200]\tLoss 0.8760 (0.8260)\tIOU 0.863 (0.866)\n",
      "Epoch: [3][140/200]\tLoss 1.0430 (0.7888)\tIOU 0.806 (0.874)\n",
      "Epoch: [3][160/200]\tLoss 1.1841 (0.7367)\tIOU 0.766 (0.885)\n",
      "Epoch: [3][180/200]\tLoss 1.0647 (0.7369)\tIOU 0.816 (0.880)\n",
      "Epoch: [3][Validation]\tVal_Loss: 1.26674\tVal_IOU: 0.78755\tBest Val_IOU: 0.82673\n",
      "epoch time:  105.60057759284973\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0098\n",
      "Epoch: [4][0/200]\tLoss 0.7587 (0.7587)\tIOU 0.859 (0.859)\n",
      "Epoch: [4][20/200]\tLoss 1.1195 (0.6954)\tIOU 0.803 (0.886)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][40/200]\tLoss 1.5737 (0.8790)\tIOU 0.819 (0.855)\n",
      "Epoch: [4][60/200]\tLoss 0.9459 (0.8614)\tIOU 0.831 (0.852)\n",
      "Epoch: [4][80/200]\tLoss 1.1151 (0.8100)\tIOU 0.844 (0.868)\n",
      "Epoch: [4][100/200]\tLoss 1.2623 (0.8313)\tIOU 0.803 (0.870)\n",
      "Epoch: [4][120/200]\tLoss 0.8786 (0.7144)\tIOU 0.884 (0.891)\n",
      "Epoch: [4][140/200]\tLoss 0.8974 (0.8168)\tIOU 0.853 (0.871)\n",
      "Epoch: [4][160/200]\tLoss 0.8587 (0.9337)\tIOU 0.834 (0.840)\n",
      "Epoch: [4][180/200]\tLoss 1.0847 (0.9086)\tIOU 0.806 (0.853)\n",
      "Epoch: [4][Validation]\tVal_Loss: 1.24512\tVal_IOU: 0.80735\tBest Val_IOU: 0.82673\n",
      "epoch time:  105.00754761695862\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0097\n",
      "Epoch: [5][0/200]\tLoss 0.5363 (0.5363)\tIOU 0.916 (0.916)\n",
      "Epoch: [5][20/200]\tLoss 0.4181 (0.7622)\tIOU 0.928 (0.879)\n",
      "Epoch: [5][40/200]\tLoss 0.7836 (0.8356)\tIOU 0.906 (0.869)\n",
      "Epoch: [5][60/200]\tLoss 0.5775 (0.8176)\tIOU 0.909 (0.875)\n",
      "Epoch: [5][80/200]\tLoss 0.7498 (0.7415)\tIOU 0.903 (0.887)\n",
      "Epoch: [5][100/200]\tLoss 1.1534 (0.7292)\tIOU 0.762 (0.876)\n",
      "Epoch: [5][120/200]\tLoss 0.6273 (0.7145)\tIOU 0.919 (0.880)\n",
      "Epoch: [5][140/200]\tLoss 0.6516 (0.8101)\tIOU 0.887 (0.866)\n",
      "Epoch: [5][160/200]\tLoss 0.7818 (0.7841)\tIOU 0.872 (0.871)\n",
      "Epoch: [5][180/200]\tLoss 0.6290 (0.7745)\tIOU 0.881 (0.874)\n",
      "Epoch: [5][Validation]\tVal_Loss: 1.15659\tVal_IOU: 0.82501\tBest Val_IOU: 0.82673\n",
      "epoch time:  105.29851126670837\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0096\n",
      "Epoch: [6][0/200]\tLoss 1.1759 (1.1759)\tIOU 0.772 (0.772)\n",
      "Epoch: [6][20/200]\tLoss 0.6384 (0.8084)\tIOU 0.897 (0.867)\n",
      "Epoch: [6][40/200]\tLoss 0.9929 (0.7909)\tIOU 0.837 (0.871)\n",
      "Epoch: [6][60/200]\tLoss 1.0018 (0.7801)\tIOU 0.872 (0.873)\n",
      "Epoch: [6][80/200]\tLoss 0.4067 (0.8297)\tIOU 0.941 (0.869)\n",
      "Epoch: [6][100/200]\tLoss 0.4618 (0.7528)\tIOU 0.931 (0.875)\n",
      "Epoch: [6][120/200]\tLoss 0.5926 (0.7203)\tIOU 0.909 (0.888)\n",
      "Epoch: [6][140/200]\tLoss 1.4406 (0.7247)\tIOU 0.772 (0.891)\n",
      "Epoch: [6][160/200]\tLoss 0.9389 (0.7607)\tIOU 0.834 (0.880)\n",
      "Epoch: [6][180/200]\tLoss 0.5373 (0.7361)\tIOU 0.903 (0.879)\n",
      "Epoch: [6][Validation]\tVal_Loss: 1.23695\tVal_IOU: 0.79971\tBest Val_IOU: 0.82673\n",
      "epoch time:  105.26887321472168\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0094\n",
      "Epoch: [7][0/200]\tLoss 0.5685 (0.5685)\tIOU 0.894 (0.894)\n",
      "Epoch: [7][20/200]\tLoss 0.6397 (0.7341)\tIOU 0.884 (0.893)\n",
      "Epoch: [7][40/200]\tLoss 0.9011 (0.6891)\tIOU 0.834 (0.891)\n",
      "Epoch: [7][60/200]\tLoss 0.8637 (0.6564)\tIOU 0.844 (0.895)\n",
      "Epoch: [7][80/200]\tLoss 0.8041 (0.8084)\tIOU 0.912 (0.864)\n",
      "Epoch: [7][100/200]\tLoss 0.6670 (0.7593)\tIOU 0.903 (0.874)\n",
      "Epoch: [7][120/200]\tLoss 0.6003 (0.7794)\tIOU 0.909 (0.871)\n",
      "Epoch: [7][140/200]\tLoss 0.5803 (0.6738)\tIOU 0.912 (0.893)\n",
      "Epoch: [7][160/200]\tLoss 1.0133 (0.6855)\tIOU 0.816 (0.892)\n",
      "Epoch: [7][180/200]\tLoss 0.7459 (0.7116)\tIOU 0.881 (0.880)\n",
      "Epoch: [7][Validation]\tVal_Loss: 1.44488\tVal_IOU: 0.80758\tBest Val_IOU: 0.82673\n",
      "epoch time:  104.27383327484131\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0093\n",
      "Epoch: [8][0/200]\tLoss 1.1467 (1.1467)\tIOU 0.803 (0.803)\n",
      "Epoch: [8][20/200]\tLoss 0.3590 (0.8216)\tIOU 0.959 (0.858)\n",
      "Epoch: [8][40/200]\tLoss 0.4066 (0.8117)\tIOU 0.941 (0.858)\n",
      "Epoch: [8][60/200]\tLoss 0.7928 (0.6583)\tIOU 0.869 (0.895)\n",
      "Epoch: [8][80/200]\tLoss 0.8850 (0.7265)\tIOU 0.863 (0.885)\n",
      "Epoch: [8][100/200]\tLoss 0.5918 (0.7191)\tIOU 0.897 (0.879)\n",
      "Epoch: [8][120/200]\tLoss 0.6871 (0.7041)\tIOU 0.909 (0.885)\n",
      "Epoch: [8][140/200]\tLoss 0.9786 (0.7069)\tIOU 0.791 (0.885)\n",
      "Epoch: [8][160/200]\tLoss 0.8309 (0.8534)\tIOU 0.856 (0.854)\n",
      "Epoch: [8][180/200]\tLoss 0.6389 (0.7681)\tIOU 0.856 (0.874)\n",
      "Epoch: [8][Validation]\tVal_Loss: 1.31525\tVal_IOU: 0.80798\tBest Val_IOU: 0.82673\n",
      "epoch time:  105.95296716690063\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0091\n",
      "Epoch: [9][0/200]\tLoss 0.8251 (0.8251)\tIOU 0.853 (0.853)\n",
      "Epoch: [9][20/200]\tLoss 0.4812 (0.7927)\tIOU 0.922 (0.876)\n",
      "Epoch: [9][40/200]\tLoss 1.1051 (0.8123)\tIOU 0.825 (0.872)\n",
      "Epoch: [9][60/200]\tLoss 0.5830 (0.7492)\tIOU 0.878 (0.880)\n",
      "Epoch: [9][80/200]\tLoss 0.8737 (0.8227)\tIOU 0.906 (0.870)\n",
      "Epoch: [9][100/200]\tLoss 0.7209 (0.7466)\tIOU 0.875 (0.883)\n",
      "Epoch: [9][120/200]\tLoss 0.6353 (0.7333)\tIOU 0.916 (0.889)\n",
      "Epoch: [9][140/200]\tLoss 1.2833 (0.8142)\tIOU 0.772 (0.853)\n",
      "Epoch: [9][160/200]\tLoss 0.7814 (0.7705)\tIOU 0.900 (0.874)\n",
      "Epoch: [9][180/200]\tLoss 0.7521 (0.7251)\tIOU 0.875 (0.886)\n",
      "Epoch: [9][Validation]\tVal_Loss: 1.17958\tVal_IOU: 0.81952\tBest Val_IOU: 0.82673\n",
      "epoch time:  104.72033381462097\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0090\n",
      "Epoch: [10][0/200]\tLoss 0.6606 (0.6606)\tIOU 0.866 (0.866)\n",
      "Epoch: [10][20/200]\tLoss 0.6926 (0.6678)\tIOU 0.881 (0.895)\n",
      "Epoch: [10][40/200]\tLoss 0.6479 (0.6603)\tIOU 0.878 (0.892)\n",
      "Epoch: [10][60/200]\tLoss 0.7226 (0.6527)\tIOU 0.894 (0.898)\n",
      "Epoch: [10][80/200]\tLoss 0.7847 (0.7887)\tIOU 0.872 (0.859)\n",
      "Epoch: [10][100/200]\tLoss 0.4447 (0.6320)\tIOU 0.944 (0.898)\n",
      "Epoch: [10][120/200]\tLoss 0.7176 (0.6401)\tIOU 0.912 (0.895)\n",
      "Epoch: [10][140/200]\tLoss 0.6951 (0.7214)\tIOU 0.856 (0.879)\n",
      "Epoch: [10][160/200]\tLoss 0.6933 (0.7154)\tIOU 0.913 (0.893)\n",
      "Epoch: [10][180/200]\tLoss 0.6059 (0.8339)\tIOU 0.931 (0.862)\n",
      "Epoch: [10][Validation]\tVal_Loss: 1.26998\tVal_IOU: 0.81996\tBest Val_IOU: 0.82673\n",
      "epoch time:  105.65455150604248\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0088\n",
      "Epoch: [11][0/200]\tLoss 0.4203 (0.4203)\tIOU 0.931 (0.931)\n",
      "Epoch: [11][20/200]\tLoss 0.6810 (0.6474)\tIOU 0.891 (0.901)\n",
      "Epoch: [11][40/200]\tLoss 1.0226 (0.6838)\tIOU 0.816 (0.888)\n",
      "Epoch: [11][60/200]\tLoss 0.5645 (0.7113)\tIOU 0.900 (0.877)\n",
      "Epoch: [11][80/200]\tLoss 0.3116 (0.6758)\tIOU 0.984 (0.896)\n",
      "Epoch: [11][100/200]\tLoss 0.7653 (0.7112)\tIOU 0.850 (0.886)\n",
      "Epoch: [11][120/200]\tLoss 1.0203 (0.7536)\tIOU 0.812 (0.875)\n",
      "Epoch: [11][140/200]\tLoss 0.3663 (0.6819)\tIOU 0.963 (0.885)\n",
      "Epoch: [11][160/200]\tLoss 0.4696 (0.5610)\tIOU 0.922 (0.906)\n",
      "Epoch: [11][180/200]\tLoss 0.8454 (0.7434)\tIOU 0.875 (0.874)\n",
      "Epoch: [11][Validation]\tVal_Loss: 1.17362\tVal_IOU: 0.81552\tBest Val_IOU: 0.82673\n",
      "epoch time:  105.66958522796631\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0086\n",
      "Epoch: [12][0/200]\tLoss 0.8617 (0.8617)\tIOU 0.863 (0.863)\n",
      "Epoch: [12][20/200]\tLoss 0.6389 (0.8001)\tIOU 0.875 (0.870)\n",
      "Epoch: [12][40/200]\tLoss 0.6035 (0.6966)\tIOU 0.897 (0.888)\n",
      "Epoch: [12][60/200]\tLoss 0.6552 (0.7183)\tIOU 0.903 (0.882)\n",
      "Epoch: [12][80/200]\tLoss 0.3764 (0.6768)\tIOU 0.944 (0.889)\n",
      "Epoch: [12][100/200]\tLoss 0.6396 (0.6296)\tIOU 0.925 (0.894)\n",
      "Epoch: [12][120/200]\tLoss 0.5015 (0.7172)\tIOU 0.928 (0.885)\n",
      "Epoch: [12][140/200]\tLoss 0.5047 (0.6041)\tIOU 0.906 (0.894)\n",
      "Epoch: [12][160/200]\tLoss 0.3469 (0.5873)\tIOU 0.944 (0.900)\n",
      "Epoch: [12][180/200]\tLoss 0.4338 (0.6650)\tIOU 0.925 (0.887)\n",
      "Epoch: [12][Validation]\tVal_Loss: 1.27167\tVal_IOU: 0.82189\tBest Val_IOU: 0.82673\n",
      "epoch time:  105.077472448349\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0084\n",
      "Epoch: [13][0/200]\tLoss 0.6569 (0.6569)\tIOU 0.903 (0.903)\n",
      "Epoch: [13][20/200]\tLoss 0.9696 (0.7437)\tIOU 0.825 (0.883)\n",
      "Epoch: [13][40/200]\tLoss 1.0524 (0.7099)\tIOU 0.900 (0.889)\n",
      "Epoch: [13][60/200]\tLoss 0.9940 (0.6831)\tIOU 0.825 (0.884)\n",
      "Epoch: [13][80/200]\tLoss 0.7439 (0.6378)\tIOU 0.869 (0.897)\n",
      "Epoch: [13][100/200]\tLoss 0.8179 (0.6005)\tIOU 0.859 (0.901)\n",
      "Epoch: [13][120/200]\tLoss 0.5859 (0.7775)\tIOU 0.928 (0.871)\n",
      "Epoch: [13][140/200]\tLoss 1.1031 (0.7751)\tIOU 0.819 (0.864)\n",
      "Epoch: [13][160/200]\tLoss 0.5873 (0.6889)\tIOU 0.909 (0.884)\n",
      "Epoch: [13][180/200]\tLoss 0.6392 (0.7195)\tIOU 0.891 (0.886)\n",
      "Epoch: [13][Validation]\tVal_Loss: 1.24249\tVal_IOU: 0.82288\tBest Val_IOU: 0.82673\n",
      "epoch time:  105.93128538131714\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0081\n",
      "Epoch: [14][0/200]\tLoss 0.8065 (0.8065)\tIOU 0.856 (0.856)\n",
      "Epoch: [14][20/200]\tLoss 0.6898 (0.6674)\tIOU 0.869 (0.890)\n",
      "Epoch: [14][40/200]\tLoss 0.7747 (0.7148)\tIOU 0.856 (0.884)\n",
      "Epoch: [14][60/200]\tLoss 0.5257 (0.7167)\tIOU 0.928 (0.880)\n",
      "Epoch: [14][80/200]\tLoss 0.6633 (0.7013)\tIOU 0.916 (0.880)\n",
      "Epoch: [14][100/200]\tLoss 0.5558 (0.7388)\tIOU 0.903 (0.875)\n",
      "Epoch: [14][120/200]\tLoss 0.5454 (0.6789)\tIOU 0.891 (0.887)\n",
      "Epoch: [14][140/200]\tLoss 0.4484 (0.6665)\tIOU 0.919 (0.893)\n",
      "Epoch: [14][160/200]\tLoss 0.5166 (0.6442)\tIOU 0.922 (0.899)\n",
      "Epoch: [14][180/200]\tLoss 0.6673 (0.6004)\tIOU 0.919 (0.914)\n",
      "Epoch: [14][Validation]\tVal_Loss: 1.34969\tVal_IOU: 0.81930\tBest Val_IOU: 0.82673\n",
      "epoch time:  104.36978387832642\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0079\n",
      "Epoch: [15][0/200]\tLoss 0.7971 (0.7971)\tIOU 0.875 (0.875)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [15][20/200]\tLoss 0.8193 (0.6912)\tIOU 0.894 (0.887)\n",
      "Epoch: [15][40/200]\tLoss 0.5374 (0.6279)\tIOU 0.916 (0.892)\n",
      "Epoch: [15][60/200]\tLoss 0.9699 (0.6105)\tIOU 0.881 (0.907)\n",
      "Epoch: [15][80/200]\tLoss 0.7590 (0.6840)\tIOU 0.894 (0.881)\n",
      "Epoch: [15][100/200]\tLoss 0.6109 (0.6177)\tIOU 0.913 (0.896)\n",
      "Epoch: [15][120/200]\tLoss 0.6435 (0.6501)\tIOU 0.919 (0.896)\n",
      "Epoch: [15][140/200]\tLoss 0.6066 (0.6044)\tIOU 0.909 (0.905)\n",
      "Epoch: [15][160/200]\tLoss 0.3801 (0.5797)\tIOU 0.950 (0.909)\n",
      "Epoch: [15][180/200]\tLoss 1.1380 (0.7025)\tIOU 0.825 (0.884)\n",
      "Epoch: [15][Validation]\tVal_Loss: 1.23915\tVal_IOU: 0.81486\tBest Val_IOU: 0.82673\n",
      "epoch time:  105.34666538238525\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0077\n",
      "Epoch: [16][0/200]\tLoss 0.6957 (0.6957)\tIOU 0.887 (0.887)\n",
      "Epoch: [16][20/200]\tLoss 0.5478 (0.6711)\tIOU 0.922 (0.887)\n",
      "Epoch: [16][40/200]\tLoss 0.3276 (0.6828)\tIOU 0.966 (0.895)\n",
      "Epoch: [16][60/200]\tLoss 0.6722 (0.6108)\tIOU 0.897 (0.906)\n",
      "Epoch: [16][80/200]\tLoss 0.3646 (0.5217)\tIOU 0.941 (0.926)\n",
      "Epoch: [16][100/200]\tLoss 0.6010 (0.6294)\tIOU 0.903 (0.898)\n",
      "Epoch: [16][120/200]\tLoss 0.6449 (0.6163)\tIOU 0.869 (0.902)\n",
      "Epoch: [16][140/200]\tLoss 0.7896 (0.6234)\tIOU 0.875 (0.899)\n",
      "Epoch: [16][160/200]\tLoss 0.8417 (0.6330)\tIOU 0.850 (0.893)\n",
      "Epoch: [16][180/200]\tLoss 0.6558 (0.6543)\tIOU 0.894 (0.894)\n",
      "Epoch: [16][Validation]\tVal_Loss: 1.18054\tVal_IOU: 0.83210\tBest Val_IOU: 0.83210\n",
      "epoch time:  107.30028080940247\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0074\n",
      "Epoch: [17][0/200]\tLoss 0.5585 (0.5585)\tIOU 0.897 (0.897)\n",
      "Epoch: [17][20/200]\tLoss 0.8613 (0.6840)\tIOU 0.856 (0.888)\n",
      "Epoch: [17][40/200]\tLoss 0.9065 (0.6816)\tIOU 0.837 (0.885)\n",
      "Epoch: [17][60/200]\tLoss 0.3851 (0.5947)\tIOU 0.947 (0.905)\n",
      "Epoch: [17][80/200]\tLoss 0.2935 (0.6934)\tIOU 0.966 (0.883)\n",
      "Epoch: [17][100/200]\tLoss 0.6808 (0.6632)\tIOU 0.881 (0.898)\n",
      "Epoch: [17][120/200]\tLoss 0.9294 (0.5845)\tIOU 0.850 (0.904)\n",
      "Epoch: [17][140/200]\tLoss 0.6145 (0.6376)\tIOU 0.894 (0.895)\n",
      "Epoch: [17][160/200]\tLoss 0.8424 (0.6414)\tIOU 0.844 (0.897)\n",
      "Epoch: [17][180/200]\tLoss 0.7625 (0.6555)\tIOU 0.847 (0.888)\n",
      "Epoch: [17][Validation]\tVal_Loss: 1.44642\tVal_IOU: 0.82625\tBest Val_IOU: 0.83210\n",
      "epoch time:  104.65630555152893\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0072\n",
      "Epoch: [18][0/200]\tLoss 0.7810 (0.7810)\tIOU 0.878 (0.878)\n",
      "Epoch: [18][20/200]\tLoss 0.6912 (0.6510)\tIOU 0.878 (0.900)\n",
      "Epoch: [18][40/200]\tLoss 0.6038 (0.5831)\tIOU 0.900 (0.908)\n",
      "Epoch: [18][60/200]\tLoss 0.4626 (0.5313)\tIOU 0.916 (0.911)\n",
      "Epoch: [18][80/200]\tLoss 0.3745 (0.5325)\tIOU 0.947 (0.920)\n",
      "Epoch: [18][100/200]\tLoss 0.4279 (0.5794)\tIOU 0.950 (0.910)\n",
      "Epoch: [18][120/200]\tLoss 0.5536 (0.5534)\tIOU 0.912 (0.913)\n",
      "Epoch: [18][140/200]\tLoss 0.6130 (0.5256)\tIOU 0.888 (0.913)\n",
      "Epoch: [18][160/200]\tLoss 1.4099 (0.6540)\tIOU 0.738 (0.888)\n",
      "Epoch: [18][180/200]\tLoss 0.4952 (0.5589)\tIOU 0.919 (0.910)\n",
      "Epoch: [18][Validation]\tVal_Loss: 1.18790\tVal_IOU: 0.83082\tBest Val_IOU: 0.83210\n",
      "epoch time:  104.78967666625977\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0069\n",
      "Epoch: [19][0/200]\tLoss 0.5945 (0.5945)\tIOU 0.909 (0.909)\n",
      "Epoch: [19][20/200]\tLoss 0.5123 (0.5941)\tIOU 0.931 (0.906)\n",
      "Epoch: [19][40/200]\tLoss 0.3546 (0.6972)\tIOU 0.969 (0.884)\n",
      "Epoch: [19][60/200]\tLoss 0.6742 (0.5899)\tIOU 0.872 (0.899)\n",
      "Epoch: [19][80/200]\tLoss 0.8891 (0.6276)\tIOU 0.812 (0.892)\n",
      "Epoch: [19][100/200]\tLoss 0.5886 (0.6203)\tIOU 0.919 (0.895)\n",
      "Epoch: [19][120/200]\tLoss 0.8478 (0.6297)\tIOU 0.859 (0.897)\n",
      "Epoch: [19][140/200]\tLoss 0.5525 (0.5101)\tIOU 0.934 (0.920)\n",
      "Epoch: [19][160/200]\tLoss 0.5658 (0.5740)\tIOU 0.891 (0.905)\n",
      "Epoch: [19][180/200]\tLoss 0.2925 (0.5475)\tIOU 0.991 (0.917)\n",
      "Epoch: [19][Validation]\tVal_Loss: 1.14562\tVal_IOU: 0.81811\tBest Val_IOU: 0.83210\n",
      "epoch time:  104.6881172657013\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0066\n",
      "Epoch: [20][0/200]\tLoss 0.3415 (0.3415)\tIOU 0.959 (0.959)\n",
      "Epoch: [20][20/200]\tLoss 0.5451 (0.5791)\tIOU 0.909 (0.905)\n",
      "Epoch: [20][40/200]\tLoss 0.6052 (0.5783)\tIOU 0.909 (0.906)\n",
      "Epoch: [20][60/200]\tLoss 0.5358 (0.5148)\tIOU 0.909 (0.920)\n",
      "Epoch: [20][80/200]\tLoss 0.3992 (0.5289)\tIOU 0.947 (0.913)\n",
      "Epoch: [20][100/200]\tLoss 0.3256 (0.5941)\tIOU 0.947 (0.908)\n",
      "Epoch: [20][120/200]\tLoss 0.6752 (0.6478)\tIOU 0.856 (0.886)\n",
      "Epoch: [20][140/200]\tLoss 0.8758 (0.6116)\tIOU 0.847 (0.891)\n",
      "Epoch: [20][160/200]\tLoss 0.3648 (0.5637)\tIOU 0.941 (0.904)\n",
      "Epoch: [20][180/200]\tLoss 0.6163 (0.5356)\tIOU 0.887 (0.920)\n",
      "Epoch: [20][Validation]\tVal_Loss: 1.27330\tVal_IOU: 0.82758\tBest Val_IOU: 0.83210\n",
      "epoch time:  105.40234303474426\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0063\n",
      "Epoch: [21][0/200]\tLoss 0.6480 (0.6480)\tIOU 0.891 (0.891)\n",
      "Epoch: [21][20/200]\tLoss 1.0716 (0.6065)\tIOU 0.816 (0.903)\n",
      "Epoch: [21][40/200]\tLoss 0.6992 (0.5961)\tIOU 0.906 (0.901)\n",
      "Epoch: [21][60/200]\tLoss 0.5053 (0.5831)\tIOU 0.916 (0.900)\n",
      "Epoch: [21][80/200]\tLoss 0.6969 (0.5802)\tIOU 0.866 (0.904)\n",
      "Epoch: [21][100/200]\tLoss 0.4974 (0.5770)\tIOU 0.947 (0.908)\n",
      "Epoch: [21][120/200]\tLoss 0.8169 (0.5679)\tIOU 0.869 (0.907)\n",
      "Epoch: [21][140/200]\tLoss 0.5127 (0.5237)\tIOU 0.922 (0.911)\n",
      "Epoch: [21][160/200]\tLoss 0.3680 (0.5545)\tIOU 0.944 (0.913)\n",
      "Epoch: [21][180/200]\tLoss 0.2369 (0.5309)\tIOU 0.978 (0.912)\n",
      "Epoch: [21][Validation]\tVal_Loss: 1.14388\tVal_IOU: 0.82949\tBest Val_IOU: 0.83210\n",
      "epoch time:  105.10887169837952\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0061\n",
      "Epoch: [22][0/200]\tLoss 0.7929 (0.7929)\tIOU 0.844 (0.844)\n",
      "Epoch: [22][20/200]\tLoss 0.3831 (0.5845)\tIOU 0.947 (0.903)\n",
      "Epoch: [22][40/200]\tLoss 0.5140 (0.4850)\tIOU 0.903 (0.924)\n",
      "Epoch: [22][60/200]\tLoss 1.3422 (0.6246)\tIOU 0.834 (0.904)\n",
      "Epoch: [22][80/200]\tLoss 0.3675 (0.5375)\tIOU 0.962 (0.917)\n",
      "Epoch: [22][100/200]\tLoss 0.5359 (0.5677)\tIOU 0.912 (0.908)\n",
      "Epoch: [22][120/200]\tLoss 0.8975 (0.5595)\tIOU 0.838 (0.913)\n",
      "Epoch: [22][140/200]\tLoss 0.4014 (0.5572)\tIOU 0.950 (0.908)\n",
      "Epoch: [22][160/200]\tLoss 0.3350 (0.4502)\tIOU 0.969 (0.931)\n",
      "Epoch: [22][180/200]\tLoss 0.5521 (0.6999)\tIOU 0.875 (0.877)\n",
      "Epoch: [22][Validation]\tVal_Loss: 1.20675\tVal_IOU: 0.82697\tBest Val_IOU: 0.83210\n",
      "epoch time:  105.05985069274902\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0058\n",
      "Epoch: [23][0/200]\tLoss 0.5017 (0.5017)\tIOU 0.909 (0.909)\n",
      "Epoch: [23][20/200]\tLoss 0.6383 (0.5359)\tIOU 0.922 (0.913)\n",
      "Epoch: [23][40/200]\tLoss 0.3549 (0.4950)\tIOU 0.966 (0.925)\n",
      "Epoch: [23][60/200]\tLoss 0.3555 (0.5485)\tIOU 0.953 (0.909)\n",
      "Epoch: [23][80/200]\tLoss 0.4852 (0.5284)\tIOU 0.950 (0.917)\n",
      "Epoch: [23][100/200]\tLoss 0.8052 (0.5055)\tIOU 0.881 (0.922)\n",
      "Epoch: [23][120/200]\tLoss 1.3139 (0.5680)\tIOU 0.784 (0.908)\n",
      "Epoch: [23][140/200]\tLoss 0.4295 (0.4692)\tIOU 0.934 (0.924)\n",
      "Epoch: [23][160/200]\tLoss 0.5974 (0.5398)\tIOU 0.888 (0.911)\n",
      "Epoch: [23][180/200]\tLoss 0.2119 (0.5171)\tIOU 0.981 (0.922)\n",
      "Epoch: [23][Validation]\tVal_Loss: 1.18938\tVal_IOU: 0.83887\tBest Val_IOU: 0.83887\n",
      "epoch time:  107.06752347946167\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0055\n",
      "Epoch: [24][0/200]\tLoss 0.6137 (0.6137)\tIOU 0.869 (0.869)\n",
      "Epoch: [24][20/200]\tLoss 0.3071 (0.4691)\tIOU 0.956 (0.926)\n",
      "Epoch: [24][40/200]\tLoss 0.7341 (0.5240)\tIOU 0.869 (0.915)\n",
      "Epoch: [24][60/200]\tLoss 0.6079 (0.5486)\tIOU 0.916 (0.910)\n",
      "Epoch: [24][80/200]\tLoss 0.6131 (0.5908)\tIOU 0.887 (0.903)\n",
      "Epoch: [24][100/200]\tLoss 0.6719 (0.4700)\tIOU 0.878 (0.922)\n",
      "Epoch: [24][120/200]\tLoss 0.5505 (0.6100)\tIOU 0.916 (0.893)\n",
      "Epoch: [24][140/200]\tLoss 0.9547 (0.5381)\tIOU 0.809 (0.916)\n",
      "Epoch: [24][160/200]\tLoss 0.4779 (0.5029)\tIOU 0.938 (0.920)\n",
      "Epoch: [24][180/200]\tLoss 0.5012 (0.5693)\tIOU 0.919 (0.909)\n",
      "Epoch: [24][Validation]\tVal_Loss: 1.25668\tVal_IOU: 0.83814\tBest Val_IOU: 0.83887\n",
      "epoch time:  105.35181093215942\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0052\n",
      "Epoch: [25][0/200]\tLoss 0.4159 (0.4159)\tIOU 0.922 (0.922)\n",
      "Epoch: [25][20/200]\tLoss 0.5130 (0.5728)\tIOU 0.916 (0.905)\n",
      "Epoch: [25][40/200]\tLoss 0.6235 (0.5645)\tIOU 0.894 (0.903)\n",
      "Epoch: [25][60/200]\tLoss 0.4381 (0.5655)\tIOU 0.931 (0.908)\n",
      "Epoch: [25][80/200]\tLoss 0.4555 (0.4974)\tIOU 0.919 (0.917)\n",
      "Epoch: [25][100/200]\tLoss 0.6260 (0.5569)\tIOU 0.866 (0.910)\n",
      "Epoch: [25][120/200]\tLoss 0.5525 (0.5867)\tIOU 0.903 (0.900)\n",
      "Epoch: [25][140/200]\tLoss 0.4279 (0.4785)\tIOU 0.947 (0.924)\n",
      "Epoch: [25][160/200]\tLoss 0.4419 (0.4649)\tIOU 0.909 (0.923)\n",
      "Epoch: [25][180/200]\tLoss 0.6049 (0.5064)\tIOU 0.872 (0.913)\n",
      "Epoch: [25][Validation]\tVal_Loss: 1.19349\tVal_IOU: 0.83237\tBest Val_IOU: 0.83887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch time:  105.40421462059021\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0049\n",
      "Epoch: [26][0/200]\tLoss 0.2799 (0.2799)\tIOU 0.975 (0.975)\n",
      "Epoch: [26][20/200]\tLoss 0.4336 (0.5174)\tIOU 0.950 (0.922)\n",
      "Epoch: [26][40/200]\tLoss 0.8131 (0.5442)\tIOU 0.847 (0.906)\n",
      "Epoch: [26][60/200]\tLoss 0.6548 (0.4901)\tIOU 0.872 (0.924)\n",
      "Epoch: [26][80/200]\tLoss 0.5372 (0.5531)\tIOU 0.906 (0.911)\n",
      "Epoch: [26][100/200]\tLoss 0.3284 (0.4584)\tIOU 0.953 (0.924)\n",
      "Epoch: [26][120/200]\tLoss 0.6933 (0.5269)\tIOU 0.878 (0.914)\n",
      "Epoch: [26][140/200]\tLoss 0.4818 (0.5075)\tIOU 0.922 (0.917)\n",
      "Epoch: [26][160/200]\tLoss 0.6946 (0.5393)\tIOU 0.894 (0.910)\n",
      "Epoch: [26][180/200]\tLoss 0.5640 (0.4952)\tIOU 0.891 (0.925)\n",
      "Epoch: [26][Validation]\tVal_Loss: 1.27327\tVal_IOU: 0.82674\tBest Val_IOU: 0.83887\n",
      "epoch time:  107.1777811050415\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0047\n",
      "Epoch: [27][0/200]\tLoss 0.4350 (0.4350)\tIOU 0.931 (0.931)\n",
      "Epoch: [27][20/200]\tLoss 0.4034 (0.5016)\tIOU 0.931 (0.921)\n",
      "Epoch: [27][40/200]\tLoss 0.9927 (0.4642)\tIOU 0.838 (0.931)\n",
      "Epoch: [27][60/200]\tLoss 0.7147 (0.4967)\tIOU 0.887 (0.915)\n",
      "Epoch: [27][80/200]\tLoss 0.5056 (0.4686)\tIOU 0.934 (0.930)\n",
      "Epoch: [27][100/200]\tLoss 0.7295 (0.4913)\tIOU 0.884 (0.930)\n",
      "Epoch: [27][120/200]\tLoss 0.2223 (0.5344)\tIOU 0.978 (0.914)\n",
      "Epoch: [27][140/200]\tLoss 0.4398 (0.4933)\tIOU 0.922 (0.921)\n",
      "Epoch: [27][160/200]\tLoss 0.3045 (0.4486)\tIOU 0.975 (0.927)\n",
      "Epoch: [27][180/200]\tLoss 0.7487 (0.4518)\tIOU 0.881 (0.927)\n",
      "Epoch: [27][Validation]\tVal_Loss: 1.25675\tVal_IOU: 0.83721\tBest Val_IOU: 0.83887\n",
      "epoch time:  105.39345908164978\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0044\n",
      "Epoch: [28][0/200]\tLoss 0.5263 (0.5263)\tIOU 0.912 (0.912)\n",
      "Epoch: [28][20/200]\tLoss 0.7553 (0.5132)\tIOU 0.847 (0.910)\n",
      "Epoch: [28][40/200]\tLoss 0.5602 (0.5104)\tIOU 0.894 (0.917)\n",
      "Epoch: [28][60/200]\tLoss 0.6208 (0.5043)\tIOU 0.894 (0.924)\n",
      "Epoch: [28][80/200]\tLoss 0.5933 (0.4910)\tIOU 0.887 (0.920)\n",
      "Epoch: [28][100/200]\tLoss 0.4536 (0.5001)\tIOU 0.928 (0.913)\n",
      "Epoch: [28][120/200]\tLoss 0.2592 (0.4592)\tIOU 0.972 (0.921)\n",
      "Epoch: [28][140/200]\tLoss 0.5425 (0.4695)\tIOU 0.906 (0.924)\n",
      "Epoch: [28][160/200]\tLoss 0.3419 (0.4717)\tIOU 0.956 (0.927)\n",
      "Epoch: [28][180/200]\tLoss 0.2727 (0.4341)\tIOU 0.969 (0.932)\n",
      "Epoch: [28][Validation]\tVal_Loss: 1.29251\tVal_IOU: 0.82927\tBest Val_IOU: 0.83887\n",
      "epoch time:  105.35205554962158\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0041\n",
      "Epoch: [29][0/200]\tLoss 0.3269 (0.3269)\tIOU 0.953 (0.953)\n",
      "Epoch: [29][20/200]\tLoss 0.8173 (0.5036)\tIOU 0.869 (0.921)\n",
      "Epoch: [29][40/200]\tLoss 0.4130 (0.4056)\tIOU 0.938 (0.937)\n",
      "Epoch: [29][60/200]\tLoss 0.5170 (0.4636)\tIOU 0.922 (0.922)\n",
      "Epoch: [29][80/200]\tLoss 0.3859 (0.4414)\tIOU 0.938 (0.928)\n",
      "Epoch: [29][100/200]\tLoss 0.9738 (0.4526)\tIOU 0.866 (0.932)\n",
      "Epoch: [29][120/200]\tLoss 0.3668 (0.4746)\tIOU 0.969 (0.928)\n",
      "Epoch: [29][140/200]\tLoss 0.9963 (0.4588)\tIOU 0.844 (0.930)\n",
      "Epoch: [29][160/200]\tLoss 0.6307 (0.4352)\tIOU 0.909 (0.932)\n",
      "Epoch: [29][180/200]\tLoss 0.4415 (0.4933)\tIOU 0.925 (0.917)\n",
      "Epoch: [29][Validation]\tVal_Loss: 1.20618\tVal_IOU: 0.83778\tBest Val_IOU: 0.83887\n",
      "epoch time:  105.21043252944946\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0038\n",
      "Epoch: [30][0/200]\tLoss 0.7629 (0.7629)\tIOU 0.863 (0.863)\n",
      "Epoch: [30][20/200]\tLoss 0.3883 (0.4919)\tIOU 0.938 (0.919)\n",
      "Epoch: [30][40/200]\tLoss 0.5268 (0.4149)\tIOU 0.894 (0.934)\n",
      "Epoch: [30][60/200]\tLoss 0.6055 (0.4607)\tIOU 0.884 (0.924)\n",
      "Epoch: [30][80/200]\tLoss 0.4824 (0.4501)\tIOU 0.950 (0.931)\n",
      "Epoch: [30][100/200]\tLoss 0.6976 (0.4905)\tIOU 0.875 (0.920)\n",
      "Epoch: [30][120/200]\tLoss 0.7991 (0.5048)\tIOU 0.881 (0.916)\n",
      "Epoch: [30][140/200]\tLoss 0.4425 (0.4721)\tIOU 0.938 (0.928)\n",
      "Epoch: [30][160/200]\tLoss 0.5021 (0.4714)\tIOU 0.944 (0.922)\n",
      "Epoch: [30][180/200]\tLoss 0.6784 (0.4681)\tIOU 0.872 (0.924)\n",
      "Epoch: [30][Validation]\tVal_Loss: 1.20551\tVal_IOU: 0.84190\tBest Val_IOU: 0.84190\n",
      "epoch time:  106.74653840065002\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0036\n",
      "Epoch: [31][0/200]\tLoss 0.3931 (0.3931)\tIOU 0.938 (0.938)\n",
      "Epoch: [31][20/200]\tLoss 0.6032 (0.4099)\tIOU 0.922 (0.939)\n",
      "Epoch: [31][40/200]\tLoss 0.6147 (0.4684)\tIOU 0.872 (0.923)\n",
      "Epoch: [31][60/200]\tLoss 0.8484 (0.4727)\tIOU 0.853 (0.928)\n",
      "Epoch: [31][80/200]\tLoss 0.5330 (0.4994)\tIOU 0.887 (0.921)\n",
      "Epoch: [31][100/200]\tLoss 0.5077 (0.4395)\tIOU 0.916 (0.932)\n",
      "Epoch: [31][120/200]\tLoss 0.5197 (0.4984)\tIOU 0.897 (0.915)\n",
      "Epoch: [31][140/200]\tLoss 0.8468 (0.5640)\tIOU 0.863 (0.905)\n",
      "Epoch: [31][160/200]\tLoss 0.4757 (0.4522)\tIOU 0.906 (0.929)\n",
      "Epoch: [31][180/200]\tLoss 0.4423 (0.4555)\tIOU 0.919 (0.922)\n",
      "Epoch: [31][Validation]\tVal_Loss: 1.20370\tVal_IOU: 0.83745\tBest Val_IOU: 0.84190\n",
      "epoch time:  105.33512687683105\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0033\n",
      "Epoch: [32][0/200]\tLoss 0.2858 (0.2858)\tIOU 0.959 (0.959)\n",
      "Epoch: [32][20/200]\tLoss 0.3556 (0.4383)\tIOU 0.953 (0.930)\n",
      "Epoch: [32][40/200]\tLoss 0.2723 (0.3941)\tIOU 0.953 (0.938)\n",
      "Epoch: [32][60/200]\tLoss 0.7312 (0.4926)\tIOU 0.850 (0.918)\n",
      "Epoch: [32][80/200]\tLoss 0.3065 (0.4410)\tIOU 0.947 (0.932)\n",
      "Epoch: [32][100/200]\tLoss 0.4567 (0.4744)\tIOU 0.922 (0.918)\n",
      "Epoch: [32][120/200]\tLoss 0.4040 (0.4141)\tIOU 0.934 (0.934)\n",
      "Epoch: [32][140/200]\tLoss 0.4501 (0.4323)\tIOU 0.906 (0.931)\n",
      "Epoch: [32][160/200]\tLoss 0.9716 (0.4269)\tIOU 0.925 (0.938)\n",
      "Epoch: [32][180/200]\tLoss 0.8895 (0.4815)\tIOU 0.850 (0.923)\n",
      "Epoch: [32][Validation]\tVal_Loss: 1.12883\tVal_IOU: 0.84303\tBest Val_IOU: 0.84303\n",
      "epoch time:  107.18668961524963\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0031\n",
      "Epoch: [33][0/200]\tLoss 0.2369 (0.2369)\tIOU 0.972 (0.972)\n",
      "Epoch: [33][20/200]\tLoss 0.2087 (0.4244)\tIOU 0.984 (0.934)\n",
      "Epoch: [33][40/200]\tLoss 0.5463 (0.4518)\tIOU 0.875 (0.927)\n",
      "Epoch: [33][60/200]\tLoss 0.3468 (0.4216)\tIOU 0.947 (0.932)\n",
      "Epoch: [33][80/200]\tLoss 0.1947 (0.3954)\tIOU 0.978 (0.942)\n",
      "Epoch: [33][100/200]\tLoss 0.3949 (0.4377)\tIOU 0.941 (0.932)\n",
      "Epoch: [33][120/200]\tLoss 0.3416 (0.4590)\tIOU 0.956 (0.927)\n",
      "Epoch: [33][140/200]\tLoss 0.5234 (0.4416)\tIOU 0.887 (0.934)\n",
      "Epoch: [33][160/200]\tLoss 0.2972 (0.4517)\tIOU 0.953 (0.926)\n",
      "Epoch: [33][180/200]\tLoss 0.5621 (0.4325)\tIOU 0.903 (0.929)\n",
      "Epoch: [33][Validation]\tVal_Loss: 1.23312\tVal_IOU: 0.84093\tBest Val_IOU: 0.84303\n",
      "epoch time:  104.94317507743835\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0029\n",
      "Epoch: [34][0/200]\tLoss 0.6830 (0.6830)\tIOU 0.872 (0.872)\n",
      "Epoch: [34][20/200]\tLoss 0.3576 (0.4371)\tIOU 0.941 (0.931)\n",
      "Epoch: [34][40/200]\tLoss 0.2448 (0.4128)\tIOU 0.978 (0.934)\n",
      "Epoch: [34][60/200]\tLoss 0.4315 (0.4499)\tIOU 0.944 (0.935)\n",
      "Epoch: [34][80/200]\tLoss 0.5050 (0.4300)\tIOU 0.912 (0.933)\n",
      "Epoch: [34][100/200]\tLoss 0.1887 (0.3618)\tIOU 0.988 (0.944)\n",
      "Epoch: [34][120/200]\tLoss 0.1997 (0.4381)\tIOU 0.972 (0.928)\n",
      "Epoch: [34][140/200]\tLoss 0.3452 (0.5328)\tIOU 0.953 (0.911)\n",
      "Epoch: [34][160/200]\tLoss 0.5459 (0.4587)\tIOU 0.900 (0.925)\n",
      "Epoch: [34][180/200]\tLoss 0.6096 (0.4437)\tIOU 0.903 (0.936)\n",
      "Epoch: [34][Validation]\tVal_Loss: 1.18902\tVal_IOU: 0.84355\tBest Val_IOU: 0.84355\n",
      "epoch time:  106.92744708061218\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0026\n",
      "Epoch: [35][0/200]\tLoss 0.4806 (0.4806)\tIOU 0.941 (0.941)\n",
      "Epoch: [35][20/200]\tLoss 0.5759 (0.4026)\tIOU 0.916 (0.936)\n",
      "Epoch: [35][40/200]\tLoss 0.3025 (0.4386)\tIOU 0.959 (0.928)\n",
      "Epoch: [35][60/200]\tLoss 0.4966 (0.4018)\tIOU 0.916 (0.938)\n",
      "Epoch: [35][80/200]\tLoss 0.2136 (0.3989)\tIOU 0.984 (0.941)\n",
      "Epoch: [35][100/200]\tLoss 0.5513 (0.4290)\tIOU 0.894 (0.927)\n",
      "Epoch: [35][120/200]\tLoss 0.6565 (0.3963)\tIOU 0.887 (0.942)\n",
      "Epoch: [35][140/200]\tLoss 0.3046 (0.4201)\tIOU 0.950 (0.938)\n",
      "Epoch: [35][160/200]\tLoss 0.5038 (0.4521)\tIOU 0.909 (0.924)\n",
      "Epoch: [35][180/200]\tLoss 0.3304 (0.4301)\tIOU 0.959 (0.936)\n",
      "Epoch: [35][Validation]\tVal_Loss: 1.20701\tVal_IOU: 0.84210\tBest Val_IOU: 0.84355\n",
      "epoch time:  105.1487488746643\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0024\n",
      "Epoch: [36][0/200]\tLoss 0.3221 (0.3221)\tIOU 0.959 (0.959)\n",
      "Epoch: [36][20/200]\tLoss 0.3936 (0.4216)\tIOU 0.928 (0.932)\n",
      "Epoch: [36][40/200]\tLoss 0.2689 (0.3670)\tIOU 0.959 (0.942)\n",
      "Epoch: [36][60/200]\tLoss 0.4512 (0.4888)\tIOU 0.928 (0.915)\n",
      "Epoch: [36][80/200]\tLoss 0.5166 (0.4640)\tIOU 0.912 (0.920)\n",
      "Epoch: [36][100/200]\tLoss 0.4343 (0.4154)\tIOU 0.931 (0.938)\n",
      "Epoch: [36][120/200]\tLoss 0.6144 (0.4402)\tIOU 0.903 (0.925)\n",
      "Epoch: [36][140/200]\tLoss 0.4879 (0.4353)\tIOU 0.953 (0.935)\n",
      "Epoch: [36][160/200]\tLoss 0.4813 (0.4605)\tIOU 0.913 (0.927)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [36][180/200]\tLoss 0.1662 (0.4067)\tIOU 0.991 (0.939)\n",
      "Epoch: [36][Validation]\tVal_Loss: 1.28112\tVal_IOU: 0.83261\tBest Val_IOU: 0.84355\n",
      "epoch time:  104.251051902771\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0022\n",
      "Epoch: [37][0/200]\tLoss 0.3681 (0.3681)\tIOU 0.944 (0.944)\n",
      "Epoch: [37][20/200]\tLoss 0.4980 (0.3927)\tIOU 0.897 (0.944)\n",
      "Epoch: [37][40/200]\tLoss 0.5191 (0.3752)\tIOU 0.922 (0.942)\n",
      "Epoch: [37][60/200]\tLoss 0.3411 (0.4178)\tIOU 0.941 (0.933)\n",
      "Epoch: [37][80/200]\tLoss 0.3144 (0.4507)\tIOU 0.953 (0.924)\n",
      "Epoch: [37][100/200]\tLoss 0.4471 (0.3481)\tIOU 0.922 (0.950)\n",
      "Epoch: [37][120/200]\tLoss 0.3661 (0.4512)\tIOU 0.953 (0.928)\n",
      "Epoch: [37][140/200]\tLoss 0.2870 (0.4263)\tIOU 0.978 (0.935)\n",
      "Epoch: [37][160/200]\tLoss 0.2817 (0.3968)\tIOU 0.966 (0.940)\n",
      "Epoch: [37][180/200]\tLoss 0.4293 (0.4919)\tIOU 0.938 (0.920)\n",
      "Epoch: [37][Validation]\tVal_Loss: 1.17568\tVal_IOU: 0.83862\tBest Val_IOU: 0.84355\n",
      "epoch time:  105.38252830505371\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0020\n",
      "Epoch: [38][0/200]\tLoss 0.3168 (0.3168)\tIOU 0.950 (0.950)\n",
      "Epoch: [38][20/200]\tLoss 0.2902 (0.4161)\tIOU 0.975 (0.934)\n",
      "Epoch: [38][40/200]\tLoss 0.2358 (0.3754)\tIOU 0.978 (0.939)\n",
      "Epoch: [38][60/200]\tLoss 0.5372 (0.4207)\tIOU 0.916 (0.932)\n",
      "Epoch: [38][80/200]\tLoss 0.3621 (0.3902)\tIOU 0.944 (0.939)\n",
      "Epoch: [38][100/200]\tLoss 0.3599 (0.4469)\tIOU 0.944 (0.924)\n",
      "Epoch: [38][120/200]\tLoss 0.4025 (0.4124)\tIOU 0.925 (0.933)\n",
      "Epoch: [38][140/200]\tLoss 0.2151 (0.3379)\tIOU 0.984 (0.953)\n",
      "Epoch: [38][160/200]\tLoss 0.5480 (0.4471)\tIOU 0.922 (0.926)\n",
      "Epoch: [38][180/200]\tLoss 0.3315 (0.3713)\tIOU 0.944 (0.945)\n",
      "Epoch: [38][Validation]\tVal_Loss: 1.30830\tVal_IOU: 0.84202\tBest Val_IOU: 0.84355\n",
      "epoch time:  104.81154465675354\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0019\n",
      "Epoch: [39][0/200]\tLoss 0.4505 (0.4505)\tIOU 0.934 (0.934)\n",
      "Epoch: [39][20/200]\tLoss 0.3624 (0.3681)\tIOU 0.934 (0.949)\n",
      "Epoch: [39][40/200]\tLoss 0.1805 (0.3992)\tIOU 1.000 (0.936)\n",
      "Epoch: [39][60/200]\tLoss 0.4261 (0.4147)\tIOU 0.938 (0.935)\n",
      "Epoch: [39][80/200]\tLoss 0.6250 (0.4142)\tIOU 0.878 (0.941)\n",
      "Epoch: [39][100/200]\tLoss 0.3981 (0.4563)\tIOU 0.925 (0.927)\n",
      "Epoch: [39][120/200]\tLoss 0.3228 (0.4478)\tIOU 0.953 (0.923)\n",
      "Epoch: [39][140/200]\tLoss 0.5926 (0.4748)\tIOU 0.922 (0.922)\n",
      "Epoch: [39][160/200]\tLoss 0.2920 (0.4359)\tIOU 0.959 (0.931)\n",
      "Epoch: [39][180/200]\tLoss 0.1894 (0.3367)\tIOU 0.984 (0.952)\n",
      "Epoch: [39][Validation]\tVal_Loss: 1.28915\tVal_IOU: 0.84034\tBest Val_IOU: 0.84355\n",
      "epoch time:  104.46092557907104\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0017\n",
      "Epoch: [40][0/200]\tLoss 0.5554 (0.5554)\tIOU 0.894 (0.894)\n",
      "Epoch: [40][20/200]\tLoss 0.4061 (0.3598)\tIOU 0.928 (0.947)\n",
      "Epoch: [40][40/200]\tLoss 0.3507 (0.4226)\tIOU 0.944 (0.932)\n",
      "Epoch: [40][60/200]\tLoss 0.4377 (0.3823)\tIOU 0.928 (0.940)\n",
      "Epoch: [40][80/200]\tLoss 0.3813 (0.4268)\tIOU 0.966 (0.934)\n",
      "Epoch: [40][100/200]\tLoss 0.3141 (0.3804)\tIOU 0.950 (0.946)\n",
      "Epoch: [40][120/200]\tLoss 0.5942 (0.4245)\tIOU 0.884 (0.935)\n",
      "Epoch: [40][140/200]\tLoss 0.7642 (0.4084)\tIOU 0.838 (0.931)\n",
      "Epoch: [40][160/200]\tLoss 0.1665 (0.4077)\tIOU 0.991 (0.936)\n",
      "Epoch: [40][180/200]\tLoss 0.4155 (0.3976)\tIOU 0.934 (0.934)\n",
      "Epoch: [40][Validation]\tVal_Loss: 1.23671\tVal_IOU: 0.83841\tBest Val_IOU: 0.84355\n",
      "epoch time:  105.30084419250488\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0016\n",
      "Epoch: [41][0/200]\tLoss 0.4443 (0.4443)\tIOU 0.909 (0.909)\n",
      "Epoch: [41][20/200]\tLoss 0.1882 (0.3995)\tIOU 0.984 (0.938)\n",
      "Epoch: [41][40/200]\tLoss 0.1320 (0.3931)\tIOU 0.988 (0.936)\n",
      "Epoch: [41][60/200]\tLoss 0.3970 (0.4005)\tIOU 0.947 (0.936)\n",
      "Epoch: [41][80/200]\tLoss 0.5645 (0.4489)\tIOU 0.928 (0.927)\n",
      "Epoch: [41][100/200]\tLoss 0.4311 (0.4395)\tIOU 0.928 (0.931)\n",
      "Epoch: [41][120/200]\tLoss 0.2844 (0.3610)\tIOU 0.966 (0.943)\n",
      "Epoch: [41][140/200]\tLoss 0.2109 (0.4339)\tIOU 0.988 (0.926)\n",
      "Epoch: [41][160/200]\tLoss 0.3359 (0.3899)\tIOU 0.947 (0.938)\n",
      "Epoch: [41][180/200]\tLoss 0.5670 (0.4136)\tIOU 0.884 (0.934)\n",
      "Epoch: [41][Validation]\tVal_Loss: 1.26778\tVal_IOU: 0.83757\tBest Val_IOU: 0.84355\n",
      "epoch time:  105.55612397193909\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0014\n",
      "Epoch: [42][0/200]\tLoss 0.1501 (0.1501)\tIOU 0.991 (0.991)\n",
      "Epoch: [42][20/200]\tLoss 0.4117 (0.3910)\tIOU 0.934 (0.943)\n",
      "Epoch: [42][40/200]\tLoss 0.5509 (0.3950)\tIOU 0.894 (0.933)\n",
      "Epoch: [42][60/200]\tLoss 0.6519 (0.3947)\tIOU 0.862 (0.937)\n",
      "Epoch: [42][80/200]\tLoss 0.2453 (0.4394)\tIOU 0.969 (0.930)\n",
      "Epoch: [42][100/200]\tLoss 0.3685 (0.3636)\tIOU 0.950 (0.947)\n",
      "Epoch: [42][120/200]\tLoss 0.4373 (0.4132)\tIOU 0.928 (0.936)\n",
      "Epoch: [42][140/200]\tLoss 0.4686 (0.3745)\tIOU 0.941 (0.940)\n",
      "Epoch: [42][160/200]\tLoss 0.7011 (0.4072)\tIOU 0.853 (0.936)\n",
      "Epoch: [42][180/200]\tLoss 0.2512 (0.4416)\tIOU 0.969 (0.929)\n",
      "Epoch: [42][Validation]\tVal_Loss: 1.26032\tVal_IOU: 0.84297\tBest Val_IOU: 0.84355\n",
      "epoch time:  104.30392694473267\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0013\n",
      "Epoch: [43][0/200]\tLoss 0.6722 (0.6722)\tIOU 0.853 (0.853)\n",
      "Epoch: [43][20/200]\tLoss 0.4784 (0.3241)\tIOU 0.934 (0.953)\n",
      "Epoch: [43][40/200]\tLoss 0.3577 (0.3933)\tIOU 0.975 (0.939)\n",
      "Epoch: [43][60/200]\tLoss 0.5636 (0.3977)\tIOU 0.909 (0.940)\n",
      "Epoch: [43][80/200]\tLoss 0.4998 (0.3854)\tIOU 0.944 (0.939)\n",
      "Epoch: [43][100/200]\tLoss 0.3323 (0.4054)\tIOU 0.956 (0.938)\n",
      "Epoch: [43][120/200]\tLoss 0.5548 (0.4405)\tIOU 0.897 (0.929)\n",
      "Epoch: [43][140/200]\tLoss 0.3345 (0.3629)\tIOU 0.934 (0.943)\n",
      "Epoch: [43][160/200]\tLoss 0.3155 (0.4069)\tIOU 0.953 (0.935)\n",
      "Epoch: [43][180/200]\tLoss 0.4720 (0.3916)\tIOU 0.900 (0.935)\n",
      "Epoch: [43][Validation]\tVal_Loss: 1.26476\tVal_IOU: 0.83889\tBest Val_IOU: 0.84355\n",
      "epoch time:  105.59624123573303\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0012\n",
      "Epoch: [44][0/200]\tLoss 0.2637 (0.2637)\tIOU 0.969 (0.969)\n",
      "Epoch: [44][20/200]\tLoss 0.4634 (0.4219)\tIOU 0.925 (0.934)\n",
      "Epoch: [44][40/200]\tLoss 0.4290 (0.4310)\tIOU 0.925 (0.928)\n",
      "Epoch: [44][60/200]\tLoss 0.1698 (0.3800)\tIOU 0.981 (0.943)\n",
      "Epoch: [44][80/200]\tLoss 0.3386 (0.3847)\tIOU 0.953 (0.939)\n",
      "Epoch: [44][100/200]\tLoss 0.4358 (0.4161)\tIOU 0.925 (0.937)\n",
      "Epoch: [44][120/200]\tLoss 0.2808 (0.3784)\tIOU 0.963 (0.943)\n",
      "Epoch: [44][140/200]\tLoss 0.3732 (0.3702)\tIOU 0.956 (0.948)\n",
      "Epoch: [44][160/200]\tLoss 0.5924 (0.3531)\tIOU 0.884 (0.944)\n",
      "Epoch: [44][180/200]\tLoss 0.2027 (0.4243)\tIOU 0.978 (0.929)\n",
      "Epoch: [44][Validation]\tVal_Loss: 1.29752\tVal_IOU: 0.83997\tBest Val_IOU: 0.84355\n",
      "epoch time:  104.87701630592346\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0011\n",
      "Epoch: [45][0/200]\tLoss 0.5631 (0.5631)\tIOU 0.903 (0.903)\n",
      "Epoch: [45][20/200]\tLoss 0.3326 (0.4236)\tIOU 0.963 (0.935)\n",
      "Epoch: [45][40/200]\tLoss 0.3632 (0.3821)\tIOU 0.938 (0.944)\n",
      "Epoch: [45][60/200]\tLoss 0.3306 (0.3612)\tIOU 0.956 (0.945)\n",
      "Epoch: [45][80/200]\tLoss 0.4604 (0.4115)\tIOU 0.925 (0.932)\n",
      "Epoch: [45][100/200]\tLoss 0.1271 (0.3770)\tIOU 0.997 (0.943)\n",
      "Epoch: [45][120/200]\tLoss 0.3877 (0.3758)\tIOU 0.956 (0.944)\n",
      "Epoch: [45][140/200]\tLoss 0.6273 (0.4217)\tIOU 0.887 (0.930)\n",
      "Epoch: [45][160/200]\tLoss 0.3927 (0.4124)\tIOU 0.928 (0.936)\n",
      "Epoch: [45][180/200]\tLoss 0.3426 (0.3926)\tIOU 0.934 (0.936)\n",
      "Epoch: [45][Validation]\tVal_Loss: 1.28468\tVal_IOU: 0.84081\tBest Val_IOU: 0.84355\n",
      "epoch time:  104.99174404144287\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0011\n",
      "Epoch: [46][0/200]\tLoss 0.3250 (0.3250)\tIOU 0.953 (0.953)\n",
      "Epoch: [46][20/200]\tLoss 0.3930 (0.3980)\tIOU 0.938 (0.940)\n",
      "Epoch: [46][40/200]\tLoss 0.2930 (0.4205)\tIOU 0.953 (0.934)\n",
      "Epoch: [46][60/200]\tLoss 0.2481 (0.3641)\tIOU 0.962 (0.942)\n",
      "Epoch: [46][80/200]\tLoss 0.2984 (0.3857)\tIOU 0.950 (0.939)\n",
      "Epoch: [46][100/200]\tLoss 0.3699 (0.4216)\tIOU 0.941 (0.935)\n",
      "Epoch: [46][120/200]\tLoss 0.2552 (0.3860)\tIOU 0.963 (0.941)\n",
      "Epoch: [46][140/200]\tLoss 0.2361 (0.3956)\tIOU 0.975 (0.940)\n",
      "Epoch: [46][160/200]\tLoss 0.1503 (0.3604)\tIOU 0.991 (0.946)\n",
      "Epoch: [46][180/200]\tLoss 0.6133 (0.3562)\tIOU 0.928 (0.950)\n",
      "Epoch: [46][Validation]\tVal_Loss: 1.30614\tVal_IOU: 0.84105\tBest Val_IOU: 0.84355\n",
      "epoch time:  104.97525000572205\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0010\n",
      "Epoch: [47][0/200]\tLoss 0.3117 (0.3117)\tIOU 0.959 (0.959)\n",
      "Epoch: [47][20/200]\tLoss 0.4557 (0.4321)\tIOU 0.916 (0.933)\n",
      "Epoch: [47][40/200]\tLoss 0.2488 (0.3864)\tIOU 0.972 (0.940)\n",
      "Epoch: [47][60/200]\tLoss 0.3817 (0.3883)\tIOU 0.956 (0.946)\n",
      "Epoch: [47][80/200]\tLoss 0.3999 (0.3676)\tIOU 0.947 (0.945)\n",
      "Epoch: [47][100/200]\tLoss 0.6655 (0.3583)\tIOU 0.863 (0.942)\n",
      "Epoch: [47][120/200]\tLoss 0.3172 (0.3926)\tIOU 0.953 (0.944)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [47][140/200]\tLoss 0.2395 (0.3663)\tIOU 0.981 (0.943)\n",
      "Epoch: [47][160/200]\tLoss 0.4268 (0.3654)\tIOU 0.922 (0.944)\n",
      "Epoch: [47][180/200]\tLoss 0.1909 (0.3416)\tIOU 0.988 (0.950)\n",
      "Epoch: [47][Validation]\tVal_Loss: 1.28457\tVal_IOU: 0.84053\tBest Val_IOU: 0.84355\n",
      "epoch time:  105.60870933532715\n",
      "Fold/Cycle: [2/1]\t\n",
      "change learning rate into: 0.0010\n",
      "Epoch: [48][0/200]\tLoss 0.3075 (0.3075)\tIOU 0.969 (0.969)\n",
      "Epoch: [48][20/200]\tLoss 0.5832 (0.4262)\tIOU 0.906 (0.931)\n",
      "Epoch: [48][40/200]\tLoss 0.3655 (0.3626)\tIOU 0.975 (0.946)\n",
      "Epoch: [48][60/200]\tLoss 0.5616 (0.4041)\tIOU 0.925 (0.936)\n",
      "Epoch: [48][80/200]\tLoss 0.4397 (0.3793)\tIOU 0.906 (0.941)\n",
      "Epoch: [48][100/200]\tLoss 0.5538 (0.4023)\tIOU 0.906 (0.937)\n",
      "Epoch: [48][120/200]\tLoss 0.2522 (0.3998)\tIOU 0.972 (0.933)\n",
      "Epoch: [48][140/200]\tLoss 0.4256 (0.3606)\tIOU 0.922 (0.943)\n",
      "Epoch: [48][160/200]\tLoss 0.3574 (0.4317)\tIOU 0.963 (0.930)\n",
      "Epoch: [48][180/200]\tLoss 0.3996 (0.4273)\tIOU 0.931 (0.931)\n",
      "Epoch: [48][Validation]\tVal_Loss: 1.22066\tVal_IOU: 0.83957\tBest Val_IOU: 0.84355\n",
      "epoch time:  104.38622975349426\n",
      "Fold/Cycle: [2/1]\t\n",
      "restart at epoch 100\n",
      "change learning rate into: 0.0010\n",
      "Epoch: [49][0/200]\tLoss 0.2078 (0.2078)\tIOU 0.984 (0.984)\n",
      "Epoch: [49][20/200]\tLoss 0.3035 (0.4111)\tIOU 0.959 (0.938)\n",
      "Epoch: [49][40/200]\tLoss 0.5428 (0.4121)\tIOU 0.925 (0.935)\n",
      "Epoch: [49][60/200]\tLoss 0.6100 (0.4012)\tIOU 0.916 (0.938)\n",
      "Epoch: [49][80/200]\tLoss 0.3085 (0.3622)\tIOU 0.953 (0.947)\n",
      "Epoch: [49][100/200]\tLoss 0.5936 (0.4039)\tIOU 0.872 (0.931)\n",
      "Epoch: [49][120/200]\tLoss 0.3463 (0.3834)\tIOU 0.934 (0.937)\n",
      "Epoch: [49][140/200]\tLoss 0.2258 (0.3776)\tIOU 0.981 (0.944)\n",
      "Epoch: [49][160/200]\tLoss 0.3424 (0.3734)\tIOU 0.963 (0.944)\n",
      "Epoch: [49][180/200]\tLoss 0.4313 (0.4253)\tIOU 0.931 (0.931)\n",
      "Epoch: [49][Validation]\tVal_Loss: 1.25168\tVal_IOU: 0.84089\tBest Val_IOU: 0.84355\n",
      "epoch time:  104.86462354660034\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0100\n",
      "Epoch: [0][0/200]\tLoss 0.2456 (0.2456)\tIOU 0.963 (0.963)\n",
      "Epoch: [0][20/200]\tLoss 0.4146 (0.3904)\tIOU 0.925 (0.938)\n",
      "Epoch: [0][40/200]\tLoss 0.6680 (0.4492)\tIOU 0.919 (0.937)\n",
      "Epoch: [0][60/200]\tLoss 0.3567 (0.4448)\tIOU 0.959 (0.931)\n",
      "Epoch: [0][80/200]\tLoss 0.3186 (0.5157)\tIOU 0.969 (0.917)\n",
      "Epoch: [0][100/200]\tLoss 0.8829 (0.7295)\tIOU 0.853 (0.883)\n",
      "Epoch: [0][120/200]\tLoss 0.8891 (0.7418)\tIOU 0.844 (0.881)\n",
      "Epoch: [0][140/200]\tLoss 0.5417 (0.6587)\tIOU 0.913 (0.894)\n",
      "Epoch: [0][160/200]\tLoss 0.6774 (0.6502)\tIOU 0.897 (0.901)\n",
      "Epoch: [0][180/200]\tLoss 0.8466 (0.7017)\tIOU 0.859 (0.896)\n",
      "Epoch: [0][Validation]\tVal_Loss: 1.22569\tVal_IOU: 0.81435\tBest Val_IOU: 0.81435\n",
      "epoch time:  104.98366641998291\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0100\n",
      "Epoch: [1][0/200]\tLoss 0.5819 (0.5819)\tIOU 0.872 (0.872)\n",
      "Epoch: [1][20/200]\tLoss 1.4078 (0.6435)\tIOU 0.794 (0.896)\n",
      "Epoch: [1][40/200]\tLoss 0.8550 (0.7287)\tIOU 0.816 (0.873)\n",
      "Epoch: [1][60/200]\tLoss 0.4593 (0.7181)\tIOU 0.950 (0.879)\n",
      "Epoch: [1][80/200]\tLoss 0.8473 (0.7602)\tIOU 0.856 (0.872)\n",
      "Epoch: [1][100/200]\tLoss 0.8190 (0.7999)\tIOU 0.856 (0.865)\n",
      "Epoch: [1][120/200]\tLoss 0.4124 (0.6820)\tIOU 0.941 (0.894)\n",
      "Epoch: [1][140/200]\tLoss 0.4941 (0.7347)\tIOU 0.912 (0.880)\n",
      "Epoch: [1][160/200]\tLoss 0.4589 (0.7487)\tIOU 0.934 (0.883)\n",
      "Epoch: [1][180/200]\tLoss 0.8121 (0.8615)\tIOU 0.831 (0.853)\n",
      "Epoch: [1][Validation]\tVal_Loss: 1.34499\tVal_IOU: 0.80830\tBest Val_IOU: 0.81435\n",
      "epoch time:  107.76370358467102\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0099\n",
      "Epoch: [2][0/200]\tLoss 1.2902 (1.2902)\tIOU 0.781 (0.781)\n",
      "Epoch: [2][20/200]\tLoss 0.3782 (0.7629)\tIOU 0.962 (0.876)\n",
      "Epoch: [2][40/200]\tLoss 0.3755 (0.6451)\tIOU 0.950 (0.898)\n",
      "Epoch: [2][60/200]\tLoss 0.8106 (0.7207)\tIOU 0.850 (0.882)\n",
      "Epoch: [2][80/200]\tLoss 0.8349 (0.7100)\tIOU 0.866 (0.881)\n",
      "Epoch: [2][100/200]\tLoss 0.5249 (0.7554)\tIOU 0.938 (0.872)\n",
      "Epoch: [2][120/200]\tLoss 0.6911 (0.6839)\tIOU 0.856 (0.883)\n",
      "Epoch: [2][140/200]\tLoss 0.4639 (0.6417)\tIOU 0.931 (0.895)\n",
      "Epoch: [2][160/200]\tLoss 0.8274 (0.6334)\tIOU 0.866 (0.899)\n",
      "Epoch: [2][180/200]\tLoss 0.5882 (0.6521)\tIOU 0.909 (0.886)\n",
      "Epoch: [2][Validation]\tVal_Loss: 1.44457\tVal_IOU: 0.78864\tBest Val_IOU: 0.81435\n",
      "epoch time:  105.58224534988403\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0099\n",
      "Epoch: [3][0/200]\tLoss 0.7082 (0.7082)\tIOU 0.897 (0.897)\n",
      "Epoch: [3][20/200]\tLoss 0.9474 (0.6643)\tIOU 0.872 (0.890)\n",
      "Epoch: [3][40/200]\tLoss 0.3783 (0.6289)\tIOU 0.956 (0.898)\n",
      "Epoch: [3][60/200]\tLoss 0.3823 (0.6548)\tIOU 0.969 (0.896)\n",
      "Epoch: [3][80/200]\tLoss 0.6512 (0.6947)\tIOU 0.894 (0.886)\n",
      "Epoch: [3][100/200]\tLoss 0.6823 (0.6966)\tIOU 0.891 (0.892)\n",
      "Epoch: [3][120/200]\tLoss 0.5486 (0.7037)\tIOU 0.897 (0.889)\n",
      "Epoch: [3][140/200]\tLoss 0.5423 (0.6570)\tIOU 0.912 (0.895)\n",
      "Epoch: [3][160/200]\tLoss 0.6455 (0.7032)\tIOU 0.934 (0.890)\n",
      "Epoch: [3][180/200]\tLoss 0.8185 (0.6535)\tIOU 0.828 (0.887)\n",
      "Epoch: [3][Validation]\tVal_Loss: 1.28237\tVal_IOU: 0.80940\tBest Val_IOU: 0.81435\n",
      "epoch time:  104.78402161598206\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0098\n",
      "Epoch: [4][0/200]\tLoss 0.4866 (0.4866)\tIOU 0.909 (0.909)\n",
      "Epoch: [4][20/200]\tLoss 0.7668 (0.6177)\tIOU 0.853 (0.898)\n",
      "Epoch: [4][40/200]\tLoss 0.4026 (0.6909)\tIOU 0.938 (0.885)\n",
      "Epoch: [4][60/200]\tLoss 1.0020 (0.6160)\tIOU 0.837 (0.898)\n",
      "Epoch: [4][80/200]\tLoss 0.6486 (0.6690)\tIOU 0.897 (0.888)\n",
      "Epoch: [4][100/200]\tLoss 0.3197 (0.5655)\tIOU 0.963 (0.912)\n",
      "Epoch: [4][120/200]\tLoss 1.2287 (0.6293)\tIOU 0.753 (0.897)\n",
      "Epoch: [4][140/200]\tLoss 0.7738 (0.6603)\tIOU 0.875 (0.894)\n",
      "Epoch: [4][160/200]\tLoss 0.4958 (0.5321)\tIOU 0.925 (0.915)\n",
      "Epoch: [4][180/200]\tLoss 0.8188 (0.6359)\tIOU 0.834 (0.899)\n",
      "Epoch: [4][Validation]\tVal_Loss: 1.35730\tVal_IOU: 0.82584\tBest Val_IOU: 0.82584\n",
      "epoch time:  108.49816012382507\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0097\n",
      "Epoch: [5][0/200]\tLoss 0.9362 (0.9362)\tIOU 0.850 (0.850)\n",
      "Epoch: [5][20/200]\tLoss 0.6336 (0.5842)\tIOU 0.916 (0.908)\n",
      "Epoch: [5][40/200]\tLoss 0.4297 (0.6284)\tIOU 0.934 (0.898)\n",
      "Epoch: [5][60/200]\tLoss 0.3927 (0.5846)\tIOU 0.947 (0.907)\n",
      "Epoch: [5][80/200]\tLoss 0.6776 (0.6575)\tIOU 0.884 (0.896)\n",
      "Epoch: [5][100/200]\tLoss 1.0102 (0.6910)\tIOU 0.838 (0.890)\n",
      "Epoch: [5][120/200]\tLoss 0.4443 (0.7499)\tIOU 0.953 (0.884)\n",
      "Epoch: [5][140/200]\tLoss 0.7415 (0.6846)\tIOU 0.863 (0.898)\n",
      "Epoch: [5][160/200]\tLoss 0.6727 (0.6255)\tIOU 0.869 (0.899)\n",
      "Epoch: [5][180/200]\tLoss 0.5215 (0.6615)\tIOU 0.931 (0.902)\n",
      "Epoch: [5][Validation]\tVal_Loss: 1.35928\tVal_IOU: 0.82149\tBest Val_IOU: 0.82584\n",
      "epoch time:  104.68625783920288\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0096\n",
      "Epoch: [6][0/200]\tLoss 0.3465 (0.3465)\tIOU 0.956 (0.956)\n",
      "Epoch: [6][20/200]\tLoss 0.6446 (0.5057)\tIOU 0.878 (0.921)\n",
      "Epoch: [6][40/200]\tLoss 1.0483 (0.6809)\tIOU 0.872 (0.893)\n",
      "Epoch: [6][60/200]\tLoss 0.3709 (0.5715)\tIOU 0.950 (0.910)\n",
      "Epoch: [6][80/200]\tLoss 0.7968 (0.5634)\tIOU 0.875 (0.917)\n",
      "Epoch: [6][100/200]\tLoss 0.8314 (0.6632)\tIOU 0.841 (0.898)\n",
      "Epoch: [6][120/200]\tLoss 0.6922 (0.6385)\tIOU 0.891 (0.899)\n",
      "Epoch: [6][140/200]\tLoss 0.5457 (0.6099)\tIOU 0.938 (0.901)\n",
      "Epoch: [6][160/200]\tLoss 0.7323 (0.5650)\tIOU 0.875 (0.910)\n",
      "Epoch: [6][180/200]\tLoss 0.4553 (0.6761)\tIOU 0.913 (0.889)\n",
      "Epoch: [6][Validation]\tVal_Loss: 1.27601\tVal_IOU: 0.82703\tBest Val_IOU: 0.82703\n",
      "epoch time:  106.6732120513916\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0094\n",
      "Epoch: [7][0/200]\tLoss 0.3924 (0.3924)\tIOU 0.956 (0.956)\n",
      "Epoch: [7][20/200]\tLoss 0.4813 (0.6369)\tIOU 0.916 (0.891)\n",
      "Epoch: [7][40/200]\tLoss 0.5506 (0.6282)\tIOU 0.891 (0.898)\n",
      "Epoch: [7][60/200]\tLoss 0.4674 (0.6022)\tIOU 0.919 (0.903)\n",
      "Epoch: [7][80/200]\tLoss 0.5142 (0.6100)\tIOU 0.928 (0.908)\n",
      "Epoch: [7][100/200]\tLoss 0.5834 (0.5561)\tIOU 0.906 (0.914)\n",
      "Epoch: [7][120/200]\tLoss 0.5501 (0.6800)\tIOU 0.894 (0.895)\n",
      "Epoch: [7][140/200]\tLoss 0.4771 (0.6268)\tIOU 0.934 (0.903)\n",
      "Epoch: [7][160/200]\tLoss 0.5734 (0.5948)\tIOU 0.900 (0.901)\n",
      "Epoch: [7][180/200]\tLoss 0.7395 (0.5969)\tIOU 0.878 (0.909)\n",
      "Epoch: [7][Validation]\tVal_Loss: 1.21678\tVal_IOU: 0.81033\tBest Val_IOU: 0.82703\n",
      "epoch time:  104.5525586605072\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0093\n",
      "Epoch: [8][0/200]\tLoss 0.5266 (0.5266)\tIOU 0.922 (0.922)\n",
      "Epoch: [8][20/200]\tLoss 0.7411 (0.6404)\tIOU 0.866 (0.902)\n",
      "Epoch: [8][40/200]\tLoss 0.5473 (0.6365)\tIOU 0.919 (0.896)\n",
      "Epoch: [8][60/200]\tLoss 0.8656 (0.5561)\tIOU 0.859 (0.911)\n",
      "Epoch: [8][80/200]\tLoss 0.6606 (0.5827)\tIOU 0.856 (0.908)\n",
      "Epoch: [8][100/200]\tLoss 0.6976 (0.6250)\tIOU 0.856 (0.892)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][120/200]\tLoss 0.4679 (0.6631)\tIOU 0.931 (0.888)\n",
      "Epoch: [8][140/200]\tLoss 0.7244 (0.6836)\tIOU 0.862 (0.886)\n",
      "Epoch: [8][160/200]\tLoss 0.7548 (0.5964)\tIOU 0.906 (0.904)\n",
      "Epoch: [8][180/200]\tLoss 0.2446 (0.6138)\tIOU 0.972 (0.895)\n",
      "Epoch: [8][Validation]\tVal_Loss: 1.30779\tVal_IOU: 0.81891\tBest Val_IOU: 0.82703\n",
      "epoch time:  104.83252453804016\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0091\n",
      "Epoch: [9][0/200]\tLoss 0.3375 (0.3375)\tIOU 0.944 (0.944)\n",
      "Epoch: [9][20/200]\tLoss 0.6794 (0.6074)\tIOU 0.891 (0.909)\n",
      "Epoch: [9][40/200]\tLoss 0.2313 (0.6478)\tIOU 0.975 (0.898)\n",
      "Epoch: [9][60/200]\tLoss 0.8272 (0.5956)\tIOU 0.909 (0.906)\n",
      "Epoch: [9][80/200]\tLoss 0.6440 (0.5754)\tIOU 0.894 (0.907)\n",
      "Epoch: [9][100/200]\tLoss 0.6413 (0.6061)\tIOU 0.881 (0.898)\n",
      "Epoch: [9][120/200]\tLoss 0.5226 (0.6754)\tIOU 0.953 (0.890)\n",
      "Epoch: [9][140/200]\tLoss 0.4812 (0.6434)\tIOU 0.944 (0.905)\n",
      "Epoch: [9][160/200]\tLoss 0.9160 (0.6201)\tIOU 0.828 (0.898)\n",
      "Epoch: [9][180/200]\tLoss 0.6005 (0.6533)\tIOU 0.931 (0.903)\n",
      "Epoch: [9][Validation]\tVal_Loss: 1.34210\tVal_IOU: 0.82579\tBest Val_IOU: 0.82703\n",
      "epoch time:  104.84021258354187\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0090\n",
      "Epoch: [10][0/200]\tLoss 0.6726 (0.6726)\tIOU 0.853 (0.853)\n",
      "Epoch: [10][20/200]\tLoss 0.6612 (0.5654)\tIOU 0.897 (0.904)\n",
      "Epoch: [10][40/200]\tLoss 0.3688 (0.6116)\tIOU 0.947 (0.899)\n",
      "Epoch: [10][60/200]\tLoss 0.5692 (0.6020)\tIOU 0.897 (0.905)\n",
      "Epoch: [10][80/200]\tLoss 0.4371 (0.5729)\tIOU 0.938 (0.912)\n",
      "Epoch: [10][100/200]\tLoss 0.4467 (0.6305)\tIOU 0.947 (0.901)\n",
      "Epoch: [10][120/200]\tLoss 0.6842 (0.5079)\tIOU 0.900 (0.925)\n",
      "Epoch: [10][140/200]\tLoss 0.3604 (0.5153)\tIOU 0.938 (0.916)\n",
      "Epoch: [10][160/200]\tLoss 0.4788 (0.5503)\tIOU 0.919 (0.921)\n",
      "Epoch: [10][180/200]\tLoss 0.2493 (0.6267)\tIOU 0.972 (0.892)\n",
      "Epoch: [10][Validation]\tVal_Loss: 1.30432\tVal_IOU: 0.80981\tBest Val_IOU: 0.82703\n",
      "epoch time:  105.37577486038208\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0088\n",
      "Epoch: [11][0/200]\tLoss 0.6429 (0.6429)\tIOU 0.888 (0.888)\n",
      "Epoch: [11][20/200]\tLoss 0.7288 (0.5500)\tIOU 0.894 (0.910)\n",
      "Epoch: [11][40/200]\tLoss 0.7855 (0.5048)\tIOU 0.850 (0.919)\n",
      "Epoch: [11][60/200]\tLoss 0.5186 (0.5397)\tIOU 0.894 (0.906)\n",
      "Epoch: [11][80/200]\tLoss 0.4326 (0.5776)\tIOU 0.934 (0.909)\n",
      "Epoch: [11][100/200]\tLoss 0.5194 (0.6027)\tIOU 0.931 (0.907)\n",
      "Epoch: [11][120/200]\tLoss 0.4589 (0.5368)\tIOU 0.934 (0.916)\n",
      "Epoch: [11][140/200]\tLoss 0.6479 (0.6218)\tIOU 0.869 (0.895)\n",
      "Epoch: [11][160/200]\tLoss 0.3260 (0.4869)\tIOU 0.959 (0.931)\n",
      "Epoch: [11][180/200]\tLoss 0.4270 (0.6593)\tIOU 0.934 (0.892)\n",
      "Epoch: [11][Validation]\tVal_Loss: 1.23697\tVal_IOU: 0.82504\tBest Val_IOU: 0.82703\n",
      "epoch time:  105.03360414505005\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0086\n",
      "Epoch: [12][0/200]\tLoss 0.4301 (0.4301)\tIOU 0.934 (0.934)\n",
      "Epoch: [12][20/200]\tLoss 0.3044 (0.4680)\tIOU 0.972 (0.934)\n",
      "Epoch: [12][40/200]\tLoss 0.6165 (0.5591)\tIOU 0.919 (0.908)\n",
      "Epoch: [12][60/200]\tLoss 0.3216 (0.5306)\tIOU 0.947 (0.911)\n",
      "Epoch: [12][80/200]\tLoss 0.4328 (0.5776)\tIOU 0.925 (0.901)\n",
      "Epoch: [12][100/200]\tLoss 0.5648 (0.5609)\tIOU 0.897 (0.907)\n",
      "Epoch: [12][120/200]\tLoss 0.4121 (0.5850)\tIOU 0.941 (0.899)\n",
      "Epoch: [12][140/200]\tLoss 0.7683 (0.5423)\tIOU 0.897 (0.915)\n",
      "Epoch: [12][160/200]\tLoss 0.4227 (0.5633)\tIOU 0.928 (0.914)\n",
      "Epoch: [12][180/200]\tLoss 0.6176 (0.5452)\tIOU 0.881 (0.914)\n",
      "Epoch: [12][Validation]\tVal_Loss: 1.34564\tVal_IOU: 0.83105\tBest Val_IOU: 0.83105\n",
      "epoch time:  106.46366453170776\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0084\n",
      "Epoch: [13][0/200]\tLoss 0.6815 (0.6815)\tIOU 0.897 (0.897)\n",
      "Epoch: [13][20/200]\tLoss 0.3721 (0.5637)\tIOU 0.963 (0.906)\n",
      "Epoch: [13][40/200]\tLoss 0.5481 (0.5055)\tIOU 0.938 (0.917)\n",
      "Epoch: [13][60/200]\tLoss 0.3577 (0.5425)\tIOU 0.953 (0.913)\n",
      "Epoch: [13][80/200]\tLoss 0.5289 (0.4689)\tIOU 0.900 (0.925)\n",
      "Epoch: [13][100/200]\tLoss 0.2722 (0.4337)\tIOU 0.969 (0.933)\n",
      "Epoch: [13][120/200]\tLoss 0.4904 (0.4825)\tIOU 0.919 (0.919)\n",
      "Epoch: [13][140/200]\tLoss 0.6523 (0.5399)\tIOU 0.897 (0.912)\n",
      "Epoch: [13][160/200]\tLoss 0.4680 (0.5318)\tIOU 0.925 (0.911)\n",
      "Epoch: [13][180/200]\tLoss 0.4848 (0.5564)\tIOU 0.928 (0.910)\n",
      "Epoch: [13][Validation]\tVal_Loss: 1.39940\tVal_IOU: 0.79924\tBest Val_IOU: 0.83105\n",
      "epoch time:  105.55884742736816\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0081\n",
      "Epoch: [14][0/200]\tLoss 0.7087 (0.7087)\tIOU 0.841 (0.841)\n",
      "Epoch: [14][20/200]\tLoss 0.8914 (0.6295)\tIOU 0.856 (0.894)\n",
      "Epoch: [14][40/200]\tLoss 0.3787 (0.5555)\tIOU 0.944 (0.911)\n",
      "Epoch: [14][60/200]\tLoss 0.4206 (0.5868)\tIOU 0.956 (0.910)\n",
      "Epoch: [14][80/200]\tLoss 0.2801 (0.5529)\tIOU 0.966 (0.905)\n",
      "Epoch: [14][100/200]\tLoss 0.8242 (0.5231)\tIOU 0.834 (0.921)\n",
      "Epoch: [14][120/200]\tLoss 0.2323 (0.5564)\tIOU 0.972 (0.913)\n",
      "Epoch: [14][140/200]\tLoss 0.4079 (0.4845)\tIOU 0.922 (0.926)\n",
      "Epoch: [14][160/200]\tLoss 0.4048 (0.5587)\tIOU 0.959 (0.913)\n",
      "Epoch: [14][180/200]\tLoss 0.3938 (0.5626)\tIOU 0.941 (0.908)\n",
      "Epoch: [14][Validation]\tVal_Loss: 1.24431\tVal_IOU: 0.81968\tBest Val_IOU: 0.83105\n",
      "epoch time:  104.76088190078735\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0079\n",
      "Epoch: [15][0/200]\tLoss 0.4971 (0.4971)\tIOU 0.894 (0.894)\n",
      "Epoch: [15][20/200]\tLoss 0.4400 (0.4832)\tIOU 0.916 (0.915)\n",
      "Epoch: [15][40/200]\tLoss 0.4487 (0.5312)\tIOU 0.925 (0.912)\n",
      "Epoch: [15][60/200]\tLoss 0.5641 (0.4936)\tIOU 0.919 (0.923)\n",
      "Epoch: [15][80/200]\tLoss 0.5535 (0.4852)\tIOU 0.900 (0.923)\n",
      "Epoch: [15][100/200]\tLoss 0.8409 (0.4932)\tIOU 0.825 (0.924)\n",
      "Epoch: [15][120/200]\tLoss 0.8121 (0.5325)\tIOU 0.862 (0.915)\n",
      "Epoch: [15][140/200]\tLoss 0.4253 (0.5962)\tIOU 0.922 (0.903)\n",
      "Epoch: [15][160/200]\tLoss 0.4268 (0.5850)\tIOU 0.925 (0.904)\n",
      "Epoch: [15][180/200]\tLoss 0.7086 (0.5064)\tIOU 0.897 (0.915)\n",
      "Epoch: [15][Validation]\tVal_Loss: 1.42861\tVal_IOU: 0.82308\tBest Val_IOU: 0.83105\n",
      "epoch time:  105.27301669120789\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0077\n",
      "Epoch: [16][0/200]\tLoss 0.9920 (0.9920)\tIOU 0.828 (0.828)\n",
      "Epoch: [16][20/200]\tLoss 0.3569 (0.5199)\tIOU 0.934 (0.914)\n",
      "Epoch: [16][40/200]\tLoss 0.9538 (0.5690)\tIOU 0.856 (0.911)\n",
      "Epoch: [16][60/200]\tLoss 0.3476 (0.4358)\tIOU 0.950 (0.931)\n",
      "Epoch: [16][80/200]\tLoss 0.8547 (0.5544)\tIOU 0.825 (0.911)\n",
      "Epoch: [16][100/200]\tLoss 0.6656 (0.4753)\tIOU 0.912 (0.925)\n",
      "Epoch: [16][120/200]\tLoss 0.1691 (0.4536)\tIOU 0.994 (0.927)\n",
      "Epoch: [16][140/200]\tLoss 0.5744 (0.5045)\tIOU 0.903 (0.920)\n",
      "Epoch: [16][160/200]\tLoss 0.2016 (0.4293)\tIOU 0.978 (0.931)\n",
      "Epoch: [16][180/200]\tLoss 0.5338 (0.5396)\tIOU 0.912 (0.909)\n",
      "Epoch: [16][Validation]\tVal_Loss: 1.35114\tVal_IOU: 0.81485\tBest Val_IOU: 0.83105\n",
      "epoch time:  103.86009001731873\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0074\n",
      "Epoch: [17][0/200]\tLoss 0.4514 (0.4514)\tIOU 0.912 (0.912)\n",
      "Epoch: [17][20/200]\tLoss 0.3727 (0.5077)\tIOU 0.950 (0.921)\n",
      "Epoch: [17][40/200]\tLoss 0.7968 (0.5192)\tIOU 0.853 (0.910)\n",
      "Epoch: [17][60/200]\tLoss 0.4491 (0.5097)\tIOU 0.916 (0.915)\n",
      "Epoch: [17][80/200]\tLoss 0.5969 (0.4996)\tIOU 0.931 (0.921)\n",
      "Epoch: [17][100/200]\tLoss 0.4371 (0.5000)\tIOU 0.922 (0.923)\n",
      "Epoch: [17][120/200]\tLoss 0.6249 (0.5471)\tIOU 0.891 (0.914)\n",
      "Epoch: [17][140/200]\tLoss 0.2211 (0.5176)\tIOU 0.975 (0.922)\n",
      "Epoch: [17][160/200]\tLoss 0.2431 (0.4858)\tIOU 0.981 (0.926)\n",
      "Epoch: [17][180/200]\tLoss 0.5693 (0.5736)\tIOU 0.912 (0.910)\n",
      "Epoch: [17][Validation]\tVal_Loss: 1.31096\tVal_IOU: 0.83251\tBest Val_IOU: 0.83251\n",
      "epoch time:  106.90830731391907\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0072\n",
      "Epoch: [18][0/200]\tLoss 0.3580 (0.3580)\tIOU 0.963 (0.963)\n",
      "Epoch: [18][20/200]\tLoss 0.7829 (0.5465)\tIOU 0.878 (0.910)\n",
      "Epoch: [18][40/200]\tLoss 0.3457 (0.4755)\tIOU 0.950 (0.934)\n",
      "Epoch: [18][60/200]\tLoss 0.4038 (0.5178)\tIOU 0.966 (0.915)\n",
      "Epoch: [18][80/200]\tLoss 0.3804 (0.5169)\tIOU 0.941 (0.915)\n",
      "Epoch: [18][100/200]\tLoss 0.4417 (0.4934)\tIOU 0.925 (0.918)\n",
      "Epoch: [18][120/200]\tLoss 0.8009 (0.5744)\tIOU 0.863 (0.905)\n",
      "Epoch: [18][140/200]\tLoss 0.4069 (0.4949)\tIOU 0.938 (0.921)\n",
      "Epoch: [18][160/200]\tLoss 0.4546 (0.4890)\tIOU 0.934 (0.925)\n",
      "Epoch: [18][180/200]\tLoss 0.6212 (0.5170)\tIOU 0.887 (0.921)\n",
      "Epoch: [18][Validation]\tVal_Loss: 1.30500\tVal_IOU: 0.84643\tBest Val_IOU: 0.84643\n",
      "epoch time:  107.2046549320221\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0069\n",
      "Epoch: [19][0/200]\tLoss 0.4863 (0.4863)\tIOU 0.912 (0.912)\n",
      "Epoch: [19][20/200]\tLoss 0.5613 (0.4678)\tIOU 0.900 (0.926)\n",
      "Epoch: [19][40/200]\tLoss 0.2515 (0.4570)\tIOU 0.962 (0.929)\n",
      "Epoch: [19][60/200]\tLoss 0.5634 (0.4477)\tIOU 0.894 (0.933)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [19][80/200]\tLoss 0.6999 (0.4720)\tIOU 0.841 (0.919)\n",
      "Epoch: [19][100/200]\tLoss 0.7435 (0.5960)\tIOU 0.875 (0.904)\n",
      "Epoch: [19][120/200]\tLoss 0.6779 (0.6024)\tIOU 0.884 (0.899)\n",
      "Epoch: [19][140/200]\tLoss 0.2971 (0.4556)\tIOU 0.975 (0.930)\n",
      "Epoch: [19][160/200]\tLoss 0.4111 (0.4310)\tIOU 0.944 (0.937)\n",
      "Epoch: [19][180/200]\tLoss 0.4696 (0.4908)\tIOU 0.906 (0.912)\n",
      "Epoch: [19][Validation]\tVal_Loss: 1.29087\tVal_IOU: 0.84127\tBest Val_IOU: 0.84643\n",
      "epoch time:  105.40113043785095\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0066\n",
      "Epoch: [20][0/200]\tLoss 0.4941 (0.4941)\tIOU 0.912 (0.912)\n",
      "Epoch: [20][20/200]\tLoss 0.4428 (0.4579)\tIOU 0.928 (0.925)\n",
      "Epoch: [20][40/200]\tLoss 0.4272 (0.4785)\tIOU 0.938 (0.918)\n",
      "Epoch: [20][60/200]\tLoss 0.3872 (0.4966)\tIOU 0.947 (0.925)\n",
      "Epoch: [20][80/200]\tLoss 0.6058 (0.5130)\tIOU 0.872 (0.912)\n",
      "Epoch: [20][100/200]\tLoss 0.8734 (0.4211)\tIOU 0.872 (0.937)\n",
      "Epoch: [20][120/200]\tLoss 0.7349 (0.4611)\tIOU 0.869 (0.928)\n",
      "Epoch: [20][140/200]\tLoss 0.6281 (0.5068)\tIOU 0.897 (0.919)\n",
      "Epoch: [20][160/200]\tLoss 0.3147 (0.4751)\tIOU 0.966 (0.925)\n",
      "Epoch: [20][180/200]\tLoss 0.7335 (0.4849)\tIOU 0.850 (0.920)\n",
      "Epoch: [20][Validation]\tVal_Loss: 1.39856\tVal_IOU: 0.83001\tBest Val_IOU: 0.84643\n",
      "epoch time:  104.84228873252869\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0063\n",
      "Epoch: [21][0/200]\tLoss 0.6586 (0.6586)\tIOU 0.912 (0.912)\n",
      "Epoch: [21][20/200]\tLoss 0.2563 (0.3993)\tIOU 0.975 (0.944)\n",
      "Epoch: [21][40/200]\tLoss 0.2839 (0.4304)\tIOU 0.962 (0.933)\n",
      "Epoch: [21][60/200]\tLoss 0.3993 (0.4183)\tIOU 0.966 (0.935)\n",
      "Epoch: [21][80/200]\tLoss 0.4323 (0.4478)\tIOU 0.928 (0.927)\n",
      "Epoch: [21][100/200]\tLoss 0.6871 (0.4857)\tIOU 0.900 (0.921)\n",
      "Epoch: [21][120/200]\tLoss 0.2956 (0.4478)\tIOU 0.975 (0.928)\n",
      "Epoch: [21][140/200]\tLoss 0.4885 (0.4864)\tIOU 0.912 (0.922)\n",
      "Epoch: [21][160/200]\tLoss 0.5022 (0.4931)\tIOU 0.928 (0.922)\n",
      "Epoch: [21][180/200]\tLoss 0.2523 (0.4738)\tIOU 0.969 (0.923)\n",
      "Epoch: [21][Validation]\tVal_Loss: 1.40138\tVal_IOU: 0.83465\tBest Val_IOU: 0.84643\n",
      "epoch time:  104.89692687988281\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0061\n",
      "Epoch: [22][0/200]\tLoss 0.4718 (0.4718)\tIOU 0.928 (0.928)\n",
      "Epoch: [22][20/200]\tLoss 0.4520 (0.4258)\tIOU 0.922 (0.936)\n",
      "Epoch: [22][40/200]\tLoss 0.3575 (0.4596)\tIOU 0.938 (0.929)\n",
      "Epoch: [22][60/200]\tLoss 0.5278 (0.4721)\tIOU 0.922 (0.925)\n",
      "Epoch: [22][80/200]\tLoss 0.2922 (0.4527)\tIOU 0.969 (0.927)\n",
      "Epoch: [22][100/200]\tLoss 0.3412 (0.4625)\tIOU 0.944 (0.922)\n",
      "Epoch: [22][120/200]\tLoss 0.2982 (0.3955)\tIOU 0.962 (0.944)\n",
      "Epoch: [22][140/200]\tLoss 0.5282 (0.4878)\tIOU 0.925 (0.922)\n",
      "Epoch: [22][160/200]\tLoss 0.3821 (0.4729)\tIOU 0.934 (0.921)\n",
      "Epoch: [22][180/200]\tLoss 0.6187 (0.4494)\tIOU 0.903 (0.930)\n",
      "Epoch: [22][Validation]\tVal_Loss: 1.37536\tVal_IOU: 0.82900\tBest Val_IOU: 0.84643\n",
      "epoch time:  104.89008021354675\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0058\n",
      "Epoch: [23][0/200]\tLoss 0.4677 (0.4677)\tIOU 0.922 (0.922)\n",
      "Epoch: [23][20/200]\tLoss 0.4679 (0.4965)\tIOU 0.928 (0.923)\n",
      "Epoch: [23][40/200]\tLoss 0.2559 (0.4292)\tIOU 0.984 (0.932)\n",
      "Epoch: [23][60/200]\tLoss 0.4697 (0.4377)\tIOU 0.922 (0.929)\n",
      "Epoch: [23][80/200]\tLoss 0.5241 (0.4558)\tIOU 0.925 (0.927)\n",
      "Epoch: [23][100/200]\tLoss 0.4814 (0.3922)\tIOU 0.909 (0.938)\n",
      "Epoch: [23][120/200]\tLoss 0.5285 (0.4623)\tIOU 0.881 (0.923)\n",
      "Epoch: [23][140/200]\tLoss 0.3162 (0.4131)\tIOU 0.978 (0.940)\n",
      "Epoch: [23][160/200]\tLoss 0.5120 (0.4127)\tIOU 0.909 (0.931)\n",
      "Epoch: [23][180/200]\tLoss 0.3810 (0.4543)\tIOU 0.938 (0.926)\n",
      "Epoch: [23][Validation]\tVal_Loss: 1.37740\tVal_IOU: 0.82222\tBest Val_IOU: 0.84643\n",
      "epoch time:  105.67551946640015\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0055\n",
      "Epoch: [24][0/200]\tLoss 0.5108 (0.5108)\tIOU 0.912 (0.912)\n",
      "Epoch: [24][20/200]\tLoss 0.3368 (0.4658)\tIOU 0.950 (0.928)\n",
      "Epoch: [24][40/200]\tLoss 0.2675 (0.5115)\tIOU 0.950 (0.916)\n",
      "Epoch: [24][60/200]\tLoss 0.4168 (0.4090)\tIOU 0.919 (0.943)\n",
      "Epoch: [24][80/200]\tLoss 0.4249 (0.4513)\tIOU 0.947 (0.928)\n",
      "Epoch: [24][100/200]\tLoss 0.6509 (0.3949)\tIOU 0.850 (0.937)\n",
      "Epoch: [24][120/200]\tLoss 0.4257 (0.5039)\tIOU 0.931 (0.922)\n",
      "Epoch: [24][140/200]\tLoss 0.5154 (0.4523)\tIOU 0.906 (0.929)\n",
      "Epoch: [24][160/200]\tLoss 0.7976 (0.4301)\tIOU 0.841 (0.935)\n",
      "Epoch: [24][180/200]\tLoss 0.3740 (0.4583)\tIOU 0.928 (0.927)\n",
      "Epoch: [24][Validation]\tVal_Loss: 1.24453\tVal_IOU: 0.84037\tBest Val_IOU: 0.84643\n",
      "epoch time:  104.7512366771698\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0052\n",
      "Epoch: [25][0/200]\tLoss 0.4244 (0.4244)\tIOU 0.903 (0.903)\n",
      "Epoch: [25][20/200]\tLoss 0.3592 (0.3385)\tIOU 0.956 (0.953)\n",
      "Epoch: [25][40/200]\tLoss 0.4214 (0.3955)\tIOU 0.931 (0.940)\n",
      "Epoch: [25][60/200]\tLoss 0.5162 (0.4337)\tIOU 0.903 (0.934)\n",
      "Epoch: [25][80/200]\tLoss 0.2151 (0.4198)\tIOU 0.975 (0.934)\n",
      "Epoch: [25][100/200]\tLoss 0.7131 (0.4815)\tIOU 0.841 (0.919)\n",
      "Epoch: [25][120/200]\tLoss 0.4239 (0.4216)\tIOU 0.963 (0.935)\n",
      "Epoch: [25][140/200]\tLoss 0.4680 (0.4017)\tIOU 0.913 (0.937)\n",
      "Epoch: [25][160/200]\tLoss 0.7101 (0.4654)\tIOU 0.869 (0.926)\n",
      "Epoch: [25][180/200]\tLoss 0.2484 (0.3571)\tIOU 0.972 (0.944)\n",
      "Epoch: [25][Validation]\tVal_Loss: 1.31755\tVal_IOU: 0.83678\tBest Val_IOU: 0.84643\n",
      "epoch time:  105.39469313621521\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0049\n",
      "Epoch: [26][0/200]\tLoss 0.6442 (0.6442)\tIOU 0.919 (0.919)\n",
      "Epoch: [26][20/200]\tLoss 0.4719 (0.4102)\tIOU 0.947 (0.938)\n",
      "Epoch: [26][40/200]\tLoss 0.3848 (0.4402)\tIOU 0.950 (0.926)\n",
      "Epoch: [26][60/200]\tLoss 0.2366 (0.4527)\tIOU 0.972 (0.927)\n",
      "Epoch: [26][80/200]\tLoss 0.2153 (0.3790)\tIOU 0.972 (0.938)\n",
      "Epoch: [26][100/200]\tLoss 0.3764 (0.4197)\tIOU 0.938 (0.935)\n",
      "Epoch: [26][120/200]\tLoss 0.3447 (0.4259)\tIOU 0.947 (0.937)\n",
      "Epoch: [26][140/200]\tLoss 0.2999 (0.3724)\tIOU 0.956 (0.946)\n",
      "Epoch: [26][160/200]\tLoss 0.4266 (0.4563)\tIOU 0.947 (0.927)\n",
      "Epoch: [26][180/200]\tLoss 0.4745 (0.4579)\tIOU 0.916 (0.922)\n",
      "Epoch: [26][Validation]\tVal_Loss: 1.45178\tVal_IOU: 0.83561\tBest Val_IOU: 0.84643\n",
      "epoch time:  105.45536351203918\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0047\n",
      "Epoch: [27][0/200]\tLoss 0.3359 (0.3359)\tIOU 0.959 (0.959)\n",
      "Epoch: [27][20/200]\tLoss 0.3839 (0.3504)\tIOU 0.928 (0.950)\n",
      "Epoch: [27][40/200]\tLoss 0.5921 (0.4340)\tIOU 0.906 (0.923)\n",
      "Epoch: [27][60/200]\tLoss 0.4503 (0.4400)\tIOU 0.928 (0.933)\n",
      "Epoch: [27][80/200]\tLoss 0.2939 (0.3632)\tIOU 0.953 (0.946)\n",
      "Epoch: [27][100/200]\tLoss 0.3928 (0.3494)\tIOU 0.925 (0.949)\n",
      "Epoch: [27][120/200]\tLoss 0.4006 (0.4142)\tIOU 0.928 (0.938)\n",
      "Epoch: [27][140/200]\tLoss 0.3965 (0.4105)\tIOU 0.956 (0.936)\n",
      "Epoch: [27][160/200]\tLoss 0.4219 (0.4296)\tIOU 0.938 (0.935)\n",
      "Epoch: [27][180/200]\tLoss 0.3974 (0.4154)\tIOU 0.934 (0.934)\n",
      "Epoch: [27][Validation]\tVal_Loss: 1.34199\tVal_IOU: 0.83898\tBest Val_IOU: 0.84643\n",
      "epoch time:  104.412522315979\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0044\n",
      "Epoch: [28][0/200]\tLoss 0.3816 (0.3816)\tIOU 0.953 (0.953)\n",
      "Epoch: [28][20/200]\tLoss 0.4996 (0.4535)\tIOU 0.916 (0.931)\n",
      "Epoch: [28][40/200]\tLoss 0.6202 (0.3866)\tIOU 0.884 (0.940)\n",
      "Epoch: [28][60/200]\tLoss 0.2402 (0.4414)\tIOU 0.962 (0.933)\n",
      "Epoch: [28][80/200]\tLoss 0.2561 (0.3836)\tIOU 0.972 (0.941)\n",
      "Epoch: [28][100/200]\tLoss 0.2727 (0.3995)\tIOU 0.972 (0.937)\n",
      "Epoch: [28][120/200]\tLoss 0.2279 (0.3585)\tIOU 0.966 (0.946)\n",
      "Epoch: [28][140/200]\tLoss 0.3452 (0.3892)\tIOU 0.934 (0.935)\n",
      "Epoch: [28][160/200]\tLoss 0.2687 (0.3990)\tIOU 0.956 (0.936)\n",
      "Epoch: [28][180/200]\tLoss 0.2583 (0.4601)\tIOU 0.975 (0.922)\n",
      "Epoch: [28][Validation]\tVal_Loss: 1.41106\tVal_IOU: 0.82799\tBest Val_IOU: 0.84643\n",
      "epoch time:  105.03819227218628\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0041\n",
      "Epoch: [29][0/200]\tLoss 0.3333 (0.3333)\tIOU 0.944 (0.944)\n",
      "Epoch: [29][20/200]\tLoss 0.2414 (0.3708)\tIOU 0.963 (0.944)\n",
      "Epoch: [29][40/200]\tLoss 0.1979 (0.3923)\tIOU 0.984 (0.938)\n",
      "Epoch: [29][60/200]\tLoss 0.3291 (0.3898)\tIOU 0.953 (0.938)\n",
      "Epoch: [29][80/200]\tLoss 0.3925 (0.5307)\tIOU 0.962 (0.916)\n",
      "Epoch: [29][100/200]\tLoss 0.3420 (0.4187)\tIOU 0.962 (0.933)\n",
      "Epoch: [29][120/200]\tLoss 0.6390 (0.4442)\tIOU 0.872 (0.933)\n",
      "Epoch: [29][140/200]\tLoss 0.3858 (0.3585)\tIOU 0.934 (0.945)\n",
      "Epoch: [29][160/200]\tLoss 0.1306 (0.3519)\tIOU 0.994 (0.949)\n",
      "Epoch: [29][180/200]\tLoss 0.5060 (0.3890)\tIOU 0.919 (0.938)\n",
      "Epoch: [29][Validation]\tVal_Loss: 1.35729\tVal_IOU: 0.84162\tBest Val_IOU: 0.84643\n",
      "epoch time:  104.75341153144836\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0038\n",
      "Epoch: [30][0/200]\tLoss 0.6283 (0.6283)\tIOU 0.869 (0.869)\n",
      "Epoch: [30][20/200]\tLoss 0.3685 (0.4495)\tIOU 0.950 (0.926)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [30][40/200]\tLoss 0.5556 (0.4423)\tIOU 0.887 (0.926)\n",
      "Epoch: [30][60/200]\tLoss 0.4312 (0.4208)\tIOU 0.928 (0.933)\n",
      "Epoch: [30][80/200]\tLoss 0.3377 (0.4015)\tIOU 0.963 (0.935)\n",
      "Epoch: [30][100/200]\tLoss 0.2338 (0.3731)\tIOU 0.978 (0.944)\n",
      "Epoch: [30][120/200]\tLoss 0.3686 (0.3791)\tIOU 0.931 (0.949)\n",
      "Epoch: [30][140/200]\tLoss 0.3506 (0.3750)\tIOU 0.941 (0.940)\n",
      "Epoch: [30][160/200]\tLoss 0.2400 (0.4237)\tIOU 0.975 (0.931)\n",
      "Epoch: [30][180/200]\tLoss 0.3611 (0.4244)\tIOU 0.947 (0.932)\n",
      "Epoch: [30][Validation]\tVal_Loss: 1.28826\tVal_IOU: 0.83105\tBest Val_IOU: 0.84643\n",
      "epoch time:  105.33398056030273\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0036\n",
      "Epoch: [31][0/200]\tLoss 0.2906 (0.2906)\tIOU 0.988 (0.988)\n",
      "Epoch: [31][20/200]\tLoss 0.4510 (0.4072)\tIOU 0.909 (0.936)\n",
      "Epoch: [31][40/200]\tLoss 0.4531 (0.4219)\tIOU 0.956 (0.932)\n",
      "Epoch: [31][60/200]\tLoss 0.5311 (0.4144)\tIOU 0.925 (0.938)\n",
      "Epoch: [31][80/200]\tLoss 0.1813 (0.3682)\tIOU 0.991 (0.946)\n",
      "Epoch: [31][100/200]\tLoss 0.5479 (0.4088)\tIOU 0.903 (0.932)\n",
      "Epoch: [31][120/200]\tLoss 0.3139 (0.3599)\tIOU 0.959 (0.946)\n",
      "Epoch: [31][140/200]\tLoss 0.2397 (0.4144)\tIOU 0.966 (0.935)\n",
      "Epoch: [31][160/200]\tLoss 0.3478 (0.3937)\tIOU 0.931 (0.943)\n",
      "Epoch: [31][180/200]\tLoss 0.2827 (0.3720)\tIOU 0.953 (0.943)\n",
      "Epoch: [31][Validation]\tVal_Loss: 1.33988\tVal_IOU: 0.83240\tBest Val_IOU: 0.84643\n",
      "epoch time:  105.8224983215332\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0033\n",
      "Epoch: [32][0/200]\tLoss 0.3746 (0.3746)\tIOU 0.947 (0.947)\n",
      "Epoch: [32][20/200]\tLoss 0.5585 (0.4011)\tIOU 0.891 (0.937)\n",
      "Epoch: [32][40/200]\tLoss 0.3942 (0.4636)\tIOU 0.941 (0.922)\n",
      "Epoch: [32][60/200]\tLoss 0.4954 (0.3606)\tIOU 0.909 (0.941)\n",
      "Epoch: [32][80/200]\tLoss 0.2891 (0.3277)\tIOU 0.956 (0.956)\n",
      "Epoch: [32][100/200]\tLoss 0.4025 (0.4295)\tIOU 0.931 (0.931)\n",
      "Epoch: [32][120/200]\tLoss 0.2207 (0.4306)\tIOU 0.978 (0.927)\n",
      "Epoch: [32][140/200]\tLoss 0.3107 (0.4019)\tIOU 0.956 (0.937)\n",
      "Epoch: [32][160/200]\tLoss 0.3198 (0.3913)\tIOU 0.966 (0.940)\n",
      "Epoch: [32][180/200]\tLoss 0.4584 (0.3751)\tIOU 0.912 (0.948)\n",
      "Epoch: [32][Validation]\tVal_Loss: 1.30582\tVal_IOU: 0.83969\tBest Val_IOU: 0.84643\n",
      "epoch time:  104.62493014335632\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0031\n",
      "Epoch: [33][0/200]\tLoss 0.4080 (0.4080)\tIOU 0.919 (0.919)\n",
      "Epoch: [33][20/200]\tLoss 0.2265 (0.4456)\tIOU 0.988 (0.929)\n",
      "Epoch: [33][40/200]\tLoss 0.4278 (0.3800)\tIOU 0.919 (0.939)\n",
      "Epoch: [33][60/200]\tLoss 0.1634 (0.3628)\tIOU 0.988 (0.948)\n",
      "Epoch: [33][80/200]\tLoss 0.2505 (0.3205)\tIOU 0.966 (0.954)\n",
      "Epoch: [33][100/200]\tLoss 0.2966 (0.3860)\tIOU 0.959 (0.944)\n",
      "Epoch: [33][120/200]\tLoss 0.4856 (0.3933)\tIOU 0.931 (0.940)\n",
      "Epoch: [33][140/200]\tLoss 0.2587 (0.3966)\tIOU 0.962 (0.940)\n",
      "Epoch: [33][160/200]\tLoss 0.2704 (0.3742)\tIOU 0.969 (0.940)\n",
      "Epoch: [33][180/200]\tLoss 0.3437 (0.3416)\tIOU 0.966 (0.951)\n",
      "Epoch: [33][Validation]\tVal_Loss: 1.30815\tVal_IOU: 0.83892\tBest Val_IOU: 0.84643\n",
      "epoch time:  104.57643294334412\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0029\n",
      "Epoch: [34][0/200]\tLoss 0.4293 (0.4293)\tIOU 0.922 (0.922)\n",
      "Epoch: [34][20/200]\tLoss 0.5455 (0.4481)\tIOU 0.903 (0.930)\n",
      "Epoch: [34][40/200]\tLoss 0.4304 (0.3833)\tIOU 0.928 (0.937)\n",
      "Epoch: [34][60/200]\tLoss 0.3531 (0.4386)\tIOU 0.934 (0.927)\n",
      "Epoch: [34][80/200]\tLoss 0.5074 (0.3611)\tIOU 0.925 (0.950)\n",
      "Epoch: [34][100/200]\tLoss 0.3667 (0.3408)\tIOU 0.947 (0.950)\n",
      "Epoch: [34][120/200]\tLoss 0.1849 (0.3821)\tIOU 0.994 (0.937)\n",
      "Epoch: [34][140/200]\tLoss 0.1705 (0.3642)\tIOU 0.991 (0.948)\n",
      "Epoch: [34][160/200]\tLoss 0.1661 (0.4009)\tIOU 0.984 (0.933)\n",
      "Epoch: [34][180/200]\tLoss 0.1941 (0.3579)\tIOU 0.984 (0.947)\n",
      "Epoch: [34][Validation]\tVal_Loss: 1.32627\tVal_IOU: 0.83718\tBest Val_IOU: 0.84643\n",
      "epoch time:  104.50301933288574\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0026\n",
      "Epoch: [35][0/200]\tLoss 0.1413 (0.1413)\tIOU 0.994 (0.994)\n",
      "Epoch: [35][20/200]\tLoss 0.3831 (0.3990)\tIOU 0.950 (0.939)\n",
      "Epoch: [35][40/200]\tLoss 0.4310 (0.3512)\tIOU 0.953 (0.947)\n",
      "Epoch: [35][60/200]\tLoss 0.3000 (0.3479)\tIOU 0.953 (0.947)\n",
      "Epoch: [35][80/200]\tLoss 0.3277 (0.3829)\tIOU 0.969 (0.939)\n",
      "Epoch: [35][100/200]\tLoss 0.6220 (0.4279)\tIOU 0.897 (0.932)\n",
      "Epoch: [35][120/200]\tLoss 0.3689 (0.4286)\tIOU 0.947 (0.924)\n",
      "Epoch: [35][140/200]\tLoss 0.2592 (0.3591)\tIOU 0.972 (0.950)\n",
      "Epoch: [35][160/200]\tLoss 0.4493 (0.3455)\tIOU 0.922 (0.952)\n",
      "Epoch: [35][180/200]\tLoss 0.2572 (0.3724)\tIOU 0.959 (0.939)\n",
      "Epoch: [35][Validation]\tVal_Loss: 1.36086\tVal_IOU: 0.83875\tBest Val_IOU: 0.84643\n",
      "epoch time:  104.17887616157532\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0024\n",
      "Epoch: [36][0/200]\tLoss 0.3765 (0.3765)\tIOU 0.938 (0.938)\n",
      "Epoch: [36][20/200]\tLoss 0.5183 (0.3957)\tIOU 0.931 (0.938)\n",
      "Epoch: [36][40/200]\tLoss 0.4086 (0.3766)\tIOU 0.934 (0.940)\n",
      "Epoch: [36][60/200]\tLoss 0.4602 (0.3353)\tIOU 0.928 (0.948)\n",
      "Epoch: [36][80/200]\tLoss 0.4551 (0.3689)\tIOU 0.912 (0.944)\n",
      "Epoch: [36][100/200]\tLoss 0.2474 (0.3555)\tIOU 0.963 (0.947)\n",
      "Epoch: [36][120/200]\tLoss 0.3347 (0.4082)\tIOU 0.947 (0.932)\n",
      "Epoch: [36][140/200]\tLoss 0.3251 (0.2905)\tIOU 0.975 (0.961)\n",
      "Epoch: [36][160/200]\tLoss 0.3693 (0.3854)\tIOU 0.975 (0.939)\n",
      "Epoch: [36][180/200]\tLoss 0.5749 (0.3208)\tIOU 0.909 (0.954)\n",
      "Epoch: [36][Validation]\tVal_Loss: 1.41840\tVal_IOU: 0.83358\tBest Val_IOU: 0.84643\n",
      "epoch time:  105.56880617141724\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0022\n",
      "Epoch: [37][0/200]\tLoss 0.1896 (0.1896)\tIOU 0.981 (0.981)\n",
      "Epoch: [37][20/200]\tLoss 0.2475 (0.3485)\tIOU 0.956 (0.948)\n",
      "Epoch: [37][40/200]\tLoss 0.1325 (0.3228)\tIOU 0.994 (0.950)\n",
      "Epoch: [37][60/200]\tLoss 0.1409 (0.3717)\tIOU 0.994 (0.942)\n",
      "Epoch: [37][80/200]\tLoss 0.1789 (0.3386)\tIOU 0.984 (0.951)\n",
      "Epoch: [37][100/200]\tLoss 0.5872 (0.3548)\tIOU 0.881 (0.945)\n",
      "Epoch: [37][120/200]\tLoss 0.5572 (0.3785)\tIOU 0.875 (0.938)\n",
      "Epoch: [37][140/200]\tLoss 0.1577 (0.3886)\tIOU 0.991 (0.938)\n",
      "Epoch: [37][160/200]\tLoss 0.1696 (0.3653)\tIOU 0.981 (0.945)\n",
      "Epoch: [37][180/200]\tLoss 0.3037 (0.3795)\tIOU 0.947 (0.939)\n",
      "Epoch: [37][Validation]\tVal_Loss: 1.37185\tVal_IOU: 0.83647\tBest Val_IOU: 0.84643\n",
      "epoch time:  104.20693445205688\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0020\n",
      "Epoch: [38][0/200]\tLoss 0.3088 (0.3088)\tIOU 0.944 (0.944)\n",
      "Epoch: [38][20/200]\tLoss 0.5672 (0.3895)\tIOU 0.941 (0.942)\n",
      "Epoch: [38][40/200]\tLoss 0.2531 (0.3872)\tIOU 0.972 (0.941)\n",
      "Epoch: [38][60/200]\tLoss 0.2153 (0.4014)\tIOU 0.975 (0.934)\n",
      "Epoch: [38][80/200]\tLoss 0.2536 (0.3257)\tIOU 0.959 (0.946)\n",
      "Epoch: [38][100/200]\tLoss 0.3281 (0.3801)\tIOU 0.963 (0.943)\n",
      "Epoch: [38][120/200]\tLoss 0.3598 (0.3669)\tIOU 0.950 (0.943)\n",
      "Epoch: [38][140/200]\tLoss 0.3850 (0.3311)\tIOU 0.934 (0.953)\n",
      "Epoch: [38][160/200]\tLoss 0.2062 (0.3587)\tIOU 0.981 (0.946)\n",
      "Epoch: [38][180/200]\tLoss 0.3178 (0.3198)\tIOU 0.947 (0.955)\n",
      "Epoch: [38][Validation]\tVal_Loss: 1.38992\tVal_IOU: 0.84498\tBest Val_IOU: 0.84643\n",
      "epoch time:  105.59156084060669\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0019\n",
      "Epoch: [39][0/200]\tLoss 0.3617 (0.3617)\tIOU 0.966 (0.966)\n",
      "Epoch: [39][20/200]\tLoss 0.4671 (0.3657)\tIOU 0.909 (0.944)\n",
      "Epoch: [39][40/200]\tLoss 0.2337 (0.3507)\tIOU 0.972 (0.947)\n",
      "Epoch: [39][60/200]\tLoss 0.5561 (0.3751)\tIOU 0.897 (0.944)\n",
      "Epoch: [39][80/200]\tLoss 0.5242 (0.3060)\tIOU 0.912 (0.954)\n",
      "Epoch: [39][100/200]\tLoss 0.4336 (0.3748)\tIOU 0.928 (0.942)\n",
      "Epoch: [39][120/200]\tLoss 0.1812 (0.3445)\tIOU 0.981 (0.944)\n",
      "Epoch: [39][140/200]\tLoss 0.5322 (0.3759)\tIOU 0.903 (0.940)\n",
      "Epoch: [39][160/200]\tLoss 0.1424 (0.3346)\tIOU 0.991 (0.946)\n",
      "Epoch: [39][180/200]\tLoss 0.5842 (0.3718)\tIOU 0.928 (0.945)\n",
      "Epoch: [39][Validation]\tVal_Loss: 1.33473\tVal_IOU: 0.84439\tBest Val_IOU: 0.84643\n",
      "epoch time:  104.41940593719482\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0017\n",
      "Epoch: [40][0/200]\tLoss 0.2314 (0.2314)\tIOU 0.978 (0.978)\n",
      "Epoch: [40][20/200]\tLoss 0.3158 (0.3466)\tIOU 0.941 (0.951)\n",
      "Epoch: [40][40/200]\tLoss 0.2905 (0.4102)\tIOU 0.950 (0.935)\n",
      "Epoch: [40][60/200]\tLoss 0.2502 (0.3216)\tIOU 0.972 (0.956)\n",
      "Epoch: [40][80/200]\tLoss 0.5222 (0.3556)\tIOU 0.941 (0.950)\n",
      "Epoch: [40][100/200]\tLoss 0.4866 (0.3507)\tIOU 0.931 (0.947)\n",
      "Epoch: [40][120/200]\tLoss 0.3836 (0.3940)\tIOU 0.928 (0.937)\n",
      "Epoch: [40][140/200]\tLoss 0.3345 (0.3657)\tIOU 0.953 (0.946)\n",
      "Epoch: [40][160/200]\tLoss 0.3252 (0.3462)\tIOU 0.944 (0.949)\n",
      "Epoch: [40][180/200]\tLoss 0.4682 (0.3610)\tIOU 0.903 (0.942)\n",
      "Epoch: [40][Validation]\tVal_Loss: 1.35096\tVal_IOU: 0.84041\tBest Val_IOU: 0.84643\n",
      "epoch time:  105.53331303596497\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [41][0/200]\tLoss 0.3551 (0.3551)\tIOU 0.947 (0.947)\n",
      "Epoch: [41][20/200]\tLoss 0.2737 (0.3884)\tIOU 0.966 (0.944)\n",
      "Epoch: [41][40/200]\tLoss 0.3844 (0.3492)\tIOU 0.947 (0.947)\n",
      "Epoch: [41][60/200]\tLoss 0.2436 (0.3916)\tIOU 0.984 (0.941)\n",
      "Epoch: [41][80/200]\tLoss 0.4766 (0.3141)\tIOU 0.903 (0.958)\n",
      "Epoch: [41][100/200]\tLoss 0.2601 (0.3670)\tIOU 0.963 (0.945)\n",
      "Epoch: [41][120/200]\tLoss 0.2136 (0.3119)\tIOU 0.969 (0.958)\n",
      "Epoch: [41][140/200]\tLoss 0.1937 (0.3577)\tIOU 0.984 (0.945)\n",
      "Epoch: [41][160/200]\tLoss 0.3431 (0.3833)\tIOU 0.928 (0.938)\n",
      "Epoch: [41][180/200]\tLoss 0.1363 (0.3227)\tIOU 0.997 (0.953)\n",
      "Epoch: [41][Validation]\tVal_Loss: 1.32865\tVal_IOU: 0.84089\tBest Val_IOU: 0.84643\n",
      "epoch time:  105.47443318367004\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0014\n",
      "Epoch: [42][0/200]\tLoss 0.2233 (0.2233)\tIOU 0.978 (0.978)\n",
      "Epoch: [42][20/200]\tLoss 0.6786 (0.4025)\tIOU 0.903 (0.931)\n",
      "Epoch: [42][40/200]\tLoss 0.3103 (0.3380)\tIOU 0.972 (0.951)\n",
      "Epoch: [42][60/200]\tLoss 0.4507 (0.3284)\tIOU 0.944 (0.951)\n",
      "Epoch: [42][80/200]\tLoss 0.4411 (0.3588)\tIOU 0.928 (0.946)\n",
      "Epoch: [42][100/200]\tLoss 0.2923 (0.3615)\tIOU 0.944 (0.943)\n",
      "Epoch: [42][120/200]\tLoss 0.2051 (0.3434)\tIOU 0.981 (0.947)\n",
      "Epoch: [42][140/200]\tLoss 0.3283 (0.3370)\tIOU 0.956 (0.954)\n",
      "Epoch: [42][160/200]\tLoss 0.4407 (0.3518)\tIOU 0.925 (0.951)\n",
      "Epoch: [42][180/200]\tLoss 0.4836 (0.3661)\tIOU 0.916 (0.940)\n",
      "Epoch: [42][Validation]\tVal_Loss: 1.32780\tVal_IOU: 0.83945\tBest Val_IOU: 0.84643\n",
      "epoch time:  105.6509416103363\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0013\n",
      "Epoch: [43][0/200]\tLoss 0.3463 (0.3463)\tIOU 0.944 (0.944)\n",
      "Epoch: [43][20/200]\tLoss 0.4308 (0.3451)\tIOU 0.916 (0.944)\n",
      "Epoch: [43][40/200]\tLoss 0.4741 (0.3928)\tIOU 0.947 (0.938)\n",
      "Epoch: [43][60/200]\tLoss 0.2430 (0.3310)\tIOU 0.975 (0.956)\n",
      "Epoch: [43][80/200]\tLoss 0.4620 (0.3642)\tIOU 0.944 (0.940)\n",
      "Epoch: [43][100/200]\tLoss 0.2235 (0.3791)\tIOU 0.969 (0.938)\n",
      "Epoch: [43][120/200]\tLoss 0.4217 (0.3549)\tIOU 0.938 (0.943)\n",
      "Epoch: [43][140/200]\tLoss 0.2884 (0.3452)\tIOU 0.966 (0.950)\n",
      "Epoch: [43][160/200]\tLoss 0.4460 (0.3507)\tIOU 0.931 (0.944)\n",
      "Epoch: [43][180/200]\tLoss 0.5105 (0.3473)\tIOU 0.925 (0.947)\n",
      "Epoch: [43][Validation]\tVal_Loss: 1.36712\tVal_IOU: 0.84403\tBest Val_IOU: 0.84643\n",
      "epoch time:  104.98153901100159\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0012\n",
      "Epoch: [44][0/200]\tLoss 0.3806 (0.3806)\tIOU 0.938 (0.938)\n",
      "Epoch: [44][20/200]\tLoss 0.5631 (0.3372)\tIOU 0.894 (0.946)\n",
      "Epoch: [44][40/200]\tLoss 0.3775 (0.3819)\tIOU 0.916 (0.940)\n",
      "Epoch: [44][60/200]\tLoss 0.3995 (0.3571)\tIOU 0.931 (0.942)\n",
      "Epoch: [44][80/200]\tLoss 0.4328 (0.3640)\tIOU 0.953 (0.943)\n",
      "Epoch: [44][100/200]\tLoss 0.2832 (0.3393)\tIOU 0.959 (0.950)\n",
      "Epoch: [44][120/200]\tLoss 0.6716 (0.3784)\tIOU 0.853 (0.940)\n",
      "Epoch: [44][140/200]\tLoss 0.1835 (0.2857)\tIOU 0.984 (0.960)\n",
      "Epoch: [44][160/200]\tLoss 0.2694 (0.3241)\tIOU 0.991 (0.950)\n",
      "Epoch: [44][180/200]\tLoss 0.4600 (0.3351)\tIOU 0.934 (0.950)\n",
      "Epoch: [44][Validation]\tVal_Loss: 1.35467\tVal_IOU: 0.83670\tBest Val_IOU: 0.84643\n",
      "epoch time:  104.43057131767273\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0011\n",
      "Epoch: [45][0/200]\tLoss 0.3947 (0.3947)\tIOU 0.925 (0.925)\n",
      "Epoch: [45][20/200]\tLoss 0.3790 (0.3511)\tIOU 0.944 (0.948)\n",
      "Epoch: [45][40/200]\tLoss 0.5360 (0.3049)\tIOU 0.925 (0.958)\n",
      "Epoch: [45][60/200]\tLoss 0.3909 (0.3592)\tIOU 0.934 (0.943)\n",
      "Epoch: [45][80/200]\tLoss 0.2576 (0.3402)\tIOU 0.978 (0.949)\n",
      "Epoch: [45][100/200]\tLoss 0.5204 (0.3392)\tIOU 0.916 (0.948)\n",
      "Epoch: [45][120/200]\tLoss 0.3043 (0.3842)\tIOU 0.953 (0.935)\n",
      "Epoch: [45][140/200]\tLoss 0.3383 (0.3608)\tIOU 0.947 (0.945)\n",
      "Epoch: [45][160/200]\tLoss 0.3264 (0.3430)\tIOU 0.966 (0.948)\n",
      "Epoch: [45][180/200]\tLoss 0.3919 (0.3284)\tIOU 0.928 (0.950)\n",
      "Epoch: [45][Validation]\tVal_Loss: 1.41268\tVal_IOU: 0.83742\tBest Val_IOU: 0.84643\n",
      "epoch time:  104.92409157752991\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0011\n",
      "Epoch: [46][0/200]\tLoss 0.2749 (0.2749)\tIOU 0.956 (0.956)\n",
      "Epoch: [46][20/200]\tLoss 0.4431 (0.3385)\tIOU 0.922 (0.946)\n",
      "Epoch: [46][40/200]\tLoss 0.3798 (0.3612)\tIOU 0.941 (0.948)\n",
      "Epoch: [46][60/200]\tLoss 0.2902 (0.3614)\tIOU 0.953 (0.944)\n",
      "Epoch: [46][80/200]\tLoss 0.2067 (0.3482)\tIOU 0.981 (0.951)\n",
      "Epoch: [46][100/200]\tLoss 0.2773 (0.2928)\tIOU 0.963 (0.959)\n",
      "Epoch: [46][120/200]\tLoss 0.5578 (0.3304)\tIOU 0.922 (0.953)\n",
      "Epoch: [46][140/200]\tLoss 0.2637 (0.3353)\tIOU 0.963 (0.951)\n",
      "Epoch: [46][160/200]\tLoss 0.1346 (0.2971)\tIOU 0.997 (0.959)\n",
      "Epoch: [46][180/200]\tLoss 0.2889 (0.4147)\tIOU 0.950 (0.934)\n",
      "Epoch: [46][Validation]\tVal_Loss: 1.43436\tVal_IOU: 0.83778\tBest Val_IOU: 0.84643\n",
      "epoch time:  104.24889898300171\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0010\n",
      "Epoch: [47][0/200]\tLoss 0.2643 (0.2643)\tIOU 0.978 (0.978)\n",
      "Epoch: [47][20/200]\tLoss 0.3442 (0.2963)\tIOU 0.941 (0.957)\n",
      "Epoch: [47][40/200]\tLoss 0.6177 (0.3166)\tIOU 0.859 (0.953)\n",
      "Epoch: [47][60/200]\tLoss 0.5361 (0.3443)\tIOU 0.891 (0.945)\n",
      "Epoch: [47][80/200]\tLoss 0.3029 (0.3120)\tIOU 0.950 (0.960)\n",
      "Epoch: [47][100/200]\tLoss 0.2344 (0.3599)\tIOU 0.966 (0.943)\n",
      "Epoch: [47][120/200]\tLoss 0.1795 (0.3812)\tIOU 0.981 (0.942)\n",
      "Epoch: [47][140/200]\tLoss 0.4435 (0.3470)\tIOU 0.909 (0.943)\n",
      "Epoch: [47][160/200]\tLoss 0.4329 (0.3807)\tIOU 0.925 (0.937)\n",
      "Epoch: [47][180/200]\tLoss 0.3087 (0.3133)\tIOU 0.950 (0.955)\n",
      "Epoch: [47][Validation]\tVal_Loss: 1.42533\tVal_IOU: 0.83573\tBest Val_IOU: 0.84643\n",
      "epoch time:  105.08323073387146\n",
      "Fold/Cycle: [2/2]\t\n",
      "change learning rate into: 0.0010\n",
      "Epoch: [48][0/200]\tLoss 0.2130 (0.2130)\tIOU 0.981 (0.981)\n",
      "Epoch: [48][20/200]\tLoss 0.1595 (0.3422)\tIOU 0.994 (0.950)\n",
      "Epoch: [48][40/200]\tLoss 0.4725 (0.3463)\tIOU 0.900 (0.946)\n",
      "Epoch: [48][60/200]\tLoss 0.4254 (0.3313)\tIOU 0.956 (0.955)\n",
      "Epoch: [48][80/200]\tLoss 0.3711 (0.4201)\tIOU 0.947 (0.929)\n",
      "Epoch: [48][100/200]\tLoss 0.5191 (0.3151)\tIOU 0.891 (0.952)\n",
      "Epoch: [48][120/200]\tLoss 0.4559 (0.3183)\tIOU 0.925 (0.953)\n",
      "Epoch: [48][140/200]\tLoss 0.2914 (0.3152)\tIOU 0.956 (0.954)\n",
      "Epoch: [48][160/200]\tLoss 0.4931 (0.3481)\tIOU 0.906 (0.945)\n",
      "Epoch: [48][180/200]\tLoss 0.4537 (0.3329)\tIOU 0.916 (0.950)\n",
      "Epoch: [48][Validation]\tVal_Loss: 1.40244\tVal_IOU: 0.83862\tBest Val_IOU: 0.84643\n",
      "epoch time:  105.52763772010803\n",
      "Fold/Cycle: [2/2]\t\n",
      "restart at epoch 150\n",
      "change learning rate into: 0.0010\n",
      "Epoch: [49][0/200]\tLoss 0.3607 (0.3607)\tIOU 0.944 (0.944)\n",
      "Epoch: [49][20/200]\tLoss 0.2312 (0.3078)\tIOU 0.981 (0.957)\n",
      "Epoch: [49][40/200]\tLoss 0.4895 (0.3358)\tIOU 0.903 (0.947)\n",
      "Epoch: [49][60/200]\tLoss 0.3909 (0.3554)\tIOU 0.959 (0.948)\n",
      "Epoch: [49][80/200]\tLoss 0.1983 (0.3153)\tIOU 0.975 (0.958)\n",
      "Epoch: [49][100/200]\tLoss 0.5357 (0.3507)\tIOU 0.934 (0.947)\n",
      "Epoch: [49][120/200]\tLoss 0.1294 (0.3457)\tIOU 0.997 (0.951)\n",
      "Epoch: [49][140/200]\tLoss 0.2274 (0.3636)\tIOU 0.975 (0.940)\n",
      "Epoch: [49][160/200]\tLoss 0.3397 (0.3603)\tIOU 0.941 (0.947)\n",
      "Epoch: [49][180/200]\tLoss 0.4212 (0.3174)\tIOU 0.934 (0.953)\n",
      "Epoch: [49][Validation]\tVal_Loss: 1.42287\tVal_IOU: 0.83754\tBest Val_IOU: 0.84643\n",
      "epoch time:  104.37905383110046\n",
      "Fold/Cycle: [2/3]\t\n",
      "change learning rate into: 0.0100\n",
      "Epoch: [0][0/200]\tLoss 0.4426 (0.4426)\tIOU 0.934 (0.934)\n",
      "Epoch: [0][20/200]\tLoss 0.5802 (0.4286)\tIOU 0.881 (0.938)\n",
      "Epoch: [0][40/200]\tLoss 0.5533 (0.3812)\tIOU 0.900 (0.939)\n",
      "Epoch: [0][60/200]\tLoss 0.3773 (0.3969)\tIOU 0.953 (0.941)\n",
      "Epoch: [0][80/200]\tLoss 0.4869 (0.4975)\tIOU 0.909 (0.918)\n",
      "Epoch: [0][100/200]\tLoss 0.7094 (0.4669)\tIOU 0.891 (0.926)\n",
      "Epoch: [0][120/200]\tLoss 0.6704 (0.4569)\tIOU 0.853 (0.929)\n",
      "Epoch: [0][140/200]\tLoss 0.7188 (0.4707)\tIOU 0.850 (0.924)\n",
      "Epoch: [0][160/200]\tLoss 0.4524 (0.4185)\tIOU 0.925 (0.935)\n",
      "Epoch: [0][180/200]\tLoss 0.6796 (0.5032)\tIOU 0.916 (0.926)\n"
     ]
    }
   ],
   "source": [
    "fold = 0\n",
    "for x_train_f, y_train_f, x_valid_f, y_valid_f in zip(x_train, y_train, x_valid, y_valid):\n",
    "    \n",
    "    if fold < 2:\n",
    "        fold += 1\n",
    "        continue\n",
    "        \n",
    "    train_loader = make_loader((x_train_f, y_train_f), num_workers=0, batch_size=32, shuffle=True)\n",
    "    valid_loader = make_loader((x_valid_f, y_valid_f), num_workers=0, batch_size=64, mode='valid')\n",
    "\n",
    "    res_unet = UNetResNet34_DS(dropout_2d=0.5, pretrained=False)\n",
    "    res_unet = res_unet.to(device)\n",
    "\n",
    "    #early_stop = EarlyStopping(mode='max', min_delta=0, patience=10)\n",
    "    #model = nn.DataParallel(model, device_ids=None)\n",
    "\n",
    "    n_epochs = 50\n",
    "    n_cycle = 5\n",
    "    start_epoch = 0\n",
    "    report_each = 20\n",
    "    valid_losses = []\n",
    "    valid_ious = []\n",
    "    train_losses = []\n",
    "    train_ious = []\n",
    "    valid_iou = 0\n",
    "    valid_loss = 0\n",
    "    \n",
    "    if LOAD_CHECKPONT:\n",
    "        resume_path = 'model_best_{name}_{loss}_{phrase}_{fold}_{mode}_{aug}.pth.tar'.format(name='resnet34',\n",
    "                                                                                             loss='bce_dice',\n",
    "                                                                                             phrase='0',\n",
    "                                                                                             fold=fold,\n",
    "                                                                                             mode='iou',\n",
    "                                                                                             aug='resizepad')\n",
    "        if os.path.isfile(resume_path):\n",
    "            print(\"=> loading checkpoint '{}'\".format(resume_path))\n",
    "            checkpoint = torch.load(resume_path)\n",
    "            #start_epoch = checkpoint['epoch']\n",
    "            #best_iou = checkpoint['best_iou']\n",
    "            res_unet.load_state_dict(checkpoint['state_dict'])\n",
    "            #optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            \n",
    "    optimizer= SGD(filter(lambda p: p.requires_grad, res_unet.parameters()),\n",
    "                   0.01, weight_decay=0.0002, momentum=0.9)\n",
    "    scheduler = CosineAnnealingLR_with_Restart(optimizer,\n",
    "                                              T_max=n_epochs,\n",
    "                                              T_mult=1,\n",
    "                                              model=res_unet,\n",
    "                                              out_dir='',\n",
    "                                              take_snapshot=False,\n",
    "                                              eta_min=1e-3)\n",
    "        \n",
    "    for cycle in range(n_cycle):\n",
    "        best_iou = 0  \n",
    "        for epoch in range(start_epoch, start_epoch + n_epochs):\n",
    "            print('Fold/Cycle: [{0}/{1}]\\t'.format(fold, cycle))\n",
    "            time0 = time.time()\n",
    "            train_metrics = train_phrase1(res_unet, criterion_phrase1, train_loader, optimizer, \n",
    "                                  epoch, scheduler, report_each, valid_iou)\n",
    "            valid_metrics = validation_phrase1(res_unet, criterion_phrase1, valid_loader)\n",
    "\n",
    "            train_loss = train_metrics['train_loss']\n",
    "            train_iou = train_metrics['train_iou']\n",
    "            train_losses += [train_loss]\n",
    "            train_ious += [train_iou]\n",
    "            valid_loss = valid_metrics['val_loss']\n",
    "            valid_iou = valid_metrics['val_iou']\n",
    "            valid_losses += [valid_loss]\n",
    "            valid_ious += [valid_iou]\n",
    "            is_best = best_iou < valid_iou\n",
    "            best_iou = max(valid_iou, best_iou)\n",
    "            print('Epoch: [{0}][Validation]\\t' \n",
    "                  'Val_Loss: {val_loss:.5f}\\t' \n",
    "                  'Val_IOU: {val_iou:.5f}\\t'\n",
    "                  'Best Val_IOU: {best_iou:.5f}'.format(epoch, \n",
    "                                                        val_loss=valid_loss, \n",
    "                                                        val_iou=valid_iou, \n",
    "                                                        best_iou=best_iou))\n",
    "            filename = '{name}_{loss}_{phrase}_{fold}_{cycle}_{mode}'.format(name='resnet34',\n",
    "                                                                     loss='bce_dice',\n",
    "                                                                     phrase='1',\n",
    "                                                                     fold=fold,\n",
    "                                                                     cycle=cycle,\n",
    "                                                                     mode='iou',)\n",
    "            save_checkpoint({\n",
    "                'epoch': epoch + 1,\n",
    "                'state_dict': res_unet.state_dict(),\n",
    "                'best_iou': best_iou,\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "            }, is_best, filename)\n",
    "            time1 = time.time()\n",
    "            print('epoch time: ', time1-time0)\n",
    "    fold += 1\n",
    "    \"\"\"\n",
    "    if early_stop.step(valid_iou):\n",
    "        break\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
