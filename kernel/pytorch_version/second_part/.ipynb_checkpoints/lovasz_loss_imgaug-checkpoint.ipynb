{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "54643e32b4132d15df20d55f2b9ee09efc2c51a8"
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b15761a022f76bb50db1bb55c21b59a3f1c88261"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "import shutil\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "from tqdm import tqdm_notebook #, tnrange\n",
    "#from itertools import chain\n",
    "from skimage.io import imread, imshow #, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from skimage import filters\n",
    "\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.backends.cudnn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchvision.transforms import ToTensor, ToPILImage, Normalize, Compose\n",
    "\n",
    "import PIL\n",
    "\n",
    "from datetime import datetime\n",
    "import json\n",
    "import gc\n",
    "\n",
    "import time\n",
    "t_start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "99e7207d6aec7d921e4b8ad4f30d310d2346216a"
   },
   "source": [
    "# Global variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "73cc76d8506e96b912600406fa5ceeb47083978a"
   },
   "outputs": [],
   "source": [
    "TRAIN_IMG_PATH = \"../input/tgs-salt-identification-challenge/train/images/\"\n",
    "TEST_IMG_PATH = \"../input/tgs-salt-identification-challenge/test/images/\"\n",
    "DEPTH_PATH = \"../input/tgs-salt-identification-challenge/depths.csv\"\n",
    "TRAIN_MASK_PATH = \"../input/tgs-salt-identification-challenge/train/masks/\"\n",
    "TRAIN_INFO_PATH = \"../input/tgs-salt-identification-challenge/train.csv\"\n",
    "FILENAME = \"checkpoint.pth.tar\"\n",
    "BEST_FILENAME = \"model_best.pth.tar\"\n",
    "\n",
    "# basic parameters\n",
    "IMG_ORI_SIZE = 101\n",
    "IMG_TAR_SIZE = 101\n",
    "\n",
    "# Keras Model parameters\n",
    "START_NEURONS = 16\n",
    "DROPOUT_RATIO = 0.5\n",
    "\n",
    "MODEL1_ADAM_LR = 0.01\n",
    "MODEL1_EPOCHS = 100\n",
    "MODEL1_BATCH_SIZE = 64\n",
    "MODEL1_STEPS_PER_EPOCH_TRAIN = 200\n",
    "MODEL1_LOSS = 'binary_crossentropy'\n",
    "\n",
    "MODEL2_ADAM_LR = 0.01\n",
    "MODEL2_EPOCHS = 100\n",
    "MODEL2_BATCH_SIZE = 64\n",
    "MODEL2_STEPS_PER_EPOCH_TRAIN = 200\n",
    "MODEL2_LOSS = 'lovasz_loss'\n",
    "\n",
    "# ReduceLROnPlateau parameters\n",
    "MODEL1_REDUCE_FACTOR = 0.5\n",
    "MODEL1_REDUCE_PATIENT = 5\n",
    "\n",
    "MODEL2_REDUCE_FACTOR = 0.5\n",
    "MODEL2_REDUCE_PATIENT = 5\n",
    "\n",
    "version = 1\n",
    "\n",
    "# Name\n",
    "BASIC_NAME = f'Unet_resnet_v{version}'\n",
    "SAVE_MODEL_NAME = BASIC_NAME + '.model'\n",
    "SUBMISSION_NAME = BASIC_NAME + '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aa113e7f4cabb11b9a14afc2151e96ff664ef7ed"
   },
   "outputs": [],
   "source": [
    "# encoding=utf8\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from functools import reduce\n",
    "\n",
    "################################################################################\n",
    "# related functions & loss functions\n",
    "################################################################################\n",
    "\n",
    "\n",
    "def upsample(img):\n",
    "    if IMG_ORI_SIZE == IMG_TAR_SIZE:\n",
    "        return img\n",
    "    return cv2.resize(img, (IMG_TAR_SIZE, IMG_TAR_SIZE))\n",
    "\n",
    "\n",
    "def downsample(img):\n",
    "    if IMG_ORI_SIZE == IMG_TAR_SIZE:\n",
    "        return img\n",
    "    return cv2.resize(img, (IMG_ORI_SIZE, IMG_ORI_SIZE))\n",
    "\n",
    "class MyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return super(MyEncoder, self).default(obj)\n",
    "\n",
    "def write_event(log, step: int, **data):\n",
    "    data['step'] = step\n",
    "    data['dt'] = datetime.now().isoformat()\n",
    "    log.write(json.dumps(data, sort_keys=True, cls=MyEncoder))\n",
    "    log.write('\\n')\n",
    "    log.flush()\n",
    "\n",
    "def get_variable(x):\n",
    "    \"\"\" Converts tensors to cuda, if available. \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return x.cuda()\n",
    "    return x\n",
    "\n",
    "def get_numpy(x):\n",
    "    \"\"\" Get numpy array for both cuda and not. \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return x.cpu().data.numpy()\n",
    "    return x.data.numpy()\n",
    "    \n",
    "def iou_numpy(outputs, labels):\n",
    "    SMOOTH = 1e-6\n",
    "    labels = labels.squeeze(1)\n",
    "    outputs = outputs.squeeze(1)\n",
    "    \n",
    "    intersection = (outputs & labels).sum((1, 2))\n",
    "    union = (outputs | labels).sum((1, 2))\n",
    "    \n",
    "    iou = (intersection + SMOOTH) / (union + SMOOTH)\n",
    "    \n",
    "    thresholded = np.ceil(np.clip(20 * (iou - 0.5), 0, 10)) / 10\n",
    "    \n",
    "    return thresholded.mean()\n",
    "\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    return iou_numpy(pred > 0.5, label>0.5)\n",
    "\n",
    "\n",
    "def my_iou_metric_2(label, pred):\n",
    "    return iou_numpy(pred > 0, label>0.5)\n",
    "\n",
    "\n",
    "def my_iou_metric_thre(label, pred, thre):\n",
    "    return iou_numpy(pred > thre, label>0.5) \n",
    "\n",
    "\n",
    "class DICELoss(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DICELoss, self).__init__()\n",
    "\n",
    "    def forward(self, output, mask):\n",
    "\n",
    "        probs = torch.squeeze(output, 1)\n",
    "        mask = torch.squeeze(mask, 1)\n",
    "\n",
    "        intersection = probs * mask\n",
    "        intersection = torch.sum(intersection, 2)\n",
    "        intersection = torch.sum(intersection, 1)\n",
    "\n",
    "        den1 = probs\n",
    "        # print(den1.size())\n",
    "        den1 = torch.sum(den1, 2)\n",
    "        den1 = torch.sum(den1, 1)\n",
    "\n",
    "        den2 = mask\n",
    "        # print(den2.size())\n",
    "        den2 = torch.sum(den2, 2)\n",
    "        den2 = torch.sum(den2, 1)\n",
    "\n",
    "        eps = 0.0000001\n",
    "        dice = 2 * ((intersection + eps) / (den1 + den2 + eps))\n",
    "        # dice_eso = dice[:, 1:]\n",
    "        dice_eso = dice\n",
    "\n",
    "        loss = 1 - torch.sum(dice_eso) / dice_eso.size(0)\n",
    "        return loss   \n",
    "\n",
    "class BCE_DICE_Loss(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BCE_DICE_Loss, self).__init__()\n",
    "\n",
    "    def forward(self, output, mask):\n",
    "        criterion_1 = nn.BCELoss()\n",
    "        criterion_2 = DICELoss()\n",
    "        loss = criterion_1(output, mask) + criterion_2(output, mask)\n",
    "        return loss   \n",
    "    \n",
    "def save_checkpoint(state, is_best, filename=FILENAME):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, BEST_FILENAME)\n",
    "        \n",
    "\n",
    "\"\"\"\n",
    "Lovasz-Softmax and Jaccard hinge loss in PyTorch\n",
    "Maxim Berman 2018 ESAT-PSI KU Leuven (MIT License)\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "try:\n",
    "    from itertools import  ifilterfalse\n",
    "except ImportError: # py3k\n",
    "    from itertools import  filterfalse\n",
    "\n",
    "\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    p = len(gt_sorted)\n",
    "    gts = torch.sum(gt_sorted)\n",
    "    intersection = gts - torch.cumsum(gt_sorted,0)\n",
    "    union = gts + torch.cumsum(1 - gt_sorted, 0)\n",
    "    jaccard = 1. - intersection / union\n",
    "    if p > 1: # cover 1-pixel case\n",
    "        jaccard[1:p] = jaccard[1:p] - jaccard[0:-1]\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        losses = 0\n",
    "        loss = mean(lovasz_hinge_flat(*flatten_binary_scores(log.unsqueeze(0), lab.unsqueeze(0), ignore))\n",
    "                          for log, lab in zip(logits, labels))\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"D\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "    if len(labels) == 0:\n",
    "        # only void pixels, the gradients should be 0\n",
    "        return logits.sum() * 0.\n",
    "    signs = 2 * labels - 1.\n",
    "    errors = (1 - logits * signs)\n",
    "    errors_sorted, perm = torch.sort(errors, dim=0, descending=True)\n",
    "    perm = perm.data\n",
    "    gt_sorted = labels[perm]\n",
    "    grad = lovasz_grad(gt_sorted)\n",
    "    loss = torch.dot(F.relu(errors_sorted), grad)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = scores.view(-1)\n",
    "    labels = labels.view(-1)\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = (labels != ignore)\n",
    "    vscores = scores[valid]\n",
    "    vlabels = labels[valid]\n",
    "    return vscores, vlabels\n",
    "\n",
    "def mean(l, ignore_nan=False, empty=0):\n",
    "    \"\"\"\n",
    "    nanmean compatible with generators.\n",
    "    \"\"\"\n",
    "    l = iter(l)\n",
    "    if ignore_nan:\n",
    "        l = ifilterfalse(np.isnan, l)\n",
    "    try:\n",
    "        n = 1\n",
    "        acc = next(l)\n",
    "    except StopIteration:\n",
    "        if empty == 'raise':\n",
    "            raise ValueError('Empty mean')\n",
    "        return empty\n",
    "    for n, v in enumerate(l, 2):\n",
    "        acc += v\n",
    "    if n == 1:\n",
    "        return acc\n",
    "    return acc / n\n",
    "\n",
    "\n",
    "class Lovasz_Loss(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Lovasz_Loss, self).__init__()\n",
    "\n",
    "    def forward(self, output, mask, per_image=True, ignore=None):\n",
    "        \n",
    "        return lovasz_hinge(output, mask, per_image, ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ef0e5853d0c2cc72dbf8a9fe90720a610a8dcccd"
   },
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import numpy as np\n",
    "\n",
    "ia.seed(2018)\n",
    "\n",
    "\n",
    "def _standardize(img):\n",
    "    return (img - img.map(np.mean)) / img.map(np.std)\n",
    "\n",
    "\n",
    "st = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "affine_seq = iaa.Sequential([\n",
    "    # General\n",
    "    st(iaa.Affine(\n",
    "            scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)}, # scale images to 80-120% of their size, individually per axis\n",
    "            translate_percent={\"x\": (-0.15, 0.15), \"y\": (-0.15, 0.15)} # translate by -16 to +16 pixels (per axis)\n",
    "        )),\n",
    "    # Deformations\n",
    "    iaa.Sometimes(0.3, iaa.PiecewiseAffine(scale=(0.04, 0.08))),\n",
    "    iaa.Sometimes(0.3, iaa.PerspectiveTransform(scale=(0.05, 0.1))),\n",
    "], random_order=True)\n",
    "\n",
    "intensity_seq = iaa.Sequential([\n",
    "    iaa.Invert(0.3),\n",
    "    iaa.Sometimes(0.3, iaa.ContrastNormalization((0.5, 1.5))),\n",
    "    iaa.OneOf([\n",
    "        iaa.Noop(),\n",
    "        iaa.Sequential([\n",
    "            iaa.OneOf([\n",
    "                iaa.Add((-10, 10)),\n",
    "                iaa.AddElementwise((-10, 10)),\n",
    "                iaa.Multiply((0.95, 1.05)),\n",
    "                iaa.MultiplyElementwise((0.95, 1.05)),\n",
    "            ]),\n",
    "        ]),\n",
    "        iaa.OneOf([\n",
    "            iaa.GaussianBlur(sigma=(0.0, 1.0)),\n",
    "            iaa.AverageBlur(k=(2, 5)),\n",
    "            #iaa.MedianBlur(k=(3, 5))\n",
    "        ])\n",
    "    ])\n",
    "], random_order=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1de194accd07b923821cc2f665f35d4502420869"
   },
   "outputs": [],
   "source": [
    "# encoding=utf8\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.backends.cudnn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose\n",
    "\n",
    "## convert salt coverage to class\n",
    "def _cov_to_class(mask):\n",
    "    border = 10\n",
    "    outer = np.zeros((101-2*border, 101-2*border), np.float32)\n",
    "    outer = cv2.copyMakeBorder(outer, border, border, border, border, borderType = cv2.BORDER_CONSTANT, value = 1)\n",
    "\n",
    "    cover = (mask>0.5).sum()\n",
    "    if cover < 8:\n",
    "        return 0 # empty\n",
    "    if cover == ((mask*outer) > 0.5).sum():\n",
    "        return 1 #border\n",
    "    if np.all(mask==mask[0]):\n",
    "        return 2 #vertical\n",
    "\n",
    "    percentage = cover/(101*101)\n",
    "    if percentage < 0.15:\n",
    "        return 3\n",
    "    elif percentage < 0.25:\n",
    "        return 4\n",
    "    elif percentage < 0.50:\n",
    "        return 5\n",
    "    elif percentage < 0.75:\n",
    "        return 6\n",
    "    else:\n",
    "        return 7\n",
    "\n",
    "## used to load data from data files\n",
    "class my_DataLoader:\n",
    "\n",
    "    def __init__(self, train=True, test=True, Kflod=False, test_size=0.2, num_flod=5):\n",
    "        self.test = test\n",
    "        self.train = train\n",
    "        self.Kflod = Kflod\n",
    "        self.test_size = test_size\n",
    "        \n",
    "        if self.Kflod:\n",
    "            self.num_flod = num_flod\n",
    "        else:\n",
    "            self.num_flod = 0\n",
    "        \n",
    "        if self.train:\n",
    "            train_df, self.test_df = self._load_depth()\n",
    "            self._load_image_mask(train_df, self.test_df)\n",
    "            train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(IMG_ORI_SIZE, 2)\n",
    "            train_df[\"coverage_class\"] = train_df.masks.map(_cov_to_class)\n",
    "            self.x_train, self.x_valid, self.y_train, self.y_valid = self._get_train_test_split(train_df)\n",
    "            train_df = None\n",
    "            \n",
    "        if self.test:\n",
    "            self.x_test = np.array(self.test_df.images.tolist()).reshape(-1, IMG_TAR_SIZE, IMG_TAR_SIZE, 1)\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_image_mask(train_df, test_df):\n",
    "        # load image data & mask data\n",
    "        train_df['images'] = [np.array(cv2.imread(TRAIN_IMG_PATH + \"{}.png\".format(idx), 0)) for idx in tqdm_notebook(train_df.index)]\n",
    "        train_df['masks'] = [np.array(cv2.imread(TRAIN_MASK_PATH + \"{}.png\".format(idx), 0)) for idx in tqdm_notebook(train_df.index)]\n",
    "        test_df['images'] = [np.array(cv2.imread(TEST_IMG_PATH + \"{}.png\".format(idx), 0)) for idx in tqdm_notebook(test_df.index)]\n",
    "        # Normalize image vectors\n",
    "        train_df['images'] /= 255\n",
    "        test_df['images'] /= 255\n",
    "        train_df['masks'] /= 255\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_depth():\n",
    "        train_df = pd.read_csv(TRAIN_INFO_PATH, index_col=\"id\", usecols=[0])\n",
    "        depths_df = pd.read_csv(DEPTH_PATH, index_col=\"id\")\n",
    "        depths_df['z'] = depths_df['z'].astype('float')\n",
    "        train_df = train_df.join(depths_df)\n",
    "        test_df = depths_df[~depths_df.index.isin(train_df.index)]\n",
    "        return train_df, test_df\n",
    "\n",
    "    ## get train & validation split stratified by salt coverage\n",
    "    @staticmethod\n",
    "    def _get_train_test_split(train_df):\n",
    "        x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "            np.array(train_df.images.map(upsample).tolist()).reshape(-1, IMG_TAR_SIZE, IMG_TAR_SIZE, 1),\n",
    "            np.array(train_df.masks.map(upsample).tolist()).reshape(-1, IMG_TAR_SIZE, IMG_TAR_SIZE, 1),\n",
    "            test_size=0.2, stratify=train_df.coverage_class, random_state=1234)\n",
    "        return x_train, x_valid, y_train, y_valid\n",
    "\n",
    "    def get_train(self):\n",
    "        return self.x_train, self.y_train\n",
    "    \n",
    "    def get_valid(self):\n",
    "        return self.x_valid, self.y_valid\n",
    "\n",
    "    def get_test_x(self):\n",
    "        return self.x_test\n",
    "\n",
    "    def get_test_df(self):\n",
    "        return self.test_df\n",
    "    \n",
    "class ShipDataset(Dataset):\n",
    "    def __init__(self, data, transform=None, mode='train'):\n",
    "        if mode == 'train' or mode == 'valid':\n",
    "            self.x = np.transpose(data[0], (0,3,1,2))\n",
    "            self.y = np.transpose(data[1], (0,3,1,2))\n",
    "        elif mode == 'test':\n",
    "            self.data = np.transpose(data, (0,3,1,2))\n",
    "        else:\n",
    "            raise RuntimeError('MODE_ERROR')\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.mode == 'train' or self.mode == 'valid':\n",
    "            return len(self.x)\n",
    "        elif self.mode == 'test':\n",
    "            return len(self.data)\n",
    "        else:\n",
    "            raise RuntimeError('MODE_ERROR')\n",
    "               \n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == 'train':\n",
    "            affine_seq_det = affine_seq.to_deterministic()\n",
    "            new_x_batch = affine_seq_det.augment_images(self.x[idx]*255)\n",
    "            new_x_batch = intensity_seq.augment_images(new_x_batch)/255\n",
    "            new_y_batch = affine_seq_det.augment_images(self.y[idx]*255)/255\n",
    "            return torch.from_numpy(new_x_batch).float(), torch.from_numpy(new_y_batch).float()\n",
    "        elif self.mode == 'valid':\n",
    "            return torch.from_numpy(self.x[idx]).float(), torch.from_numpy(self.y[idx]).float()\n",
    "        elif self.mode == 'test':\n",
    "            return torch.from_numpy(self.data[idx]).float()\n",
    "        else:\n",
    "            raise RuntimeError('MODE_ERROR')\n",
    "            \n",
    "def make_loader(data, batch_size, num_workers=4, shuffle=False, transform=None, mode='train'):\n",
    "        return DataLoader(\n",
    "            dataset=ShipDataset(data, transform=transform, mode=mode),\n",
    "            shuffle=shuffle,\n",
    "            num_workers = num_workers,\n",
    "            batch_size = batch_size,\n",
    "            pin_memory=torch.cuda.is_available()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "47a024a662f85e6cbe936b1bce96d1c471533ddc"
   },
   "outputs": [],
   "source": [
    "dl = my_DataLoader()\n",
    "x_train, y_train = dl.get_train()\n",
    "x_valid, y_valid = dl.get_valid()\n",
    "\n",
    "#Data augmentation\n",
    "x_train = np.append(x_train, [np.fliplr(x) for x in x_train], axis=0)\n",
    "y_train = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bbc578c9bfb6b93b501b74b721a456c0a60ef0f0"
   },
   "outputs": [],
   "source": [
    "train_loader = make_loader((x_train, y_train), batch_size=32, shuffle=True)\n",
    "valid_loader = make_loader((x_valid, y_valid), num_workers=0, batch_size=64, mode='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "438c676e325d9eea868ee669225fe6bae0eeb769"
   },
   "outputs": [],
   "source": [
    "# encoding=utf8\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "################################################################################\n",
    "# train u-net & resnet model with Pytorch\n",
    "################################################################################\n",
    "class BatchActivate(nn.Module):\n",
    "    def __init__(self, out_ch):\n",
    "        super(BatchActivate, self).__init__()\n",
    "        self.BA = nn.Sequential(\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.BA(x)\n",
    "        return x\n",
    "\n",
    "class convolution_block(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, size, strides=(1,1), padding=(1,1), activation=True):\n",
    "        super(convolution_block, self).__init__()\n",
    "        \n",
    "        if activation == True:\n",
    "            self.CB = nn.Sequential(\n",
    "                nn.Conv2d(in_ch, out_ch, size, stride=strides, padding=(1, 1)),\n",
    "                BatchActivate(out_ch)\n",
    "            )\n",
    "        else:\n",
    "            self.CB = nn.Conv2d(in_ch, out_ch, size, stride=strides, padding=(1, 1))\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.CB(x)\n",
    "        return x\n",
    "    \n",
    "class residual_block(nn.Module):\n",
    "    def __init__(self, out_ch, batch_activation=False):\n",
    "        super(residual_block, self).__init__()\n",
    "        self.BAC = nn.Sequential(\n",
    "            BatchActivate(out_ch),\n",
    "            convolution_block(out_ch, out_ch, (3,3)),\n",
    "            convolution_block(out_ch, out_ch, (3,3), activation=False)\n",
    "        )\n",
    "        self.BA = BatchActivate(out_ch)\n",
    "        self.batch_activation = batch_activation\n",
    "        \n",
    "    def forward(self, blockinput):\n",
    "        x = self.BAC(blockinput)\n",
    "        x = torch.add(blockinput, 1, x)\n",
    "        \n",
    "        if self.batch_activation:\n",
    "            return self.BA(x)\n",
    "        else:\n",
    "            return x\n",
    "        \n",
    "class up_block(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, DropoutRatio=0.5, padding=0, output_padding=0):\n",
    "        super(up_block, self).__init__()\n",
    "        self.UP = nn.ConvTranspose2d(in_ch, out_ch, (3,3), (2,2), padding, output_padding)\n",
    "        self.DP = nn.Dropout(DropoutRatio)\n",
    "            \n",
    "        self.CR = nn.Sequential(\n",
    "            nn.Conv2d(out_ch*2, out_ch, (3,3), padding=(1, 1)),\n",
    "            residual_block(out_ch),\n",
    "            residual_block(out_ch, True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, xb, xa):\n",
    "        xa = self.UP(xa)\n",
    "        x = torch.cat([xa, xb], dim=1)\n",
    "        x = self.DP(x)\n",
    "        x = self.CR(x)\n",
    "        return x\n",
    "        \n",
    "class Res_UNet(nn.Module):\n",
    "    def __init__(self, start_neurons):\n",
    "        super(Res_UNet, self).__init__()\n",
    "             \n",
    "        self.d1 = nn.Sequential(\n",
    "            nn.Conv2d(1, start_neurons * 1, (3,3), padding=(1, 1)),\n",
    "            residual_block(start_neurons * 1),\n",
    "            residual_block(start_neurons * 1, True),\n",
    "        )\n",
    "        \n",
    "        self.d2 = nn.Sequential(\n",
    "            nn.Conv2d(start_neurons * 1, start_neurons * 2, (3,3), padding=(1, 1)),\n",
    "            residual_block(start_neurons * 2),\n",
    "            residual_block(start_neurons * 2, True),\n",
    "        )\n",
    "        \n",
    "        self.d3 = nn.Sequential(\n",
    "            nn.Conv2d(start_neurons * 2, start_neurons * 4, (3,3), padding=(1, 1)),\n",
    "            residual_block(start_neurons * 4),\n",
    "            residual_block(start_neurons * 4, True),\n",
    "        )\n",
    "        \n",
    "        self.d4 = nn.Sequential(\n",
    "            nn.Conv2d(start_neurons * 4, start_neurons * 8, (3,3), padding=(1, 1)),\n",
    "            residual_block(start_neurons * 8),\n",
    "            residual_block(start_neurons * 8, True),\n",
    "        )\n",
    "        \n",
    "        self.m = nn.Sequential(\n",
    "            nn.Conv2d(start_neurons * 8, start_neurons * 16, (3,3), padding=(1, 1)),\n",
    "            residual_block(start_neurons * 16),\n",
    "            residual_block(start_neurons * 16, True)\n",
    "        )\n",
    "        \n",
    "        self.up4 = up_block(start_neurons * 16, start_neurons * 8, padding=1, output_padding=1)\n",
    "        \n",
    "        self.up5 = up_block(start_neurons * 8, start_neurons * 4)\n",
    "        \n",
    "        self.up6 = up_block(start_neurons * 4, start_neurons * 2, padding=1, output_padding=1)\n",
    "        \n",
    "        self.up7 = up_block(start_neurons * 2, start_neurons * 1)\n",
    "        \n",
    "        self.conv2d_noactiv = nn.Conv2d(start_neurons * 1, 1, (1,1))\n",
    "        \n",
    "        #self.activ = nn.Softmax()\n",
    "        \n",
    "    def forward(self, x, DropOutRatio=0.5):\n",
    "        x1 = self.d1(x)\n",
    "        x1d = F.dropout(F.max_pool2d(x1, 2), DropOutRatio/2)\n",
    "        x2 = self.d2(x1d)\n",
    "        x2d = F.dropout(F.max_pool2d(x2, 2), DropOutRatio)\n",
    "        x3 = self.d3(x2d)\n",
    "        x3d = F.dropout(F.max_pool2d(x3, 2), DropOutRatio)\n",
    "        x4 = self.d4(x3d)\n",
    "        x4d = F.dropout(F.max_pool2d(x4, 2), DropOutRatio)\n",
    "        x5 = self.m(x4d)\n",
    "        x6 = self.up4(x4, x5)\n",
    "        x7 = self.up5(x3, x6)\n",
    "        x8 = self.up6(x2, x7)\n",
    "        x9 = self.up7(x1, x8)\n",
    "        x_noactiv = self.conv2d_noactiv(x9)\n",
    "        return x_noactiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d1e5972b534849e0cec3405de9ba678904411afe"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "res_unet_noactiv = Res_UNet(16)\n",
    "criterion = Lovasz_Loss()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    res_unet_noactiv = res_unet_noactiv.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "\n",
    "#optimizer= Adam(res_unet.parameters(), lr=0.01)\n",
    "\n",
    "resume_path = '../input/shanlins-s-pretrained-res-unet-v2/model_best.pth.tar'\n",
    "if os.path.isfile(resume_path):\n",
    "    checkpoint = torch.load(resume_path)\n",
    "    #start_epoch = checkpoint['epoch']\n",
    "    best_iou = checkpoint['best_iou']\n",
    "    res_unet_noactiv.load_state_dict(checkpoint['state_dict'])\n",
    "    #optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "optimizer= Adam(res_unet_noactiv.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "66be681ece2c0b85c8c0db265979c57cd7097569"
   },
   "outputs": [],
   "source": [
    "def validation(model: nn.Module, criterion, valid_loader):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    iou = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in valid_loader:\n",
    "            inputs = torch.FloatTensor(inputs).cuda()\n",
    "            targets = torch.FloatTensor(targets).cuda()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            losses += [loss.item()]\n",
    "            iou += [my_iou_metric_2(get_numpy(targets), get_numpy(outputs))]\n",
    "\n",
    "        valid_loss = np.mean(losses)  # type: float\n",
    "\n",
    "        valid_iou = np.mean(iou)\n",
    "\n",
    "        metrics = {'val_loss': valid_loss, 'val_iou': valid_iou}\n",
    "    return metrics\n",
    "\n",
    "def train(model, criterion, train_loader, optimizer, epoch, scheduler,\n",
    "          report_each=10, valid_iou=0, fold=None):\n",
    "        model.train()\n",
    "        random.seed()\n",
    "        scheduler.step(valid_iou)\n",
    "        losses = []\n",
    "        ious = []\n",
    "        tl = train_loader\n",
    "        \n",
    "        try:\n",
    "            mean_loss = 0\n",
    "            mean_iou = 0\n",
    "            for i, (inputs, targets) in enumerate(tl):\n",
    "                inputs = torch.FloatTensor(inputs).cuda()\n",
    "                targets = torch.FloatTensor(targets).cuda()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                optimizer.zero_grad()\n",
    "                batch_size = inputs.size(0)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                losses += [loss.item()]\n",
    "                ious += [my_iou_metric_2(get_numpy(targets), get_numpy(outputs))]\n",
    "                mean_loss = np.mean(losses[-report_each:])\n",
    "                mean_iou = np.mean(ious[-report_each:])\n",
    "\n",
    "                if i % report_each == 0:\n",
    "                    print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                          'Loss {loss:.4f} ({loss_avg:.4f})\\t'\n",
    "                          'IOU {iou:.3f} ({iou_avg:.3f})'.format(\n",
    "                           epoch, i, len(tl), loss=losses[-1], loss_avg=mean_loss, iou=ious[-1], iou_avg=mean_iou))\n",
    "\n",
    "            metrics = {'train_loss': mean_loss, 'train_iou': mean_iou}\n",
    "            return metrics\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print('Ctrl+C, saving snapshot')\n",
    "            print('done.')\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5ea6b2cc9a581db9b2d156bf5671ac58a9e4a0e8",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', verbose=True, patience=5, factor=0.5, min_lr=0.0001)\n",
    "#model = nn.DataParallel(model, device_ids=None)\n",
    "\n",
    "n_epochs = 50\n",
    "start_epoch = 0\n",
    "report_each = 10\n",
    "valid_losses = []\n",
    "valid_ious = []\n",
    "train_losses = []\n",
    "train_ious = []\n",
    "valid_iou = 0\n",
    "valid_loss = 0\n",
    "for epoch in range(start_epoch, n_epochs + 1):\n",
    "    \n",
    "    train_metrics = train(res_unet_noactiv, criterion, train_loader, optimizer, \n",
    "                          epoch, scheduler, report_each, valid_iou)\n",
    "    valid_metrics = validation(res_unet_noactiv, criterion, valid_loader)\n",
    "\n",
    "    train_loss = train_metrics['train_loss']\n",
    "    train_iou = train_metrics['train_iou']\n",
    "    train_losses += [train_loss]\n",
    "    train_ious += [train_iou]\n",
    "    valid_loss = valid_metrics['val_loss']\n",
    "    valid_iou = valid_metrics['val_iou']\n",
    "    valid_losses += [valid_loss]\n",
    "    valid_ious += [valid_iou]\n",
    "    print('Epoch: [{0}][Validation]\\t' \n",
    "          'Val_Loss: {val_loss:.5f}\\t' \n",
    "          'Val_IOU: {val_iou:.5f}'.format(epoch, val_loss=valid_loss, val_iou=valid_iou))\n",
    "    is_best = best_iou < valid_iou\n",
    "    best_iou = max(valid_iou, best_iou)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': res_unet_noactiv.state_dict(),\n",
    "        'best_iou': best_iou,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cc45d408a40354ab6609f7c41675eaaac979ac44"
   },
   "outputs": [],
   "source": [
    "x_test = dl.get_test_x()\n",
    "test_loader = make_loader(x_test, batch_size=64, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "08a07a21cbdaa905f726c1a3f09510d967f7e59e"
   },
   "outputs": [],
   "source": [
    "resume_path = BEST_FILENAME\n",
    "if os.path.isfile(resume_path):\n",
    "    checkpoint = torch.load(resume_path)\n",
    "    res_unet_noactiv.load_state_dict(checkpoint['state_dict'])\n",
    "    #optimizer.load_state_dict(checkpoint['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c636982e1a4e7d34ed8c35717b747ed0d5cb3221"
   },
   "outputs": [],
   "source": [
    "res_unet_noactiv.eval()\n",
    "output_list = []\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, targets) in enumerate(valid_loader):\n",
    "        inputs = torch.FloatTensor(inputs).cuda()\n",
    "        outputs = res_unet_noactiv(inputs)\n",
    "        output_list += [get_numpy(outputs)]\n",
    "        if i % report_each == 0:\n",
    "            print('iteration: [{0}/{1}]'.format(i, len(valid_loader)))\n",
    "output_valid = np.concatenate(output_list, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b28aba45c492123696d58d80fa0617237eaeb356"
   },
   "outputs": [],
   "source": [
    "label = y_valid.swapaxes(2,3).swapaxes(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "266b6a8702c2c95d5d266d6657528059bebbb593"
   },
   "outputs": [],
   "source": [
    "## Scoring for last model, choose threshold by validation data \n",
    "thresholds_ori = np.linspace(0.3, 0.7, 31)\n",
    "# Reverse sigmoid function: Use code below because the  sigmoid activation was removed\n",
    "thresholds = np.log(thresholds_ori/(1-thresholds_ori)) \n",
    "ious = np.array([my_iou_metric_thre(label, output_valid, threshold) for threshold in tqdm_notebook(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b3652d8583024fc13240d77aebe5d9251d45f6f7"
   },
   "outputs": [],
   "source": [
    "threshold_best_index = np.argmax(ious) \n",
    "iou_best = ious[threshold_best_index]\n",
    "threshold_best = thresholds[threshold_best_index]\n",
    "\n",
    "plt.plot(thresholds, ious)\n",
    "plt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"IoU\")\n",
    "plt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "23286e49e518a5f4f4f921a52e0fb727229a3d64"
   },
   "outputs": [],
   "source": [
    "res_unet_noactiv.eval()\n",
    "output_list = []\n",
    "with torch.no_grad():\n",
    "    for i, inputs in enumerate(test_loader):\n",
    "        inputs_1 = torch.FloatTensor(inputs)\n",
    "        inputs_2 = torch.flip(inputs_1, [3])\n",
    "        inputs_1, inputs_2 = inputs_1.cuda(), inputs_2.cuda()\n",
    "        outputs_1 = res_unet_noactiv(inputs_1)\n",
    "        outputs_2 = res_unet_noactiv(inputs_2)\n",
    "        outputs_2 = torch.flip(outputs_2, [3])\n",
    "        outputs = 0.5 * (outputs_1 + outputs_2)\n",
    "        output_list += [get_numpy(outputs)]\n",
    "        if i % report_each == 0:\n",
    "            print('iteration: [{0}/{1}]'.format(i, len(test_loader)))\n",
    "output_test = np.concatenate(output_list, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6adfb78ee8266fef50ec295f6441d37ee3ebfcab"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "used for converting the decoded image to rle mask\n",
    "Fast compared to previous one\n",
    "\"\"\"\n",
    "def rle_encode(im):\n",
    "    '''\n",
    "    im: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = im.flatten(order = 'F')\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6751d1f5d2910b0d0397e8e551834b16c0d1e580"
   },
   "outputs": [],
   "source": [
    "test_df = dl.get_test_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "81520023c5e94d7922d1b74d3849a7647ddfc7ca"
   },
   "outputs": [],
   "source": [
    "pred_dict = {idx: rle_encode(output_test[i] > threshold_best) for i, idx in enumerate(tqdm_notebook(test_df.index.values))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "df52d41ffce2d41d4d27ca345a947e3d2673bd17"
   },
   "outputs": [],
   "source": [
    "submission_file = 'submission.csv'\n",
    "sub = pd.DataFrame.from_dict(pred_dict,orient='index')\n",
    "sub.index.names = ['id']\n",
    "sub.columns = ['rle_mask']\n",
    "sub.to_csv(submission_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
